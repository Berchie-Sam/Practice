{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d56d7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.13\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b8c0272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\RGT\\Code\\MLOps\\mlopsenv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import optuna\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9012788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///D:/RGT/Code/Practice/Deep Learning for GWL Changes/mlruns/1', creation_time=1705882608650, experiment_id='1', last_update_time=1705882608650, lifecycle_stage='active', name='Pamen_DL_GWL_experiment', tags={}>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set MLflow experiment name\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment('Pamen_DL_GWL_experiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "297e0f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"D:\\Groundwater level (GWL) changes\\Groundwater level (GWL) changes data\\Pamen.csv\"\n",
    "#nsawam_url = \"D:\\Groundwater level (GWL) changes\\Groundwater level (GWL) changes data\\Nsawam.csv\"\n",
    "#suhum_url = \"D:\\Groundwater level (GWL) changes\\Groundwater level (GWL) changes data\\Suhum.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adcf5192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sunlight</th>\n",
       "      <th>Avg_Temp</th>\n",
       "      <th>Spec_Hum</th>\n",
       "      <th>Rel_Hum</th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>Wind_Speed</th>\n",
       "      <th>Soil_Moisture</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>GWL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.71</td>\n",
       "      <td>27.26</td>\n",
       "      <td>14.89</td>\n",
       "      <td>68.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.52</td>\n",
       "      <td>379.60</td>\n",
       "      <td>407.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.67</td>\n",
       "      <td>27.22</td>\n",
       "      <td>14.34</td>\n",
       "      <td>67.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.52</td>\n",
       "      <td>401.30</td>\n",
       "      <td>407.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.42</td>\n",
       "      <td>27.65</td>\n",
       "      <td>14.53</td>\n",
       "      <td>66.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.73</td>\n",
       "      <td>0.52</td>\n",
       "      <td>405.50</td>\n",
       "      <td>406.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.79</td>\n",
       "      <td>27.52</td>\n",
       "      <td>15.01</td>\n",
       "      <td>68.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.52</td>\n",
       "      <td>397.90</td>\n",
       "      <td>406.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.24</td>\n",
       "      <td>27.79</td>\n",
       "      <td>14.89</td>\n",
       "      <td>66.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.52</td>\n",
       "      <td>384.90</td>\n",
       "      <td>406.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4013</th>\n",
       "      <td>20.87</td>\n",
       "      <td>24.98</td>\n",
       "      <td>8.42</td>\n",
       "      <td>45.62</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.55</td>\n",
       "      <td>348.78</td>\n",
       "      <td>443.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4014</th>\n",
       "      <td>19.13</td>\n",
       "      <td>26.27</td>\n",
       "      <td>13.85</td>\n",
       "      <td>67.75</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.55</td>\n",
       "      <td>372.94</td>\n",
       "      <td>443.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4015</th>\n",
       "      <td>19.32</td>\n",
       "      <td>25.70</td>\n",
       "      <td>11.66</td>\n",
       "      <td>59.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.54</td>\n",
       "      <td>366.63</td>\n",
       "      <td>444.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4016</th>\n",
       "      <td>18.44</td>\n",
       "      <td>25.83</td>\n",
       "      <td>13.43</td>\n",
       "      <td>67.75</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.54</td>\n",
       "      <td>367.59</td>\n",
       "      <td>444.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4017</th>\n",
       "      <td>16.70</td>\n",
       "      <td>25.30</td>\n",
       "      <td>11.78</td>\n",
       "      <td>61.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.54</td>\n",
       "      <td>364.47</td>\n",
       "      <td>444.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4018 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sunlight  Avg_Temp  Spec_Hum  Rel_Hum  Precipitation  Wind_Speed  \\\n",
       "0        19.71     27.26     14.89    68.69           0.00        1.49   \n",
       "1        19.67     27.22     14.34    67.00           0.00        1.40   \n",
       "2        20.42     27.65     14.53    66.56           0.00        1.73   \n",
       "3        19.79     27.52     15.01    68.06           0.00        1.23   \n",
       "4        19.24     27.79     14.89    66.75           0.00        1.33   \n",
       "...        ...       ...       ...      ...            ...         ...   \n",
       "4013     20.87     24.98      8.42    45.62           0.00        1.10   \n",
       "4014     19.13     26.27     13.85    67.75           0.02        1.27   \n",
       "4015     19.32     25.70     11.66    59.44           0.00        1.12   \n",
       "4016     18.44     25.83     13.43    67.75           0.01        1.37   \n",
       "4017     16.70     25.30     11.78    61.94           0.00        1.16   \n",
       "\n",
       "      Soil_Moisture  Rainfall    GWL  \n",
       "0              0.52    379.60  407.0  \n",
       "1              0.52    401.30  407.0  \n",
       "2              0.52    405.50  406.7  \n",
       "3              0.52    397.90  406.9  \n",
       "4              0.52    384.90  406.5  \n",
       "...             ...       ...    ...  \n",
       "4013           0.55    348.78  443.9  \n",
       "4014           0.55    372.94  443.9  \n",
       "4015           0.54    366.63  444.5  \n",
       "4016           0.54    367.59  444.4  \n",
       "4017           0.54    364.47  444.4  \n",
       "\n",
       "[4018 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(url)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d61ca73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sunlight</th>\n",
       "      <th>Avg_Temp</th>\n",
       "      <th>Spec_Hum</th>\n",
       "      <th>Rel_Hum</th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>Wind_Speed</th>\n",
       "      <th>Soil_Moisture</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>GWL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4018.000000</td>\n",
       "      <td>4018.000000</td>\n",
       "      <td>4018.000000</td>\n",
       "      <td>4018.000000</td>\n",
       "      <td>4018.000000</td>\n",
       "      <td>4018.000000</td>\n",
       "      <td>4018.000000</td>\n",
       "      <td>4018.000000</td>\n",
       "      <td>4018.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17.668096</td>\n",
       "      <td>26.109019</td>\n",
       "      <td>16.348838</td>\n",
       "      <td>78.168447</td>\n",
       "      <td>3.232414</td>\n",
       "      <td>1.919881</td>\n",
       "      <td>0.582723</td>\n",
       "      <td>406.608325</td>\n",
       "      <td>421.594475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.119450</td>\n",
       "      <td>1.653947</td>\n",
       "      <td>1.793582</td>\n",
       "      <td>10.054976</td>\n",
       "      <td>3.980853</td>\n",
       "      <td>0.532000</td>\n",
       "      <td>0.079789</td>\n",
       "      <td>11.092558</td>\n",
       "      <td>24.203485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.780000</td>\n",
       "      <td>20.590000</td>\n",
       "      <td>4.460000</td>\n",
       "      <td>24.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>340.440000</td>\n",
       "      <td>319.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15.950000</td>\n",
       "      <td>24.860000</td>\n",
       "      <td>15.870000</td>\n",
       "      <td>72.810000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>1.510000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>402.007500</td>\n",
       "      <td>413.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>17.980000</td>\n",
       "      <td>25.980000</td>\n",
       "      <td>16.660000</td>\n",
       "      <td>80.620000</td>\n",
       "      <td>1.980000</td>\n",
       "      <td>1.880000</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>408.120000</td>\n",
       "      <td>428.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>19.750000</td>\n",
       "      <td>27.270000</td>\n",
       "      <td>17.460000</td>\n",
       "      <td>85.940000</td>\n",
       "      <td>4.370000</td>\n",
       "      <td>2.270000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>413.347500</td>\n",
       "      <td>437.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>26.520000</td>\n",
       "      <td>31.960000</td>\n",
       "      <td>19.780000</td>\n",
       "      <td>94.560000</td>\n",
       "      <td>53.890000</td>\n",
       "      <td>3.990000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>434.500000</td>\n",
       "      <td>459.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Sunlight     Avg_Temp     Spec_Hum      Rel_Hum  Precipitation  \\\n",
       "count  4018.000000  4018.000000  4018.000000  4018.000000    4018.000000   \n",
       "mean     17.668096    26.109019    16.348838    78.168447       3.232414   \n",
       "std       3.119450     1.653947     1.793582    10.054976       3.980853   \n",
       "min       2.780000    20.590000     4.460000    24.120000       0.000000   \n",
       "25%      15.950000    24.860000    15.870000    72.810000       0.550000   \n",
       "50%      17.980000    25.980000    16.660000    80.620000       1.980000   \n",
       "75%      19.750000    27.270000    17.460000    85.940000       4.370000   \n",
       "max      26.520000    31.960000    19.780000    94.560000      53.890000   \n",
       "\n",
       "        Wind_Speed  Soil_Moisture     Rainfall          GWL  \n",
       "count  4018.000000    4018.000000  4018.000000  4018.000000  \n",
       "mean      1.919881       0.582723   406.608325   421.594475  \n",
       "std       0.532000       0.079789    11.092558    24.203485  \n",
       "min       0.580000       0.470000   340.440000   319.700000  \n",
       "25%       1.510000       0.520000   402.007500   413.900000  \n",
       "50%       1.880000       0.580000   408.120000   428.100000  \n",
       "75%       2.270000       0.630000   413.347500   437.000000  \n",
       "max       3.990000       0.850000   434.500000   459.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ec13403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sunlight         0\n",
       "Avg_Temp         0\n",
       "Spec_Hum         0\n",
       "Rel_Hum          0\n",
       "Precipitation    0\n",
       "Wind_Speed       0\n",
       "Soil_Moisture    0\n",
       "Rainfall         0\n",
       "GWL              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da2f81d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sunlight</th>\n",
       "      <th>Avg_Temp</th>\n",
       "      <th>Spec_Hum</th>\n",
       "      <th>Rel_Hum</th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>Wind_Speed</th>\n",
       "      <th>Soil_Moisture</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>GWL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.71</td>\n",
       "      <td>27.26</td>\n",
       "      <td>14.89</td>\n",
       "      <td>68.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.52</td>\n",
       "      <td>379.6</td>\n",
       "      <td>407.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.67</td>\n",
       "      <td>27.22</td>\n",
       "      <td>14.34</td>\n",
       "      <td>67.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.52</td>\n",
       "      <td>401.3</td>\n",
       "      <td>407.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.42</td>\n",
       "      <td>27.65</td>\n",
       "      <td>14.53</td>\n",
       "      <td>66.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.73</td>\n",
       "      <td>0.52</td>\n",
       "      <td>405.5</td>\n",
       "      <td>406.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.79</td>\n",
       "      <td>27.52</td>\n",
       "      <td>15.01</td>\n",
       "      <td>68.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.52</td>\n",
       "      <td>397.9</td>\n",
       "      <td>406.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.24</td>\n",
       "      <td>27.79</td>\n",
       "      <td>14.89</td>\n",
       "      <td>66.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.52</td>\n",
       "      <td>384.9</td>\n",
       "      <td>406.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18.97</td>\n",
       "      <td>27.30</td>\n",
       "      <td>15.56</td>\n",
       "      <td>69.88</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.54</td>\n",
       "      <td>0.51</td>\n",
       "      <td>394.7</td>\n",
       "      <td>407.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18.95</td>\n",
       "      <td>26.97</td>\n",
       "      <td>15.81</td>\n",
       "      <td>72.19</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0.51</td>\n",
       "      <td>411.8</td>\n",
       "      <td>406.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18.41</td>\n",
       "      <td>26.87</td>\n",
       "      <td>14.22</td>\n",
       "      <td>67.12</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.51</td>\n",
       "      <td>407.3</td>\n",
       "      <td>406.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20.55</td>\n",
       "      <td>27.12</td>\n",
       "      <td>13.55</td>\n",
       "      <td>64.31</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.51</td>\n",
       "      <td>390.4</td>\n",
       "      <td>406.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17.65</td>\n",
       "      <td>27.30</td>\n",
       "      <td>12.51</td>\n",
       "      <td>59.31</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.50</td>\n",
       "      <td>403.3</td>\n",
       "      <td>406.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sunlight  Avg_Temp  Spec_Hum  Rel_Hum  Precipitation  Wind_Speed  \\\n",
       "0     19.71     27.26     14.89    68.69           0.00        1.49   \n",
       "1     19.67     27.22     14.34    67.00           0.00        1.40   \n",
       "2     20.42     27.65     14.53    66.56           0.00        1.73   \n",
       "3     19.79     27.52     15.01    68.06           0.00        1.23   \n",
       "4     19.24     27.79     14.89    66.75           0.00        1.33   \n",
       "5     18.97     27.30     15.56    69.88           0.05        1.54   \n",
       "6     18.95     26.97     15.81    72.19           0.03        1.41   \n",
       "7     18.41     26.87     14.22    67.12           0.06        1.57   \n",
       "8     20.55     27.12     13.55    64.31           0.05        0.81   \n",
       "9     17.65     27.30     12.51    59.31           0.10        1.35   \n",
       "\n",
       "   Soil_Moisture  Rainfall    GWL  \n",
       "0           0.52     379.6  407.0  \n",
       "1           0.52     401.3  407.0  \n",
       "2           0.52     405.5  406.7  \n",
       "3           0.52     397.9  406.9  \n",
       "4           0.52     384.9  406.5  \n",
       "5           0.51     394.7  407.0  \n",
       "6           0.51     411.8  406.9  \n",
       "7           0.51     407.3  406.3  \n",
       "8           0.51     390.4  406.6  \n",
       "9           0.50     403.3  406.4  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "890076f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sunlight</th>\n",
       "      <th>Avg_Temp</th>\n",
       "      <th>Spec_Hum</th>\n",
       "      <th>Rel_Hum</th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>Wind_Speed</th>\n",
       "      <th>Soil_Moisture</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>GWL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4008</th>\n",
       "      <td>18.81</td>\n",
       "      <td>27.05</td>\n",
       "      <td>15.87</td>\n",
       "      <td>72.94</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.56</td>\n",
       "      <td>396.07</td>\n",
       "      <td>443.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4009</th>\n",
       "      <td>17.73</td>\n",
       "      <td>26.38</td>\n",
       "      <td>16.36</td>\n",
       "      <td>76.62</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.55</td>\n",
       "      <td>393.32</td>\n",
       "      <td>443.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4010</th>\n",
       "      <td>19.32</td>\n",
       "      <td>27.17</td>\n",
       "      <td>14.47</td>\n",
       "      <td>66.88</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.55</td>\n",
       "      <td>393.20</td>\n",
       "      <td>443.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4011</th>\n",
       "      <td>19.15</td>\n",
       "      <td>26.97</td>\n",
       "      <td>12.08</td>\n",
       "      <td>57.81</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.55</td>\n",
       "      <td>392.55</td>\n",
       "      <td>443.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4012</th>\n",
       "      <td>20.09</td>\n",
       "      <td>25.05</td>\n",
       "      <td>9.95</td>\n",
       "      <td>54.38</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0.55</td>\n",
       "      <td>364.95</td>\n",
       "      <td>443.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4013</th>\n",
       "      <td>20.87</td>\n",
       "      <td>24.98</td>\n",
       "      <td>8.42</td>\n",
       "      <td>45.62</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.55</td>\n",
       "      <td>348.78</td>\n",
       "      <td>443.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4014</th>\n",
       "      <td>19.13</td>\n",
       "      <td>26.27</td>\n",
       "      <td>13.85</td>\n",
       "      <td>67.75</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.55</td>\n",
       "      <td>372.94</td>\n",
       "      <td>443.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4015</th>\n",
       "      <td>19.32</td>\n",
       "      <td>25.70</td>\n",
       "      <td>11.66</td>\n",
       "      <td>59.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.54</td>\n",
       "      <td>366.63</td>\n",
       "      <td>444.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4016</th>\n",
       "      <td>18.44</td>\n",
       "      <td>25.83</td>\n",
       "      <td>13.43</td>\n",
       "      <td>67.75</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.54</td>\n",
       "      <td>367.59</td>\n",
       "      <td>444.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4017</th>\n",
       "      <td>16.70</td>\n",
       "      <td>25.30</td>\n",
       "      <td>11.78</td>\n",
       "      <td>61.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.54</td>\n",
       "      <td>364.47</td>\n",
       "      <td>444.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sunlight  Avg_Temp  Spec_Hum  Rel_Hum  Precipitation  Wind_Speed  \\\n",
       "4008     18.81     27.05     15.87    72.94           0.13        0.97   \n",
       "4009     17.73     26.38     16.36    76.62           0.12        1.15   \n",
       "4010     19.32     27.17     14.47    66.88           0.08        1.06   \n",
       "4011     19.15     26.97     12.08    57.81           0.07        1.17   \n",
       "4012     20.09     25.05      9.95    54.38           0.01        1.91   \n",
       "4013     20.87     24.98      8.42    45.62           0.00        1.10   \n",
       "4014     19.13     26.27     13.85    67.75           0.02        1.27   \n",
       "4015     19.32     25.70     11.66    59.44           0.00        1.12   \n",
       "4016     18.44     25.83     13.43    67.75           0.01        1.37   \n",
       "4017     16.70     25.30     11.78    61.94           0.00        1.16   \n",
       "\n",
       "      Soil_Moisture  Rainfall    GWL  \n",
       "4008           0.56    396.07  443.1  \n",
       "4009           0.55    393.32  443.3  \n",
       "4010           0.55    393.20  443.7  \n",
       "4011           0.55    392.55  443.7  \n",
       "4012           0.55    364.95  443.9  \n",
       "4013           0.55    348.78  443.9  \n",
       "4014           0.55    372.94  443.9  \n",
       "4015           0.54    366.63  444.5  \n",
       "4016           0.54    367.59  444.4  \n",
       "4017           0.54    364.47  444.4  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c7650f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d0a20d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sunlight</th>\n",
       "      <th>Avg_Temp</th>\n",
       "      <th>Spec_Hum</th>\n",
       "      <th>Rel_Hum</th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>Wind_Speed</th>\n",
       "      <th>Soil_Moisture</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>GWL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.709999</td>\n",
       "      <td>27.260000</td>\n",
       "      <td>14.89</td>\n",
       "      <td>68.690002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.52</td>\n",
       "      <td>379.600006</td>\n",
       "      <td>407.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.670000</td>\n",
       "      <td>27.219999</td>\n",
       "      <td>14.34</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.52</td>\n",
       "      <td>401.299988</td>\n",
       "      <td>407.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.420000</td>\n",
       "      <td>27.650000</td>\n",
       "      <td>14.53</td>\n",
       "      <td>66.559998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.73</td>\n",
       "      <td>0.52</td>\n",
       "      <td>405.500000</td>\n",
       "      <td>406.700012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.790001</td>\n",
       "      <td>27.520000</td>\n",
       "      <td>15.01</td>\n",
       "      <td>68.059998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.52</td>\n",
       "      <td>397.899994</td>\n",
       "      <td>406.899994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.240000</td>\n",
       "      <td>27.790001</td>\n",
       "      <td>14.89</td>\n",
       "      <td>66.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.52</td>\n",
       "      <td>384.899994</td>\n",
       "      <td>406.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sunlight   Avg_Temp  Spec_Hum    Rel_Hum  Precipitation  Wind_Speed  \\\n",
       "0  19.709999  27.260000     14.89  68.690002            0.0        1.49   \n",
       "1  19.670000  27.219999     14.34  67.000000            0.0        1.40   \n",
       "2  20.420000  27.650000     14.53  66.559998            0.0        1.73   \n",
       "3  19.790001  27.520000     15.01  68.059998            0.0        1.23   \n",
       "4  19.240000  27.790001     14.89  66.750000            0.0        1.33   \n",
       "\n",
       "   Soil_Moisture    Rainfall         GWL  \n",
       "0           0.52  379.600006  407.000000  \n",
       "1           0.52  401.299988  407.000000  \n",
       "2           0.52  405.500000  406.700012  \n",
       "3           0.52  397.899994  406.899994  \n",
       "4           0.52  384.899994  406.500000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d9ed5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sunlight         0.065483\n",
      "Avg_Temp         0.198594\n",
      "Spec_Hum        -0.028607\n",
      "Rel_Hum         -0.149698\n",
      "Precipitation   -0.098030\n",
      "Wind_Speed      -0.039080\n",
      "Soil_Moisture   -0.081045\n",
      "Rainfall        -0.088520\n",
      "GWL              1.000000\n",
      "Name: GWL, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "corr_matrix = data.corr()['GWL']\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e844fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(data.corr(), annot=True)\n",
    "plt.title('Correlation between columns')\n",
    "plt.show()\n",
    "\n",
    "# Lighter color -> higher correlation value\n",
    "# Darker color -> lower correlation value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "021a269c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sunlight</th>\n",
       "      <th>Avg_Temp</th>\n",
       "      <th>Spec_Hum</th>\n",
       "      <th>Rel_Hum</th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>Wind_Speed</th>\n",
       "      <th>Soil_Moisture</th>\n",
       "      <th>Rainfall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.709999</td>\n",
       "      <td>27.260000</td>\n",
       "      <td>14.89</td>\n",
       "      <td>68.690002</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.52</td>\n",
       "      <td>379.600006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.670000</td>\n",
       "      <td>27.219999</td>\n",
       "      <td>14.34</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.52</td>\n",
       "      <td>401.299988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.420000</td>\n",
       "      <td>27.650000</td>\n",
       "      <td>14.53</td>\n",
       "      <td>66.559998</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.73</td>\n",
       "      <td>0.52</td>\n",
       "      <td>405.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.790001</td>\n",
       "      <td>27.520000</td>\n",
       "      <td>15.01</td>\n",
       "      <td>68.059998</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.52</td>\n",
       "      <td>397.899994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.240000</td>\n",
       "      <td>27.790001</td>\n",
       "      <td>14.89</td>\n",
       "      <td>66.750000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.52</td>\n",
       "      <td>384.899994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4013</th>\n",
       "      <td>20.870001</td>\n",
       "      <td>24.980000</td>\n",
       "      <td>8.42</td>\n",
       "      <td>45.619999</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.55</td>\n",
       "      <td>348.779999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4014</th>\n",
       "      <td>19.129999</td>\n",
       "      <td>26.270000</td>\n",
       "      <td>13.85</td>\n",
       "      <td>67.750000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.55</td>\n",
       "      <td>372.940002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4015</th>\n",
       "      <td>19.320000</td>\n",
       "      <td>25.700001</td>\n",
       "      <td>11.66</td>\n",
       "      <td>59.439999</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.54</td>\n",
       "      <td>366.630005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4016</th>\n",
       "      <td>18.440001</td>\n",
       "      <td>25.830000</td>\n",
       "      <td>13.43</td>\n",
       "      <td>67.750000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.54</td>\n",
       "      <td>367.589996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4017</th>\n",
       "      <td>16.700001</td>\n",
       "      <td>25.299999</td>\n",
       "      <td>11.78</td>\n",
       "      <td>61.939999</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.54</td>\n",
       "      <td>364.470001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4018 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sunlight   Avg_Temp  Spec_Hum    Rel_Hum  Precipitation  Wind_Speed  \\\n",
       "0     19.709999  27.260000     14.89  68.690002           0.00        1.49   \n",
       "1     19.670000  27.219999     14.34  67.000000           0.00        1.40   \n",
       "2     20.420000  27.650000     14.53  66.559998           0.00        1.73   \n",
       "3     19.790001  27.520000     15.01  68.059998           0.00        1.23   \n",
       "4     19.240000  27.790001     14.89  66.750000           0.00        1.33   \n",
       "...         ...        ...       ...        ...            ...         ...   \n",
       "4013  20.870001  24.980000      8.42  45.619999           0.00        1.10   \n",
       "4014  19.129999  26.270000     13.85  67.750000           0.02        1.27   \n",
       "4015  19.320000  25.700001     11.66  59.439999           0.00        1.12   \n",
       "4016  18.440001  25.830000     13.43  67.750000           0.01        1.37   \n",
       "4017  16.700001  25.299999     11.78  61.939999           0.00        1.16   \n",
       "\n",
       "      Soil_Moisture    Rainfall  \n",
       "0              0.52  379.600006  \n",
       "1              0.52  401.299988  \n",
       "2              0.52  405.500000  \n",
       "3              0.52  397.899994  \n",
       "4              0.52  384.899994  \n",
       "...             ...         ...  \n",
       "4013           0.55  348.779999  \n",
       "4014           0.55  372.940002  \n",
       "4015           0.54  366.630005  \n",
       "4016           0.54  367.589996  \n",
       "4017           0.54  364.470001  \n",
       "\n",
       "[4018 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = data.drop(columns = 'GWL')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fa538c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       407.000000\n",
       "1       407.000000\n",
       "2       406.700012\n",
       "3       406.899994\n",
       "4       406.500000\n",
       "           ...    \n",
       "4013    443.899994\n",
       "4014    443.899994\n",
       "4015    444.500000\n",
       "4016    444.399994\n",
       "4017    444.399994\n",
       "Name: GWL, Length: 4018, dtype: float32"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data['GWL']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e25698a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4018, 9)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "437c0532",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b8593ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, x_val, y_test, y_val = train_test_split(x_train, y_train, test_size = 0.5, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68874640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train (3214, 8)\n",
      "x_test (1607, 8)\n",
      "x_val (1607, 8)\n",
      "y_train (3214,)\n",
      "y_test (1607,)\n",
      "y_val (1607,)\n"
     ]
    }
   ],
   "source": [
    "print('x_train', x_train.shape)\n",
    "print('x_test', x_test.shape)\n",
    "print('x_val', x_val.shape)\n",
    "print('y_train', y_train.shape)\n",
    "print('y_test', y_test.shape)\n",
    "print('y_val', y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eec13d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling data into numpy arrays\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "x_val = scaler.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "415685fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.7818266e-02, -5.2952007e-03,  9.5399731e-01, ...,\n",
       "        -1.4290426e+00,  1.8475393e+00, -2.3641244e-01],\n",
       "       [-1.4521008e+00, -4.7886103e-02,  6.5006858e-01, ...,\n",
       "         2.0458348e+00, -6.7202872e-01, -4.6342827e-02],\n",
       "       [ 1.1904600e+00, -8.7537050e-01, -3.2291729e+00, ...,\n",
       "        -5.0866961e-01,  3.3579883e-01, -5.9331350e+00],\n",
       "       ...,\n",
       "       [ 9.6098796e-02,  3.7194067e-01,  1.0203096e+00, ...,\n",
       "         1.8955699e+00, -4.2007145e-01,  2.0874612e+00],\n",
       "       [-5.7339311e-01, -6.9283658e-01, -5.6564850e-01, ...,\n",
       "         2.2336657e+00,  8.3841562e-02, -3.6013767e-01],\n",
       "       [-2.8692785e-01, -5.7723302e-01,  2.7982756e-01, ...,\n",
       "        -9.7824764e-01,  7.1373355e-01,  1.1503630e-01]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "edd7037b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.40280157, -0.8449476 ,  0.51191896, ...,  1.1818112 ,\n",
       "         1.0916691 ,  0.50503904],\n",
       "       [ 1.0488366 ,  1.0838203 ,  0.6500686 , ...,  1.1254619 ,\n",
       "        -0.92398524,  0.38400334],\n",
       "       [-0.47683176, -0.8023567 ,  0.37929544, ..., -1.2224282 ,\n",
       "         0.9656908 ,  0.01641451],\n",
       "       ...,\n",
       "       [ 0.47268787,  1.1081575 , -0.32803097, ..., -0.28327218,\n",
       "        -0.798007  , -0.38703603],\n",
       "       [ 0.7044347 , -0.03571694,  0.74953645, ..., -1.1660789 ,\n",
       "         2.099496  , -0.6237256 ],\n",
       "       [ 0.86215144, -0.12089992,  0.7826921 , ...,  0.48683596,\n",
       "         0.46177706,  0.9577991 ]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2fbceb5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06069279,  0.74917537, -1.2729743 , ..., -0.92189837,\n",
       "        -1.0499635 , -2.1622174 ],\n",
       "       [ 1.171148  ,  0.6335718 ,  0.6500686 , ...,  0.5619684 ,\n",
       "        -0.04213669, -0.37179336],\n",
       "       [ 0.05103644, -1.3012806 ,  0.34613878, ...,  0.16752274,\n",
       "         1.595582  ,  0.14193465],\n",
       "       ...,\n",
       "       [-1.2267911 , -1.173508  ,  0.00905444, ...,  2.4590635 ,\n",
       "         0.46177706,  1.334354  ],\n",
       "       [-0.9338886 , -0.72934407,  0.9539973 , ..., -0.24570596,\n",
       "         0.9656908 ,  1.5584933 ],\n",
       "       [ 0.41153222, -0.425122  ,  1.0534652 , ...,  0.28022137,\n",
       "         1.4696038 ,  0.8860756 ]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c6c1b2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b96af024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\RGT\\Code\\MLOps\\mlopsenv\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/01/21 16:38:54 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\SAMBER~1\\AppData\\Local\\Temp\\tmp0hhf7me9\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\SAMBER~1\\AppData\\Local\\Temp\\tmp0hhf7me9\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 1000)              9000      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 500)               500500    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 250)               125250    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 251       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 635001 (2.42 MB)\n",
      "Trainable params: 635001 (2.42 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From d:\\RGT\\Code\\MLOps\\mlopsenv\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\RGT\\Code\\MLOps\\mlopsenv\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "WARNING:tensorflow:From d:\\RGT\\Code\\MLOps\\mlopsenv\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\RGT\\Code\\MLOps\\mlopsenv\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\RGT\\Code\\MLOps\\mlopsenv\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\RGT\\Code\\MLOps\\mlopsenv\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 1s 9ms/step - loss: 25748.1523 - mae: 112.6750 - val_loss: 5121.2002 - val_mae: 56.6025\n",
      "Epoch 2/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 3618.1030 - mae: 47.2316 - val_loss: 3099.3455 - val_mae: 45.8186\n",
      "Epoch 3/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 2342.4453 - mae: 38.3043 - val_loss: 2027.1162 - val_mae: 34.5498\n",
      "Epoch 4/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 1497.0325 - mae: 30.4591 - val_loss: 998.8273 - val_mae: 23.9948\n",
      "Epoch 5/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 1385.1212 - mae: 29.1186 - val_loss: 783.4960 - val_mae: 22.7850\n",
      "Epoch 6/2000\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 1169.9891 - mae: 26.4455 - val_loss: 1410.1956 - val_mae: 28.6978\n",
      "Epoch 7/2000\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 1094.1755 - mae: 25.8658 - val_loss: 613.7507 - val_mae: 18.6009\n",
      "Epoch 8/2000\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 1128.1886 - mae: 26.2991 - val_loss: 2386.0796 - val_mae: 43.0368\n",
      "Epoch 9/2000\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 1097.7062 - mae: 26.0720 - val_loss: 1514.1915 - val_mae: 29.0308\n",
      "Epoch 10/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 1107.4185 - mae: 26.1694 - val_loss: 751.0193 - val_mae: 19.8296\n",
      "Epoch 11/2000\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 1050.9135 - mae: 25.0443 - val_loss: 725.9275 - val_mae: 21.5322\n",
      "Epoch 12/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 1038.2598 - mae: 24.7850 - val_loss: 788.4331 - val_mae: 22.7556\n",
      "Epoch 13/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 1008.0609 - mae: 24.2085 - val_loss: 873.1862 - val_mae: 25.2706\n",
      "Epoch 14/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 994.9966 - mae: 24.2149 - val_loss: 922.1131 - val_mae: 20.8833\n",
      "Epoch 15/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 1008.9476 - mae: 24.6298 - val_loss: 1248.8206 - val_mae: 26.5932\n",
      "Epoch 16/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 1047.2667 - mae: 25.1213 - val_loss: 651.4839 - val_mae: 17.6803\n",
      "Epoch 17/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 946.3041 - mae: 23.6825 - val_loss: 751.4536 - val_mae: 20.0090\n",
      "Epoch 18/2000\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 1004.4940 - mae: 24.8886 - val_loss: 589.1307 - val_mae: 16.7290\n",
      "Epoch 19/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 954.5921 - mae: 23.7778 - val_loss: 2905.8606 - val_mae: 49.5905\n",
      "Epoch 20/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 978.2820 - mae: 24.2540 - val_loss: 2558.8992 - val_mae: 44.6134\n",
      "Epoch 21/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 923.2576 - mae: 23.3076 - val_loss: 1092.9834 - val_mae: 28.0127\n",
      "Epoch 22/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 934.1520 - mae: 23.4584 - val_loss: 671.4575 - val_mae: 20.8495\n",
      "Epoch 23/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 954.8864 - mae: 24.2598 - val_loss: 585.1887 - val_mae: 18.7736\n",
      "Epoch 24/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 914.7157 - mae: 23.2203 - val_loss: 1281.7592 - val_mae: 32.7393\n",
      "Epoch 25/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 941.7925 - mae: 23.6688 - val_loss: 938.7007 - val_mae: 21.8762\n",
      "Epoch 26/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 899.6816 - mae: 23.1868 - val_loss: 982.6046 - val_mae: 24.9735\n",
      "Epoch 27/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 905.3045 - mae: 23.3256 - val_loss: 681.7460 - val_mae: 17.9260\n",
      "Epoch 28/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 901.9366 - mae: 22.9122 - val_loss: 1337.0725 - val_mae: 31.9498\n",
      "Epoch 29/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 888.9553 - mae: 23.2429 - val_loss: 950.2463 - val_mae: 22.3222\n",
      "Epoch 30/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 866.5477 - mae: 22.5702 - val_loss: 1263.4071 - val_mae: 26.5755\n",
      "Epoch 31/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 929.3708 - mae: 23.6159 - val_loss: 757.8427 - val_mae: 20.4883\n",
      "Epoch 32/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 898.7468 - mae: 23.2643 - val_loss: 562.4917 - val_mae: 16.6644\n",
      "Epoch 33/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 871.1492 - mae: 22.6276 - val_loss: 813.2154 - val_mae: 24.3636\n",
      "Epoch 34/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 919.1982 - mae: 23.3805 - val_loss: 682.6191 - val_mae: 18.7049\n",
      "Epoch 35/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 841.2755 - mae: 22.1897 - val_loss: 1042.2778 - val_mae: 23.5272\n",
      "Epoch 36/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 882.3857 - mae: 22.9440 - val_loss: 515.0205 - val_mae: 16.4388\n",
      "Epoch 37/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 901.0382 - mae: 22.8569 - val_loss: 1022.9938 - val_mae: 28.2843\n",
      "Epoch 38/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 868.3714 - mae: 22.4983 - val_loss: 552.5054 - val_mae: 17.9951\n",
      "Epoch 39/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 871.0248 - mae: 22.6045 - val_loss: 1041.7542 - val_mae: 24.1865\n",
      "Epoch 40/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 855.3174 - mae: 22.1255 - val_loss: 582.7316 - val_mae: 19.0880\n",
      "Epoch 41/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 804.7833 - mae: 21.7895 - val_loss: 1057.0728 - val_mae: 27.9390\n",
      "Epoch 42/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 858.0823 - mae: 22.3744 - val_loss: 1067.3848 - val_mae: 23.5246\n",
      "Epoch 43/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 827.2043 - mae: 21.9535 - val_loss: 539.2977 - val_mae: 18.0606\n",
      "Epoch 44/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 835.7282 - mae: 22.4020 - val_loss: 923.7998 - val_mae: 22.3746\n",
      "Epoch 45/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 845.1216 - mae: 22.3387 - val_loss: 836.6138 - val_mae: 24.0421\n",
      "Epoch 46/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 820.8134 - mae: 21.4231 - val_loss: 872.9533 - val_mae: 20.7582\n",
      "Epoch 47/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 817.2029 - mae: 21.6738 - val_loss: 989.1301 - val_mae: 23.4759\n",
      "Epoch 48/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 805.1726 - mae: 21.5870 - val_loss: 524.3156 - val_mae: 16.7371\n",
      "Epoch 49/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 795.2838 - mae: 21.6197 - val_loss: 1314.1610 - val_mae: 31.2606\n",
      "Epoch 50/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 783.3948 - mae: 21.4127 - val_loss: 1421.8928 - val_mae: 32.9438\n",
      "Epoch 51/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 793.3538 - mae: 21.8511 - val_loss: 556.9276 - val_mae: 18.5080\n",
      "Epoch 52/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 797.8081 - mae: 21.5314 - val_loss: 557.8770 - val_mae: 18.0615\n",
      "Epoch 53/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 775.4726 - mae: 21.4065 - val_loss: 820.8293 - val_mae: 19.9113\n",
      "Epoch 54/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 808.1102 - mae: 21.9096 - val_loss: 894.2814 - val_mae: 21.9734\n",
      "Epoch 55/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 764.3801 - mae: 20.7672 - val_loss: 580.6503 - val_mae: 19.3244\n",
      "Epoch 56/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 772.6391 - mae: 20.9511 - val_loss: 1651.9008 - val_mae: 38.0579\n",
      "Epoch 57/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 785.1470 - mae: 21.4018 - val_loss: 976.6440 - val_mae: 23.3165\n",
      "Epoch 58/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 782.3962 - mae: 21.2921 - val_loss: 776.1231 - val_mae: 19.1110\n",
      "Epoch 59/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 785.5870 - mae: 21.2687 - val_loss: 2224.6155 - val_mae: 39.8019\n",
      "Epoch 60/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 808.3112 - mae: 22.0923 - val_loss: 773.1609 - val_mae: 19.5604\n",
      "Epoch 61/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 788.4918 - mae: 21.5453 - val_loss: 955.6917 - val_mae: 26.6998\n",
      "Epoch 62/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 769.1494 - mae: 21.0802 - val_loss: 1451.3658 - val_mae: 31.4893\n",
      "Epoch 63/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 768.2557 - mae: 21.0725 - val_loss: 542.2519 - val_mae: 16.3085\n",
      "Epoch 64/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 769.6704 - mae: 21.0332 - val_loss: 589.7011 - val_mae: 19.7034\n",
      "Epoch 65/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 782.1053 - mae: 21.4005 - val_loss: 609.8270 - val_mae: 18.1146\n",
      "Epoch 66/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 758.1296 - mae: 20.9072 - val_loss: 946.3619 - val_mae: 22.4904\n",
      "Epoch 67/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 769.7142 - mae: 21.2152 - val_loss: 551.2119 - val_mae: 17.8913\n",
      "Epoch 68/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 759.1468 - mae: 21.1907 - val_loss: 1265.4231 - val_mae: 26.2801\n",
      "Epoch 69/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 758.4699 - mae: 20.9310 - val_loss: 802.4868 - val_mae: 20.2675\n",
      "Epoch 70/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 741.3529 - mae: 20.5951 - val_loss: 2766.5588 - val_mae: 47.6863\n",
      "Epoch 71/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 778.9895 - mae: 21.1758 - val_loss: 1024.2115 - val_mae: 28.8019\n",
      "Epoch 72/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 752.7468 - mae: 20.9590 - val_loss: 748.5529 - val_mae: 22.0443\n",
      "Epoch 73/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 764.2715 - mae: 21.1498 - val_loss: 499.9694 - val_mae: 16.1527\n",
      "Epoch 74/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 737.5444 - mae: 20.6688 - val_loss: 1334.6620 - val_mae: 27.8324\n",
      "Epoch 75/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 741.3633 - mae: 20.9601 - val_loss: 1133.0137 - val_mae: 29.3032\n",
      "Epoch 76/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 750.5822 - mae: 21.0297 - val_loss: 541.8290 - val_mae: 17.5539\n",
      "Epoch 77/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 756.8001 - mae: 20.9926 - val_loss: 1360.3948 - val_mae: 33.6209\n",
      "Epoch 78/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 736.2226 - mae: 21.0536 - val_loss: 583.0550 - val_mae: 19.0279\n",
      "Epoch 79/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 746.8885 - mae: 20.7694 - val_loss: 1038.1167 - val_mae: 24.3404\n",
      "Epoch 80/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 720.3981 - mae: 20.0958 - val_loss: 695.9664 - val_mae: 20.7151\n",
      "Epoch 81/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 704.3984 - mae: 20.2172 - val_loss: 973.7667 - val_mae: 22.8926\n",
      "Epoch 82/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 749.9855 - mae: 21.1094 - val_loss: 524.3725 - val_mae: 15.6757\n",
      "Epoch 83/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 720.1195 - mae: 20.5504 - val_loss: 760.5790 - val_mae: 22.9356\n",
      "Epoch 84/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 746.7032 - mae: 20.6711 - val_loss: 840.3359 - val_mae: 20.3598\n",
      "Epoch 85/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 708.0646 - mae: 20.3807 - val_loss: 789.6772 - val_mae: 23.4569\n",
      "Epoch 86/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 727.9155 - mae: 20.4582 - val_loss: 656.7489 - val_mae: 17.6102\n",
      "Epoch 87/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 698.8285 - mae: 20.1945 - val_loss: 1297.5469 - val_mae: 31.2043\n",
      "Epoch 88/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 696.0882 - mae: 20.1898 - val_loss: 1079.7859 - val_mae: 28.5013\n",
      "Epoch 89/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 688.1494 - mae: 20.0339 - val_loss: 680.2551 - val_mae: 18.0240\n",
      "Epoch 90/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 713.9424 - mae: 20.3428 - val_loss: 859.5873 - val_mae: 20.2430\n",
      "Epoch 91/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 704.3718 - mae: 20.1608 - val_loss: 1885.5344 - val_mae: 40.1246\n",
      "Epoch 92/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 734.8699 - mae: 20.7295 - val_loss: 623.6761 - val_mae: 20.1269\n",
      "Epoch 93/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 706.6846 - mae: 20.3953 - val_loss: 585.2563 - val_mae: 16.7256\n",
      "Epoch 94/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 706.6820 - mae: 19.7491 - val_loss: 1044.0221 - val_mae: 25.0291\n",
      "Epoch 95/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 674.3435 - mae: 19.8969 - val_loss: 650.5082 - val_mae: 20.5390\n",
      "Epoch 96/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 713.4011 - mae: 20.3680 - val_loss: 1008.2907 - val_mae: 27.5844\n",
      "Epoch 97/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 682.9535 - mae: 19.6923 - val_loss: 1046.3141 - val_mae: 27.3185\n",
      "Epoch 98/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 707.1662 - mae: 20.4493 - val_loss: 809.0932 - val_mae: 20.5366\n",
      "Epoch 99/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 697.9182 - mae: 20.0965 - val_loss: 754.3768 - val_mae: 19.9495\n",
      "Epoch 100/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 704.1819 - mae: 20.1130 - val_loss: 656.1079 - val_mae: 20.3081\n",
      "Epoch 101/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 697.2242 - mae: 20.2081 - val_loss: 523.1436 - val_mae: 16.0376\n",
      "Epoch 102/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 693.7159 - mae: 20.3799 - val_loss: 1310.7948 - val_mae: 31.1545\n",
      "Epoch 103/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 680.8270 - mae: 19.7795 - val_loss: 491.1828 - val_mae: 15.6653\n",
      "Epoch 104/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 674.1296 - mae: 19.5886 - val_loss: 850.9631 - val_mae: 25.4077\n",
      "Epoch 105/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 726.5338 - mae: 20.6578 - val_loss: 693.2605 - val_mae: 21.9064\n",
      "Epoch 106/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 651.9771 - mae: 19.6678 - val_loss: 1554.0260 - val_mae: 31.4489\n",
      "Epoch 107/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 702.3492 - mae: 20.1779 - val_loss: 541.7697 - val_mae: 18.6573\n",
      "Epoch 108/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 672.2036 - mae: 19.7014 - val_loss: 610.3717 - val_mae: 19.1570\n",
      "Epoch 109/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 662.0884 - mae: 19.2004 - val_loss: 967.5961 - val_mae: 22.7894\n",
      "Epoch 110/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 677.1525 - mae: 19.6290 - val_loss: 665.7327 - val_mae: 17.5148\n",
      "Epoch 111/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 693.3979 - mae: 19.9035 - val_loss: 575.6628 - val_mae: 19.4326\n",
      "Epoch 112/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 683.6910 - mae: 20.0538 - val_loss: 566.0672 - val_mae: 16.9860\n",
      "Epoch 113/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 654.7038 - mae: 19.3045 - val_loss: 926.2419 - val_mae: 27.1533\n",
      "Epoch 114/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 665.9860 - mae: 19.6597 - val_loss: 699.0844 - val_mae: 21.7740\n",
      "Epoch 115/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 636.9198 - mae: 19.2950 - val_loss: 672.1785 - val_mae: 20.8030\n",
      "Epoch 116/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 670.6456 - mae: 19.7719 - val_loss: 852.6383 - val_mae: 24.3559\n",
      "Epoch 117/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 646.5575 - mae: 19.2079 - val_loss: 631.8127 - val_mae: 18.2567\n",
      "Epoch 118/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 659.7872 - mae: 19.6350 - val_loss: 855.8154 - val_mae: 22.1867\n",
      "Epoch 119/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 657.8384 - mae: 19.2957 - val_loss: 811.7946 - val_mae: 20.1320\n",
      "Epoch 120/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 690.1100 - mae: 19.8796 - val_loss: 544.1539 - val_mae: 18.4392\n",
      "Epoch 121/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 673.5159 - mae: 19.6335 - val_loss: 720.6191 - val_mae: 21.9808\n",
      "Epoch 122/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 611.1748 - mae: 18.7938 - val_loss: 818.7258 - val_mae: 24.1299\n",
      "Epoch 123/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 680.9313 - mae: 19.9544 - val_loss: 567.9580 - val_mae: 16.8155\n",
      "Epoch 124/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 634.6894 - mae: 18.9881 - val_loss: 1005.7433 - val_mae: 26.7662\n",
      "Epoch 125/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 665.7908 - mae: 19.6493 - val_loss: 626.2869 - val_mae: 17.2045\n",
      "Epoch 126/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 635.2445 - mae: 18.7466 - val_loss: 1147.5177 - val_mae: 30.7765\n",
      "Epoch 127/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 644.8410 - mae: 19.5241 - val_loss: 644.5351 - val_mae: 17.7721\n",
      "Epoch 128/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 642.3762 - mae: 19.4286 - val_loss: 532.1288 - val_mae: 18.6798\n",
      "Epoch 129/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 616.9174 - mae: 18.3155 - val_loss: 684.6717 - val_mae: 18.9734\n",
      "Epoch 130/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 671.3519 - mae: 19.6995 - val_loss: 621.0536 - val_mae: 17.0049\n",
      "Epoch 131/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 635.3112 - mae: 18.8890 - val_loss: 571.8006 - val_mae: 17.6276\n",
      "Epoch 132/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 622.1342 - mae: 18.8519 - val_loss: 642.4748 - val_mae: 20.9683\n",
      "Epoch 133/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 616.7834 - mae: 18.5606 - val_loss: 1070.0203 - val_mae: 29.0282\n",
      "Epoch 134/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 625.3732 - mae: 18.6963 - val_loss: 470.6086 - val_mae: 15.0250\n",
      "Epoch 135/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 651.1953 - mae: 19.4672 - val_loss: 572.8041 - val_mae: 17.5052\n",
      "Epoch 136/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 618.3569 - mae: 18.8015 - val_loss: 659.7793 - val_mae: 18.1911\n",
      "Epoch 137/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 637.1700 - mae: 19.2259 - val_loss: 547.8665 - val_mae: 16.4928\n",
      "Epoch 138/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 662.7668 - mae: 19.3027 - val_loss: 476.1439 - val_mae: 16.8857\n",
      "Epoch 139/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 607.3724 - mae: 18.3387 - val_loss: 793.1244 - val_mae: 23.6052\n",
      "Epoch 140/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 617.5748 - mae: 18.7295 - val_loss: 569.0262 - val_mae: 18.7697\n",
      "Epoch 141/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 615.5244 - mae: 18.7823 - val_loss: 526.9127 - val_mae: 17.3248\n",
      "Epoch 142/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 610.5114 - mae: 18.8068 - val_loss: 725.0042 - val_mae: 20.5113\n",
      "Epoch 143/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 615.4550 - mae: 18.7999 - val_loss: 580.9673 - val_mae: 18.0341\n",
      "Epoch 144/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 625.1011 - mae: 18.7538 - val_loss: 1033.8462 - val_mae: 24.2566\n",
      "Epoch 145/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 606.9229 - mae: 18.3797 - val_loss: 487.2569 - val_mae: 15.2168\n",
      "Epoch 146/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 605.6240 - mae: 18.5639 - val_loss: 696.4640 - val_mae: 18.7400\n",
      "Epoch 147/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 609.1414 - mae: 18.6129 - val_loss: 705.4694 - val_mae: 19.6224\n",
      "Epoch 148/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 621.9758 - mae: 19.0376 - val_loss: 537.3622 - val_mae: 15.6806\n",
      "Epoch 149/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 623.2195 - mae: 18.8288 - val_loss: 657.4747 - val_mae: 21.5588\n",
      "Epoch 150/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 590.3198 - mae: 18.2716 - val_loss: 495.9206 - val_mae: 17.7770\n",
      "Epoch 151/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 607.9935 - mae: 18.5961 - val_loss: 712.2704 - val_mae: 23.2802\n",
      "Epoch 152/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 614.6925 - mae: 18.8745 - val_loss: 543.5839 - val_mae: 18.2237\n",
      "Epoch 153/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 604.3962 - mae: 18.5560 - val_loss: 962.2543 - val_mae: 24.7503\n",
      "Epoch 154/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 598.5179 - mae: 18.5085 - val_loss: 502.5966 - val_mae: 18.1849\n",
      "Epoch 155/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 617.9818 - mae: 18.8058 - val_loss: 598.2428 - val_mae: 18.6988\n",
      "Epoch 156/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 598.6826 - mae: 18.4707 - val_loss: 561.1843 - val_mae: 19.5384\n",
      "Epoch 157/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 620.8939 - mae: 19.0509 - val_loss: 508.1323 - val_mae: 15.3146\n",
      "Epoch 158/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 605.1066 - mae: 18.4040 - val_loss: 470.9637 - val_mae: 16.4718\n",
      "Epoch 159/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 577.1872 - mae: 18.0723 - val_loss: 619.4879 - val_mae: 20.4540\n",
      "Epoch 160/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 594.7271 - mae: 18.5410 - val_loss: 427.4972 - val_mae: 14.2661\n",
      "Epoch 161/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 599.1498 - mae: 18.4239 - val_loss: 568.9610 - val_mae: 19.2091\n",
      "Epoch 162/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 574.8312 - mae: 18.2817 - val_loss: 590.8597 - val_mae: 17.5053\n",
      "Epoch 163/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 602.5474 - mae: 18.5705 - val_loss: 438.4055 - val_mae: 14.7263\n",
      "Epoch 164/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 590.9003 - mae: 18.3799 - val_loss: 803.9163 - val_mae: 20.8039\n",
      "Epoch 165/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 588.8596 - mae: 18.4308 - val_loss: 743.7560 - val_mae: 20.9315\n",
      "Epoch 166/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 575.1708 - mae: 17.8886 - val_loss: 527.2427 - val_mae: 18.2390\n",
      "Epoch 167/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 594.0587 - mae: 18.2382 - val_loss: 1002.6649 - val_mae: 26.6101\n",
      "Epoch 168/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 573.9819 - mae: 18.1587 - val_loss: 1325.9886 - val_mae: 27.9603\n",
      "Epoch 169/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 592.5193 - mae: 18.2005 - val_loss: 469.8678 - val_mae: 16.3214\n",
      "Epoch 170/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 583.6777 - mae: 18.2733 - val_loss: 459.0603 - val_mae: 16.1711\n",
      "Epoch 171/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 596.6140 - mae: 18.3231 - val_loss: 493.6150 - val_mae: 17.4543\n",
      "Epoch 172/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 582.3848 - mae: 18.2370 - val_loss: 448.5577 - val_mae: 15.4187\n",
      "Epoch 173/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 578.0510 - mae: 17.9537 - val_loss: 755.5538 - val_mae: 20.6008\n",
      "Epoch 174/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 584.0422 - mae: 18.2590 - val_loss: 523.5627 - val_mae: 17.6904\n",
      "Epoch 175/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 600.6395 - mae: 18.5144 - val_loss: 981.7722 - val_mae: 27.4128\n",
      "Epoch 176/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 551.5516 - mae: 17.6217 - val_loss: 511.1572 - val_mae: 15.6872\n",
      "Epoch 177/2000\n",
      "65/65 [==============================] - 1s 11ms/step - loss: 566.3717 - mae: 17.8476 - val_loss: 522.1818 - val_mae: 18.3477\n",
      "Epoch 178/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 589.4678 - mae: 18.3184 - val_loss: 951.5887 - val_mae: 22.7076\n",
      "Epoch 179/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 555.1353 - mae: 17.7236 - val_loss: 877.0632 - val_mae: 22.3403\n",
      "Epoch 180/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 564.4014 - mae: 17.7479 - val_loss: 675.0125 - val_mae: 21.8545\n",
      "Epoch 181/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 589.5025 - mae: 18.2715 - val_loss: 469.5804 - val_mae: 15.6201\n",
      "Epoch 182/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 568.1011 - mae: 17.9177 - val_loss: 713.4756 - val_mae: 22.1707\n",
      "Epoch 183/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 549.3832 - mae: 17.5453 - val_loss: 741.3218 - val_mae: 22.7780\n",
      "Epoch 184/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 572.4559 - mae: 18.0479 - val_loss: 782.6873 - val_mae: 24.0699\n",
      "Epoch 185/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 568.9792 - mae: 17.8441 - val_loss: 1017.1250 - val_mae: 27.1905\n",
      "Epoch 186/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 571.1685 - mae: 18.0336 - val_loss: 571.7407 - val_mae: 17.4370\n",
      "Epoch 187/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 563.2312 - mae: 17.7968 - val_loss: 426.0876 - val_mae: 15.3137\n",
      "Epoch 188/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 551.0575 - mae: 17.4911 - val_loss: 605.1191 - val_mae: 18.2943\n",
      "Epoch 189/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 561.1027 - mae: 17.9085 - val_loss: 847.8067 - val_mae: 20.8726\n",
      "Epoch 190/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 554.5372 - mae: 17.5475 - val_loss: 1248.6669 - val_mae: 28.4227\n",
      "Epoch 191/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 558.7274 - mae: 17.7973 - val_loss: 699.2704 - val_mae: 22.5331\n",
      "Epoch 192/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 577.3900 - mae: 18.0127 - val_loss: 462.9041 - val_mae: 15.8012\n",
      "Epoch 193/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 537.5634 - mae: 17.5077 - val_loss: 413.9840 - val_mae: 14.6781\n",
      "Epoch 194/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 539.8768 - mae: 17.3243 - val_loss: 662.6537 - val_mae: 21.4462\n",
      "Epoch 195/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 559.3300 - mae: 17.7326 - val_loss: 477.2256 - val_mae: 15.1411\n",
      "Epoch 196/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 574.2475 - mae: 18.0332 - val_loss: 468.9345 - val_mae: 16.4404\n",
      "Epoch 197/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 519.9396 - mae: 17.1563 - val_loss: 536.2292 - val_mae: 15.6602\n",
      "Epoch 198/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 568.5545 - mae: 18.1006 - val_loss: 576.6294 - val_mae: 19.6032\n",
      "Epoch 199/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 547.3060 - mae: 17.6689 - val_loss: 506.4008 - val_mae: 17.5867\n",
      "Epoch 200/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 553.8007 - mae: 17.9685 - val_loss: 1318.2124 - val_mae: 32.7420\n",
      "Epoch 201/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 563.4581 - mae: 17.6257 - val_loss: 625.8786 - val_mae: 18.4911\n",
      "Epoch 202/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 552.7270 - mae: 17.6556 - val_loss: 510.7044 - val_mae: 15.9250\n",
      "Epoch 203/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 544.3510 - mae: 17.7548 - val_loss: 1038.0438 - val_mae: 24.2094\n",
      "Epoch 204/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 537.6815 - mae: 17.3297 - val_loss: 762.6722 - val_mae: 20.4827\n",
      "Epoch 205/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 530.1448 - mae: 17.3376 - val_loss: 488.8861 - val_mae: 18.0945\n",
      "Epoch 206/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 527.9465 - mae: 17.3553 - val_loss: 547.6072 - val_mae: 16.4651\n",
      "Epoch 207/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 522.4121 - mae: 17.3378 - val_loss: 415.9694 - val_mae: 15.5753\n",
      "Epoch 208/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 543.4169 - mae: 17.8288 - val_loss: 418.3286 - val_mae: 14.0122\n",
      "Epoch 209/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 509.7923 - mae: 16.9382 - val_loss: 581.3708 - val_mae: 18.8647\n",
      "Epoch 210/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 556.0739 - mae: 17.9799 - val_loss: 455.5359 - val_mae: 16.5577\n",
      "Epoch 211/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 525.9054 - mae: 17.2347 - val_loss: 1057.1299 - val_mae: 29.0376\n",
      "Epoch 212/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 532.4189 - mae: 17.2665 - val_loss: 885.2101 - val_mae: 26.4199\n",
      "Epoch 213/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 555.9935 - mae: 17.7822 - val_loss: 506.1353 - val_mae: 18.3876\n",
      "Epoch 214/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 518.9324 - mae: 17.0445 - val_loss: 562.1463 - val_mae: 19.4944\n",
      "Epoch 215/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 530.9416 - mae: 17.3698 - val_loss: 480.0612 - val_mae: 15.2737\n",
      "Epoch 216/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 537.6831 - mae: 17.6274 - val_loss: 615.6451 - val_mae: 21.3133\n",
      "Epoch 217/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 500.2737 - mae: 16.7071 - val_loss: 1363.6417 - val_mae: 29.7532\n",
      "Epoch 218/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 551.4171 - mae: 17.6828 - val_loss: 395.6012 - val_mae: 13.7434\n",
      "Epoch 219/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 510.5311 - mae: 16.9911 - val_loss: 650.6638 - val_mae: 21.1451\n",
      "Epoch 220/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 531.6944 - mae: 17.2387 - val_loss: 689.6958 - val_mae: 22.4138\n",
      "Epoch 221/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 512.2828 - mae: 17.0501 - val_loss: 643.4641 - val_mae: 20.2653\n",
      "Epoch 222/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 525.7998 - mae: 17.2379 - val_loss: 851.4555 - val_mae: 24.9903\n",
      "Epoch 223/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 512.0783 - mae: 17.1080 - val_loss: 1078.2727 - val_mae: 25.8218\n",
      "Epoch 224/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 511.6913 - mae: 16.7818 - val_loss: 664.1940 - val_mae: 18.3090\n",
      "Epoch 225/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 519.7783 - mae: 17.3579 - val_loss: 952.0370 - val_mae: 27.5948\n",
      "Epoch 226/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 515.8204 - mae: 16.9614 - val_loss: 399.4066 - val_mae: 14.0304\n",
      "Epoch 227/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 512.2267 - mae: 17.1807 - val_loss: 668.2432 - val_mae: 19.6059\n",
      "Epoch 228/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 478.8522 - mae: 16.3592 - val_loss: 676.3255 - val_mae: 19.9170\n",
      "Epoch 229/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 529.7872 - mae: 17.4445 - val_loss: 559.5070 - val_mae: 19.7638\n",
      "Epoch 230/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 496.2292 - mae: 16.5531 - val_loss: 556.8345 - val_mae: 16.8320\n",
      "Epoch 231/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 514.9893 - mae: 16.9988 - val_loss: 678.2462 - val_mae: 21.3604\n",
      "Epoch 232/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 504.5501 - mae: 16.9432 - val_loss: 398.8845 - val_mae: 13.6250\n",
      "Epoch 233/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 486.7888 - mae: 16.6971 - val_loss: 964.4753 - val_mae: 27.5384\n",
      "Epoch 234/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 542.6672 - mae: 17.6459 - val_loss: 411.4030 - val_mae: 15.4393\n",
      "Epoch 235/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 516.9290 - mae: 17.2486 - val_loss: 402.0017 - val_mae: 14.1843\n",
      "Epoch 236/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 511.6611 - mae: 16.9213 - val_loss: 524.9344 - val_mae: 18.6605\n",
      "Epoch 237/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 506.2747 - mae: 16.9445 - val_loss: 569.1255 - val_mae: 16.9850\n",
      "Epoch 238/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 488.1188 - mae: 16.6061 - val_loss: 420.3803 - val_mae: 15.5049\n",
      "Epoch 239/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 531.8632 - mae: 17.3374 - val_loss: 610.8409 - val_mae: 18.1854\n",
      "Epoch 240/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 493.2979 - mae: 16.6968 - val_loss: 567.2184 - val_mae: 17.8306\n",
      "Epoch 241/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 505.5099 - mae: 16.6374 - val_loss: 841.2106 - val_mae: 22.3352\n",
      "Epoch 242/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 513.0154 - mae: 17.1069 - val_loss: 383.2417 - val_mae: 13.6801\n",
      "Epoch 243/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 477.1334 - mae: 16.2807 - val_loss: 1152.2024 - val_mae: 31.3105\n",
      "Epoch 244/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 511.9141 - mae: 17.0195 - val_loss: 550.2234 - val_mae: 19.2720\n",
      "Epoch 245/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 501.3206 - mae: 16.9025 - val_loss: 609.8202 - val_mae: 18.6924\n",
      "Epoch 246/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 500.6629 - mae: 16.8244 - val_loss: 449.4239 - val_mae: 14.6437\n",
      "Epoch 247/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 505.9786 - mae: 16.7883 - val_loss: 1429.8948 - val_mae: 32.1459\n",
      "Epoch 248/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 502.1980 - mae: 16.7223 - val_loss: 459.5358 - val_mae: 17.3907\n",
      "Epoch 249/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 481.3946 - mae: 16.4213 - val_loss: 409.4316 - val_mae: 16.0607\n",
      "Epoch 250/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 489.1077 - mae: 16.8496 - val_loss: 388.0780 - val_mae: 14.7408\n",
      "Epoch 251/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 498.2082 - mae: 16.9116 - val_loss: 375.1896 - val_mae: 14.4317\n",
      "Epoch 252/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 486.4959 - mae: 16.5238 - val_loss: 418.2744 - val_mae: 16.0298\n",
      "Epoch 253/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 501.4091 - mae: 16.7489 - val_loss: 487.2344 - val_mae: 17.4258\n",
      "Epoch 254/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 478.3345 - mae: 16.5073 - val_loss: 351.0804 - val_mae: 13.5014\n",
      "Epoch 255/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 485.2088 - mae: 16.6546 - val_loss: 551.5566 - val_mae: 19.0307\n",
      "Epoch 256/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 488.5543 - mae: 16.4145 - val_loss: 366.9659 - val_mae: 14.4724\n",
      "Epoch 257/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 501.9737 - mae: 16.8701 - val_loss: 418.7234 - val_mae: 15.7248\n",
      "Epoch 258/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 482.0037 - mae: 16.5432 - val_loss: 376.4062 - val_mae: 14.8473\n",
      "Epoch 259/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 476.0898 - mae: 16.5555 - val_loss: 387.0309 - val_mae: 15.0473\n",
      "Epoch 260/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 461.4836 - mae: 16.1058 - val_loss: 424.2969 - val_mae: 15.5439\n",
      "Epoch 261/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 519.7751 - mae: 17.2210 - val_loss: 356.9694 - val_mae: 14.1060\n",
      "Epoch 262/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 472.5533 - mae: 16.2901 - val_loss: 427.0979 - val_mae: 16.5458\n",
      "Epoch 263/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 488.4014 - mae: 16.5668 - val_loss: 592.6264 - val_mae: 19.9187\n",
      "Epoch 264/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 482.2493 - mae: 16.5521 - val_loss: 555.2726 - val_mae: 19.8319\n",
      "Epoch 265/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 497.2751 - mae: 16.7532 - val_loss: 433.0572 - val_mae: 16.8490\n",
      "Epoch 266/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 484.7313 - mae: 16.6143 - val_loss: 758.8476 - val_mae: 23.6669\n",
      "Epoch 267/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 479.2137 - mae: 16.3587 - val_loss: 662.4943 - val_mae: 21.6494\n",
      "Epoch 268/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 476.5490 - mae: 16.5526 - val_loss: 562.8235 - val_mae: 17.1544\n",
      "Epoch 269/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 465.8510 - mae: 16.1650 - val_loss: 1257.3790 - val_mae: 27.7062\n",
      "Epoch 270/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 461.6237 - mae: 15.9844 - val_loss: 458.5411 - val_mae: 17.1334\n",
      "Epoch 271/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 468.2628 - mae: 16.0911 - val_loss: 735.2409 - val_mae: 23.7906\n",
      "Epoch 272/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 491.5562 - mae: 16.8200 - val_loss: 406.5230 - val_mae: 15.9781\n",
      "Epoch 273/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 453.5616 - mae: 15.9951 - val_loss: 349.4233 - val_mae: 14.1232\n",
      "Epoch 274/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 463.4233 - mae: 16.2583 - val_loss: 352.3898 - val_mae: 13.6721\n",
      "Epoch 275/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 479.0650 - mae: 16.4551 - val_loss: 450.8065 - val_mae: 15.0776\n",
      "Epoch 276/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 458.7167 - mae: 16.2506 - val_loss: 434.7707 - val_mae: 16.0922\n",
      "Epoch 277/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 472.0175 - mae: 16.3064 - val_loss: 450.9237 - val_mae: 17.1768\n",
      "Epoch 278/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 477.7386 - mae: 16.2115 - val_loss: 363.0060 - val_mae: 12.9025\n",
      "Epoch 279/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 461.5970 - mae: 16.0371 - val_loss: 432.2180 - val_mae: 16.8854\n",
      "Epoch 280/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 476.0941 - mae: 16.6350 - val_loss: 455.1235 - val_mae: 16.3884\n",
      "Epoch 281/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 456.8182 - mae: 16.1109 - val_loss: 428.1146 - val_mae: 14.2151\n",
      "Epoch 282/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 463.2470 - mae: 16.2042 - val_loss: 343.4971 - val_mae: 12.8871\n",
      "Epoch 283/2000\n",
      "65/65 [==============================] - 1s 11ms/step - loss: 453.1421 - mae: 15.7514 - val_loss: 446.8349 - val_mae: 16.7604\n",
      "Epoch 284/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 462.6086 - mae: 16.0558 - val_loss: 615.4018 - val_mae: 20.7026\n",
      "Epoch 285/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 460.2259 - mae: 16.1623 - val_loss: 493.2806 - val_mae: 18.1819\n",
      "Epoch 286/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 440.6544 - mae: 15.7910 - val_loss: 640.3796 - val_mae: 19.7033\n",
      "Epoch 287/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 460.0480 - mae: 15.9889 - val_loss: 387.6654 - val_mae: 14.5399\n",
      "Epoch 288/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 458.1882 - mae: 15.9427 - val_loss: 316.7006 - val_mae: 12.7534\n",
      "Epoch 289/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 446.1206 - mae: 15.7304 - val_loss: 562.3019 - val_mae: 19.7429\n",
      "Epoch 290/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 456.0390 - mae: 16.2199 - val_loss: 544.2228 - val_mae: 18.8813\n",
      "Epoch 291/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 466.5156 - mae: 16.2403 - val_loss: 334.0706 - val_mae: 12.5978\n",
      "Epoch 292/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 438.9446 - mae: 15.4410 - val_loss: 439.1128 - val_mae: 16.2539\n",
      "Epoch 293/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 455.7748 - mae: 16.2152 - val_loss: 418.0846 - val_mae: 14.2860\n",
      "Epoch 294/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 457.4127 - mae: 16.0481 - val_loss: 431.6078 - val_mae: 16.5712\n",
      "Epoch 295/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 450.1555 - mae: 15.9411 - val_loss: 342.3286 - val_mae: 13.3011\n",
      "Epoch 296/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 433.9806 - mae: 15.5769 - val_loss: 596.3832 - val_mae: 19.8458\n",
      "Epoch 297/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 453.9966 - mae: 16.1531 - val_loss: 505.7610 - val_mae: 16.2239\n",
      "Epoch 298/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 454.5839 - mae: 16.0093 - val_loss: 489.3222 - val_mae: 16.5660\n",
      "Epoch 299/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 449.0483 - mae: 16.0777 - val_loss: 323.6075 - val_mae: 12.8161\n",
      "Epoch 300/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 434.1614 - mae: 15.5288 - val_loss: 385.3638 - val_mae: 15.5044\n",
      "Epoch 301/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 456.6853 - mae: 16.0637 - val_loss: 422.0501 - val_mae: 15.1575\n",
      "Epoch 302/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 427.8655 - mae: 15.5468 - val_loss: 826.0139 - val_mae: 23.4596\n",
      "Epoch 303/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 444.8626 - mae: 15.9705 - val_loss: 727.5333 - val_mae: 21.0199\n",
      "Epoch 304/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 430.6056 - mae: 15.4641 - val_loss: 599.8400 - val_mae: 19.1781\n",
      "Epoch 305/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 459.9010 - mae: 16.2506 - val_loss: 510.5172 - val_mae: 15.8833\n",
      "Epoch 306/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 437.0710 - mae: 15.6791 - val_loss: 724.3018 - val_mae: 19.9141\n",
      "Epoch 307/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 435.2440 - mae: 15.4420 - val_loss: 468.4417 - val_mae: 15.7583\n",
      "Epoch 308/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 442.2755 - mae: 16.0252 - val_loss: 636.6650 - val_mae: 19.5014\n",
      "Epoch 309/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 431.0617 - mae: 15.6827 - val_loss: 407.7196 - val_mae: 14.8940\n",
      "Epoch 310/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 438.2335 - mae: 15.8227 - val_loss: 357.2456 - val_mae: 13.8500\n",
      "Epoch 311/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 448.2037 - mae: 15.9435 - val_loss: 624.1363 - val_mae: 18.2305\n",
      "Epoch 312/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 438.7194 - mae: 15.7160 - val_loss: 352.8556 - val_mae: 13.0682\n",
      "Epoch 313/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 425.6768 - mae: 15.6134 - val_loss: 417.9642 - val_mae: 14.3106\n",
      "Epoch 314/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 432.9266 - mae: 15.5907 - val_loss: 494.7004 - val_mae: 16.6751\n",
      "Epoch 315/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 440.5455 - mae: 15.7456 - val_loss: 446.2851 - val_mae: 16.3767\n",
      "Epoch 316/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 430.6917 - mae: 15.7600 - val_loss: 749.2704 - val_mae: 24.2569\n",
      "Epoch 317/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 425.2166 - mae: 15.6142 - val_loss: 423.7400 - val_mae: 16.4435\n",
      "Epoch 318/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 431.4682 - mae: 15.9637 - val_loss: 399.3897 - val_mae: 14.5700\n",
      "Epoch 319/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 429.9224 - mae: 15.5477 - val_loss: 422.6895 - val_mae: 15.0656\n",
      "Epoch 320/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 423.3024 - mae: 15.5065 - val_loss: 366.4263 - val_mae: 13.6171\n",
      "Epoch 321/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 443.4517 - mae: 15.9213 - val_loss: 373.0043 - val_mae: 13.9802\n",
      "Epoch 322/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 424.7081 - mae: 15.3805 - val_loss: 485.9708 - val_mae: 16.0746\n",
      "Epoch 323/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 416.5038 - mae: 15.4185 - val_loss: 645.7107 - val_mae: 18.7392\n",
      "Epoch 324/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 420.0598 - mae: 15.3020 - val_loss: 484.9742 - val_mae: 17.4710\n",
      "Epoch 325/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 421.6597 - mae: 15.4336 - val_loss: 505.7044 - val_mae: 18.7717\n",
      "Epoch 326/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 434.9329 - mae: 15.5627 - val_loss: 322.3480 - val_mae: 13.5258\n",
      "Epoch 327/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 433.7772 - mae: 15.8784 - val_loss: 357.7660 - val_mae: 13.9752\n",
      "Epoch 328/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 411.6784 - mae: 15.2632 - val_loss: 366.4380 - val_mae: 14.9047\n",
      "Epoch 329/2000\n",
      "65/65 [==============================] - 1s 11ms/step - loss: 434.7657 - mae: 15.6619 - val_loss: 355.4182 - val_mae: 14.4076\n",
      "Epoch 330/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 417.0065 - mae: 15.2552 - val_loss: 672.1147 - val_mae: 21.5304\n",
      "Epoch 331/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 416.4061 - mae: 15.3821 - val_loss: 735.4467 - val_mae: 23.9090\n",
      "Epoch 332/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 418.9500 - mae: 15.2378 - val_loss: 472.5912 - val_mae: 16.6691\n",
      "Epoch 333/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 424.4284 - mae: 15.5895 - val_loss: 342.0352 - val_mae: 13.8118\n",
      "Epoch 334/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 424.8284 - mae: 15.6710 - val_loss: 695.3004 - val_mae: 20.3659\n",
      "Epoch 335/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 416.5868 - mae: 15.3680 - val_loss: 502.2303 - val_mae: 18.5160\n",
      "Epoch 336/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 418.0930 - mae: 15.3259 - val_loss: 448.2283 - val_mae: 17.6624\n",
      "Epoch 337/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 412.3347 - mae: 15.3401 - val_loss: 422.3992 - val_mae: 16.7847\n",
      "Epoch 338/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 420.7657 - mae: 15.4000 - val_loss: 328.0129 - val_mae: 13.4801\n",
      "Epoch 339/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 402.8349 - mae: 15.1174 - val_loss: 298.0667 - val_mae: 12.3072\n",
      "Epoch 340/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 407.8856 - mae: 15.2604 - val_loss: 521.5184 - val_mae: 18.7527\n",
      "Epoch 341/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 403.4354 - mae: 15.1723 - val_loss: 344.8496 - val_mae: 13.8450\n",
      "Epoch 342/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 408.1910 - mae: 15.1411 - val_loss: 560.8348 - val_mae: 20.4628\n",
      "Epoch 343/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 403.9493 - mae: 15.0557 - val_loss: 658.5616 - val_mae: 22.4697\n",
      "Epoch 344/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 404.5191 - mae: 15.2408 - val_loss: 501.0906 - val_mae: 18.9028\n",
      "Epoch 345/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 423.9140 - mae: 15.5762 - val_loss: 381.5578 - val_mae: 13.9489\n",
      "Epoch 346/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 423.2025 - mae: 15.5625 - val_loss: 309.4851 - val_mae: 12.8927\n",
      "Epoch 347/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 388.9193 - mae: 14.8458 - val_loss: 541.1326 - val_mae: 17.6557\n",
      "Epoch 348/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 414.6640 - mae: 15.3363 - val_loss: 318.5660 - val_mae: 13.4393\n",
      "Epoch 349/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 392.7823 - mae: 15.0285 - val_loss: 630.6031 - val_mae: 21.6212\n",
      "Epoch 350/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 393.5197 - mae: 14.8970 - val_loss: 411.9640 - val_mae: 15.2837\n",
      "Epoch 351/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 416.1144 - mae: 15.5051 - val_loss: 371.3331 - val_mae: 13.4903\n",
      "Epoch 352/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 407.9316 - mae: 15.1429 - val_loss: 307.1816 - val_mae: 12.9516\n",
      "Epoch 353/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 394.4303 - mae: 14.8362 - val_loss: 368.4369 - val_mae: 14.9141\n",
      "Epoch 354/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 400.1432 - mae: 15.2429 - val_loss: 422.8741 - val_mae: 15.1640\n",
      "Epoch 355/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 390.6464 - mae: 14.8549 - val_loss: 337.4923 - val_mae: 13.7782\n",
      "Epoch 356/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 393.3408 - mae: 15.0854 - val_loss: 286.4936 - val_mae: 12.8632\n",
      "Epoch 357/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 383.9661 - mae: 14.9461 - val_loss: 293.9669 - val_mae: 12.9980\n",
      "Epoch 358/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 393.4577 - mae: 15.0193 - val_loss: 320.4166 - val_mae: 12.8790\n",
      "Epoch 359/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 408.1494 - mae: 15.1619 - val_loss: 278.6156 - val_mae: 12.1957\n",
      "Epoch 360/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 393.4364 - mae: 14.9608 - val_loss: 428.6839 - val_mae: 15.0827\n",
      "Epoch 361/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 400.4979 - mae: 14.9780 - val_loss: 508.7440 - val_mae: 17.0041\n",
      "Epoch 362/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 393.9179 - mae: 14.9850 - val_loss: 673.6120 - val_mae: 20.5048\n",
      "Epoch 363/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 387.1720 - mae: 14.8475 - val_loss: 300.9873 - val_mae: 13.0226\n",
      "Epoch 364/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 413.3859 - mae: 15.4005 - val_loss: 369.1967 - val_mae: 15.1339\n",
      "Epoch 365/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 380.0161 - mae: 14.5990 - val_loss: 527.1171 - val_mae: 19.0804\n",
      "Epoch 366/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 391.0066 - mae: 15.0359 - val_loss: 308.9152 - val_mae: 13.1650\n",
      "Epoch 367/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 388.3886 - mae: 14.8743 - val_loss: 511.4891 - val_mae: 19.2350\n",
      "Epoch 368/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 392.0391 - mae: 15.0415 - val_loss: 290.1118 - val_mae: 12.0891\n",
      "Epoch 369/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 407.0790 - mae: 15.3641 - val_loss: 381.3600 - val_mae: 14.4145\n",
      "Epoch 370/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 379.8672 - mae: 14.7770 - val_loss: 386.8850 - val_mae: 14.3609\n",
      "Epoch 371/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 387.3551 - mae: 14.7847 - val_loss: 374.7019 - val_mae: 14.2605\n",
      "Epoch 372/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 387.3397 - mae: 14.7739 - val_loss: 337.1040 - val_mae: 13.4070\n",
      "Epoch 373/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 392.0371 - mae: 15.0672 - val_loss: 414.0992 - val_mae: 16.3331\n",
      "Epoch 374/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 388.5228 - mae: 14.8246 - val_loss: 328.6445 - val_mae: 13.9041\n",
      "Epoch 375/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 369.4012 - mae: 14.5175 - val_loss: 311.9909 - val_mae: 13.7272\n",
      "Epoch 376/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 377.9744 - mae: 14.6409 - val_loss: 413.5599 - val_mae: 16.6144\n",
      "Epoch 377/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 384.9084 - mae: 14.7983 - val_loss: 308.3847 - val_mae: 12.3835\n",
      "Epoch 378/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 378.7863 - mae: 14.8161 - val_loss: 345.5784 - val_mae: 13.3728\n",
      "Epoch 379/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 374.7132 - mae: 14.6878 - val_loss: 305.1988 - val_mae: 12.3466\n",
      "Epoch 380/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 389.7425 - mae: 14.8991 - val_loss: 539.5026 - val_mae: 17.9763\n",
      "Epoch 381/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 401.3368 - mae: 15.2130 - val_loss: 504.3203 - val_mae: 17.3539\n",
      "Epoch 382/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 394.3517 - mae: 14.9724 - val_loss: 689.0383 - val_mae: 21.3786\n",
      "Epoch 383/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 378.9340 - mae: 14.5923 - val_loss: 436.9602 - val_mae: 15.9400\n",
      "Epoch 384/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 383.3879 - mae: 14.6946 - val_loss: 410.8677 - val_mae: 16.1267\n",
      "Epoch 385/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 372.6372 - mae: 14.5998 - val_loss: 828.6649 - val_mae: 22.5580\n",
      "Epoch 386/2000\n",
      "65/65 [==============================] - 1s 11ms/step - loss: 385.4485 - mae: 14.8184 - val_loss: 344.8178 - val_mae: 13.5860\n",
      "Epoch 387/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 377.6284 - mae: 14.6687 - val_loss: 276.6180 - val_mae: 11.9790\n",
      "Epoch 388/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 363.5425 - mae: 14.3190 - val_loss: 492.8373 - val_mae: 18.7417\n",
      "Epoch 389/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 390.6935 - mae: 15.0857 - val_loss: 298.6995 - val_mae: 12.4460\n",
      "Epoch 390/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 370.7921 - mae: 14.4142 - val_loss: 384.4108 - val_mae: 15.9724\n",
      "Epoch 391/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 374.4042 - mae: 14.7456 - val_loss: 278.0162 - val_mae: 12.0270\n",
      "Epoch 392/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 381.4149 - mae: 14.7493 - val_loss: 477.2582 - val_mae: 18.3921\n",
      "Epoch 393/2000\n",
      "65/65 [==============================] - 1s 12ms/step - loss: 382.9637 - mae: 14.9413 - val_loss: 385.7165 - val_mae: 14.5575\n",
      "Epoch 394/2000\n",
      "65/65 [==============================] - 1s 16ms/step - loss: 363.9144 - mae: 14.3979 - val_loss: 421.1419 - val_mae: 14.9023\n",
      "Epoch 395/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 372.8745 - mae: 14.6130 - val_loss: 297.2797 - val_mae: 12.1122\n",
      "Epoch 396/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 378.5978 - mae: 14.7479 - val_loss: 324.7883 - val_mae: 12.8600\n",
      "Epoch 397/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 370.2471 - mae: 14.5930 - val_loss: 360.6819 - val_mae: 15.0844\n",
      "Epoch 398/2000\n",
      "65/65 [==============================] - 1s 19ms/step - loss: 373.0591 - mae: 14.7246 - val_loss: 324.1598 - val_mae: 12.8900\n",
      "Epoch 399/2000\n",
      "65/65 [==============================] - 1s 12ms/step - loss: 353.3451 - mae: 14.1192 - val_loss: 286.2416 - val_mae: 12.6697\n",
      "Epoch 400/2000\n",
      "65/65 [==============================] - 1s 11ms/step - loss: 375.0659 - mae: 14.8144 - val_loss: 291.1435 - val_mae: 12.2189\n",
      "Epoch 401/2000\n",
      "65/65 [==============================] - 1s 11ms/step - loss: 366.3217 - mae: 14.5625 - val_loss: 314.5209 - val_mae: 14.0981\n",
      "Epoch 402/2000\n",
      "65/65 [==============================] - 1s 11ms/step - loss: 357.2065 - mae: 14.2988 - val_loss: 1015.0267 - val_mae: 27.1609\n",
      "Epoch 403/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 378.2426 - mae: 14.6160 - val_loss: 252.8123 - val_mae: 11.6221\n",
      "Epoch 404/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 360.6998 - mae: 14.3686 - val_loss: 534.6953 - val_mae: 17.7349\n",
      "Epoch 405/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 362.8702 - mae: 14.4765 - val_loss: 439.4044 - val_mae: 15.4307\n",
      "Epoch 406/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 370.1452 - mae: 14.3875 - val_loss: 744.8478 - val_mae: 22.5303\n",
      "Epoch 407/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 368.0390 - mae: 14.5449 - val_loss: 311.0522 - val_mae: 13.7358\n",
      "Epoch 408/2000\n",
      "65/65 [==============================] - 1s 11ms/step - loss: 370.5845 - mae: 14.7196 - val_loss: 448.3011 - val_mae: 15.7372\n",
      "Epoch 409/2000\n",
      "65/65 [==============================] - 1s 11ms/step - loss: 358.2113 - mae: 14.2291 - val_loss: 391.5376 - val_mae: 14.3752\n",
      "Epoch 410/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 345.7277 - mae: 14.0585 - val_loss: 369.3022 - val_mae: 15.2581\n",
      "Epoch 411/2000\n",
      "65/65 [==============================] - 1s 11ms/step - loss: 366.4314 - mae: 14.5014 - val_loss: 409.0595 - val_mae: 16.4502\n",
      "Epoch 412/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 371.8496 - mae: 14.4995 - val_loss: 361.5965 - val_mae: 15.0721\n",
      "Epoch 413/2000\n",
      "65/65 [==============================] - 1s 12ms/step - loss: 356.7065 - mae: 14.2672 - val_loss: 437.4852 - val_mae: 17.1445\n",
      "Epoch 414/2000\n",
      "65/65 [==============================] - 1s 13ms/step - loss: 359.0892 - mae: 14.2485 - val_loss: 631.0422 - val_mae: 19.6889\n",
      "Epoch 415/2000\n",
      "65/65 [==============================] - 1s 11ms/step - loss: 375.1040 - mae: 14.6925 - val_loss: 284.2766 - val_mae: 12.9936\n",
      "Epoch 416/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 353.7826 - mae: 14.2476 - val_loss: 376.9277 - val_mae: 15.2537\n",
      "Epoch 417/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 368.7469 - mae: 14.6578 - val_loss: 337.9794 - val_mae: 14.6738\n",
      "Epoch 418/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 350.5504 - mae: 14.0503 - val_loss: 493.1389 - val_mae: 17.6993\n",
      "Epoch 419/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 366.0164 - mae: 14.4672 - val_loss: 285.7797 - val_mae: 12.8390\n",
      "Epoch 420/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 364.8062 - mae: 14.6422 - val_loss: 287.7129 - val_mae: 12.4344\n",
      "Epoch 421/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 353.5981 - mae: 14.0826 - val_loss: 321.7177 - val_mae: 13.8158\n",
      "Epoch 422/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 371.3805 - mae: 14.7052 - val_loss: 646.1696 - val_mae: 22.0569\n",
      "Epoch 423/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 356.3929 - mae: 14.3057 - val_loss: 269.3137 - val_mae: 12.5635\n",
      "Epoch 424/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 344.0239 - mae: 14.0252 - val_loss: 543.0105 - val_mae: 18.8521\n",
      "Epoch 425/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 363.6002 - mae: 14.3946 - val_loss: 383.3748 - val_mae: 15.4107\n",
      "Epoch 426/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 341.8725 - mae: 13.9115 - val_loss: 321.0883 - val_mae: 14.2983\n",
      "Epoch 427/2000\n",
      "65/65 [==============================] - 1s 12ms/step - loss: 359.3224 - mae: 14.2845 - val_loss: 321.2991 - val_mae: 14.4233\n",
      "Epoch 428/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 362.3237 - mae: 14.3880 - val_loss: 323.1369 - val_mae: 12.9760\n",
      "Epoch 429/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 350.0521 - mae: 14.2794 - val_loss: 371.7804 - val_mae: 15.3574\n",
      "Epoch 430/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 347.6841 - mae: 14.0931 - val_loss: 395.8566 - val_mae: 14.5713\n",
      "Epoch 431/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 337.1225 - mae: 13.6957 - val_loss: 521.3884 - val_mae: 18.1084\n",
      "Epoch 432/2000\n",
      "65/65 [==============================] - 1s 12ms/step - loss: 353.8886 - mae: 14.3425 - val_loss: 354.8320 - val_mae: 15.5306\n",
      "Epoch 433/2000\n",
      "65/65 [==============================] - 1s 13ms/step - loss: 344.8402 - mae: 14.1261 - val_loss: 365.2977 - val_mae: 14.0534\n",
      "Epoch 434/2000\n",
      "65/65 [==============================] - 1s 11ms/step - loss: 339.2563 - mae: 13.8603 - val_loss: 346.9659 - val_mae: 14.9976\n",
      "Epoch 435/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 360.2004 - mae: 14.4549 - val_loss: 283.1738 - val_mae: 12.7312\n",
      "Epoch 436/2000\n",
      "65/65 [==============================] - 1s 13ms/step - loss: 332.5388 - mae: 13.7871 - val_loss: 322.5572 - val_mae: 13.4394\n",
      "Epoch 437/2000\n",
      "65/65 [==============================] - 1s 12ms/step - loss: 356.2215 - mae: 14.4071 - val_loss: 380.5352 - val_mae: 15.4554\n",
      "Epoch 438/2000\n",
      "65/65 [==============================] - 1s 11ms/step - loss: 347.7518 - mae: 14.1297 - val_loss: 441.8663 - val_mae: 16.1346\n",
      "Epoch 439/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 330.6374 - mae: 13.7416 - val_loss: 288.7531 - val_mae: 12.7146\n",
      "Epoch 440/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 329.0681 - mae: 13.8074 - val_loss: 433.9325 - val_mae: 16.7659\n",
      "Epoch 441/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 337.9343 - mae: 14.0832 - val_loss: 388.3535 - val_mae: 16.1172\n",
      "Epoch 442/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 348.0590 - mae: 14.1526 - val_loss: 433.9499 - val_mae: 16.9932\n",
      "Epoch 443/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 344.0003 - mae: 14.0883 - val_loss: 851.4567 - val_mae: 24.0971\n",
      "Epoch 444/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 340.0243 - mae: 13.8931 - val_loss: 575.7991 - val_mae: 19.3970\n",
      "Epoch 445/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 336.8685 - mae: 13.8851 - val_loss: 386.9353 - val_mae: 15.5301\n",
      "Epoch 446/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 335.8986 - mae: 13.9471 - val_loss: 330.0540 - val_mae: 13.2803\n",
      "Epoch 447/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 331.4181 - mae: 13.9069 - val_loss: 257.5789 - val_mae: 11.6398\n",
      "Epoch 448/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 343.0695 - mae: 14.0635 - val_loss: 290.8878 - val_mae: 12.4151\n",
      "Epoch 449/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 329.1453 - mae: 13.5028 - val_loss: 619.5283 - val_mae: 19.1423\n",
      "Epoch 450/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 342.9609 - mae: 14.2239 - val_loss: 271.8871 - val_mae: 12.4725\n",
      "Epoch 451/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 336.8152 - mae: 13.8123 - val_loss: 534.5767 - val_mae: 18.4741\n",
      "Epoch 452/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 331.1658 - mae: 13.7934 - val_loss: 296.2960 - val_mae: 13.4756\n",
      "Epoch 453/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 326.4587 - mae: 13.6685 - val_loss: 703.1252 - val_mae: 22.8557\n",
      "Epoch 454/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 329.5768 - mae: 13.7459 - val_loss: 398.8579 - val_mae: 16.4167\n",
      "Epoch 455/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 320.6080 - mae: 13.5909 - val_loss: 318.6672 - val_mae: 13.5633\n",
      "Epoch 456/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 323.3559 - mae: 13.7527 - val_loss: 319.6760 - val_mae: 13.0138\n",
      "Epoch 457/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 334.7004 - mae: 14.0507 - val_loss: 328.9629 - val_mae: 14.3892\n",
      "Epoch 458/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 342.7092 - mae: 14.2123 - val_loss: 344.4751 - val_mae: 15.1752\n",
      "Epoch 459/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 329.7913 - mae: 13.7229 - val_loss: 247.9932 - val_mae: 12.1181\n",
      "Epoch 460/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 320.0638 - mae: 13.5997 - val_loss: 345.8091 - val_mae: 14.7338\n",
      "Epoch 461/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 332.6579 - mae: 13.8568 - val_loss: 258.7247 - val_mae: 12.0426\n",
      "Epoch 462/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 323.9148 - mae: 13.6782 - val_loss: 265.1413 - val_mae: 12.4279\n",
      "Epoch 463/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 318.2706 - mae: 13.5885 - val_loss: 333.2984 - val_mae: 14.5850\n",
      "Epoch 464/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 324.2280 - mae: 13.6739 - val_loss: 412.7399 - val_mae: 15.1694\n",
      "Epoch 465/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 324.1639 - mae: 13.5739 - val_loss: 264.3780 - val_mae: 12.4342\n",
      "Epoch 466/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 323.5379 - mae: 13.5997 - val_loss: 293.4037 - val_mae: 12.6301\n",
      "Epoch 467/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 329.5479 - mae: 13.8095 - val_loss: 253.5367 - val_mae: 12.0195\n",
      "Epoch 468/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 317.9750 - mae: 13.5227 - val_loss: 273.6390 - val_mae: 12.8101\n",
      "Epoch 469/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 313.3974 - mae: 13.4435 - val_loss: 380.4716 - val_mae: 14.7643\n",
      "Epoch 470/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 324.4945 - mae: 13.8217 - val_loss: 239.2222 - val_mae: 11.4762\n",
      "Epoch 471/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 313.3424 - mae: 13.4068 - val_loss: 381.0464 - val_mae: 15.0892\n",
      "Epoch 472/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 323.7238 - mae: 13.5806 - val_loss: 293.5289 - val_mae: 12.5744\n",
      "Epoch 473/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 323.2266 - mae: 13.4989 - val_loss: 505.0207 - val_mae: 17.1034\n",
      "Epoch 474/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 308.2382 - mae: 13.3110 - val_loss: 341.9366 - val_mae: 14.3904\n",
      "Epoch 475/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 322.4933 - mae: 13.6971 - val_loss: 251.6105 - val_mae: 12.0431\n",
      "Epoch 476/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 327.2602 - mae: 13.7533 - val_loss: 314.6602 - val_mae: 13.1285\n",
      "Epoch 477/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 319.5533 - mae: 13.6430 - val_loss: 227.6901 - val_mae: 11.0048\n",
      "Epoch 478/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 302.3990 - mae: 13.1393 - val_loss: 501.0118 - val_mae: 17.8715\n",
      "Epoch 479/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 317.9360 - mae: 13.6856 - val_loss: 226.3361 - val_mae: 11.1094\n",
      "Epoch 480/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 310.9275 - mae: 13.4455 - val_loss: 571.2906 - val_mae: 19.6815\n",
      "Epoch 481/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 320.7216 - mae: 13.6728 - val_loss: 257.6234 - val_mae: 11.7329\n",
      "Epoch 482/2000\n",
      "65/65 [==============================] - 1s 11ms/step - loss: 306.9470 - mae: 13.3534 - val_loss: 483.1794 - val_mae: 17.7477\n",
      "Epoch 483/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 326.1057 - mae: 13.7730 - val_loss: 308.4763 - val_mae: 13.6668\n",
      "Epoch 484/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 299.2573 - mae: 13.2772 - val_loss: 419.9662 - val_mae: 16.8826\n",
      "Epoch 485/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 311.0464 - mae: 13.5690 - val_loss: 213.9745 - val_mae: 10.9818\n",
      "Epoch 486/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 310.3654 - mae: 13.3805 - val_loss: 405.9356 - val_mae: 15.5717\n",
      "Epoch 487/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 326.6906 - mae: 13.9294 - val_loss: 297.8838 - val_mae: 13.4114\n",
      "Epoch 488/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 295.1983 - mae: 13.1206 - val_loss: 335.0642 - val_mae: 14.1774\n",
      "Epoch 489/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 318.8756 - mae: 13.6480 - val_loss: 295.0879 - val_mae: 12.8976\n",
      "Epoch 490/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 303.1372 - mae: 13.1775 - val_loss: 232.1866 - val_mae: 11.1750\n",
      "Epoch 491/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 299.4149 - mae: 13.1833 - val_loss: 236.4419 - val_mae: 11.4761\n",
      "Epoch 492/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 313.7538 - mae: 13.4749 - val_loss: 296.4238 - val_mae: 13.0987\n",
      "Epoch 493/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 297.2759 - mae: 13.2488 - val_loss: 257.1119 - val_mae: 12.0453\n",
      "Epoch 494/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 305.5981 - mae: 13.4097 - val_loss: 220.6606 - val_mae: 11.2668\n",
      "Epoch 495/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 308.4408 - mae: 13.4040 - val_loss: 237.3741 - val_mae: 11.4880\n",
      "Epoch 496/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 313.4555 - mae: 13.4706 - val_loss: 237.5801 - val_mae: 11.8047\n",
      "Epoch 497/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 297.4265 - mae: 13.3138 - val_loss: 206.1107 - val_mae: 10.5749\n",
      "Epoch 498/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 317.5312 - mae: 13.7339 - val_loss: 477.3396 - val_mae: 17.1617\n",
      "Epoch 499/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 302.9434 - mae: 13.1654 - val_loss: 342.1321 - val_mae: 14.4158\n",
      "Epoch 500/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 305.5753 - mae: 13.1425 - val_loss: 291.2582 - val_mae: 12.6520\n",
      "Epoch 501/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 308.7143 - mae: 13.3983 - val_loss: 264.5069 - val_mae: 12.7870\n",
      "Epoch 502/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 296.6348 - mae: 13.0737 - val_loss: 474.5454 - val_mae: 17.8238\n",
      "Epoch 503/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 315.7271 - mae: 13.5084 - val_loss: 190.4029 - val_mae: 10.1463\n",
      "Epoch 504/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 297.3131 - mae: 13.0667 - val_loss: 475.9758 - val_mae: 18.3451\n",
      "Epoch 505/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 297.8905 - mae: 13.2858 - val_loss: 391.7463 - val_mae: 15.9581\n",
      "Epoch 506/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 304.2783 - mae: 13.2396 - val_loss: 365.6133 - val_mae: 15.1357\n",
      "Epoch 507/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 288.5133 - mae: 12.9297 - val_loss: 308.9797 - val_mae: 14.3524\n",
      "Epoch 508/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 304.8542 - mae: 13.3478 - val_loss: 257.3626 - val_mae: 12.7459\n",
      "Epoch 509/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 296.8531 - mae: 13.3377 - val_loss: 233.7282 - val_mae: 11.7169\n",
      "Epoch 510/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 293.5589 - mae: 13.1062 - val_loss: 239.9553 - val_mae: 11.8331\n",
      "Epoch 511/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 289.9749 - mae: 13.0241 - val_loss: 414.5380 - val_mae: 17.2066\n",
      "Epoch 512/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 296.6953 - mae: 13.1946 - val_loss: 359.0858 - val_mae: 15.0163\n",
      "Epoch 513/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 292.0696 - mae: 13.1096 - val_loss: 225.0129 - val_mae: 11.6443\n",
      "Epoch 514/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 307.9151 - mae: 13.3998 - val_loss: 280.1372 - val_mae: 13.0703\n",
      "Epoch 515/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 289.2837 - mae: 13.0156 - val_loss: 364.0229 - val_mae: 14.8619\n",
      "Epoch 516/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 282.8502 - mae: 12.9917 - val_loss: 251.2786 - val_mae: 11.6593\n",
      "Epoch 517/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 306.0614 - mae: 13.1418 - val_loss: 254.2646 - val_mae: 12.6725\n",
      "Epoch 518/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 296.4073 - mae: 13.2037 - val_loss: 206.6934 - val_mae: 10.9023\n",
      "Epoch 519/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 292.5134 - mae: 13.1106 - val_loss: 211.4784 - val_mae: 10.6178\n",
      "Epoch 520/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 278.9712 - mae: 12.6924 - val_loss: 317.1834 - val_mae: 13.7663\n",
      "Epoch 521/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 292.2007 - mae: 12.9264 - val_loss: 277.6756 - val_mae: 12.1203\n",
      "Epoch 522/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 283.0117 - mae: 12.8178 - val_loss: 399.8108 - val_mae: 16.4698\n",
      "Epoch 523/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 284.4756 - mae: 12.8293 - val_loss: 397.6658 - val_mae: 15.3635\n",
      "Epoch 524/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 282.4805 - mae: 12.7721 - val_loss: 220.8924 - val_mae: 11.4228\n",
      "Epoch 525/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 283.6421 - mae: 12.9365 - val_loss: 505.8566 - val_mae: 18.7262\n",
      "Epoch 526/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 289.2578 - mae: 13.0932 - val_loss: 212.8044 - val_mae: 10.6391\n",
      "Epoch 527/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 281.6492 - mae: 12.7394 - val_loss: 449.7299 - val_mae: 16.8598\n",
      "Epoch 528/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 298.6371 - mae: 13.1065 - val_loss: 287.7666 - val_mae: 12.7730\n",
      "Epoch 529/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 292.6500 - mae: 13.1187 - val_loss: 349.3139 - val_mae: 14.5466\n",
      "Epoch 530/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 287.9725 - mae: 13.1085 - val_loss: 189.0081 - val_mae: 9.9524\n",
      "Epoch 531/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 282.1815 - mae: 12.8981 - val_loss: 269.2650 - val_mae: 12.3510\n",
      "Epoch 532/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 282.5299 - mae: 12.8365 - val_loss: 292.8308 - val_mae: 13.4438\n",
      "Epoch 533/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 285.1274 - mae: 12.9014 - val_loss: 243.6430 - val_mae: 11.6113\n",
      "Epoch 534/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 275.8964 - mae: 12.7823 - val_loss: 221.6160 - val_mae: 11.3295\n",
      "Epoch 535/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 280.0208 - mae: 12.7227 - val_loss: 756.9080 - val_mae: 22.9994\n",
      "Epoch 536/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 277.8604 - mae: 12.6912 - val_loss: 313.3745 - val_mae: 14.4508\n",
      "Epoch 537/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 279.3279 - mae: 12.9009 - val_loss: 385.4574 - val_mae: 16.8689\n",
      "Epoch 538/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 276.2330 - mae: 12.8798 - val_loss: 567.9124 - val_mae: 20.6666\n",
      "Epoch 539/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 281.2432 - mae: 12.8304 - val_loss: 409.2086 - val_mae: 16.3140\n",
      "Epoch 540/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 280.0277 - mae: 12.9252 - val_loss: 217.0684 - val_mae: 11.1828\n",
      "Epoch 541/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 278.3942 - mae: 12.8203 - val_loss: 204.7571 - val_mae: 10.4555\n",
      "Epoch 542/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 273.4107 - mae: 12.6422 - val_loss: 377.3790 - val_mae: 15.7925\n",
      "Epoch 543/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 284.2156 - mae: 12.9289 - val_loss: 345.4820 - val_mae: 14.6960\n",
      "Epoch 544/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 273.2786 - mae: 12.6630 - val_loss: 215.1193 - val_mae: 11.2739\n",
      "Epoch 545/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 279.2147 - mae: 12.8431 - val_loss: 298.0104 - val_mae: 13.6210\n",
      "Epoch 546/2000\n",
      "65/65 [==============================] - 1s 11ms/step - loss: 264.3795 - mae: 12.5838 - val_loss: 212.9423 - val_mae: 11.0048\n",
      "Epoch 547/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 274.9037 - mae: 12.9051 - val_loss: 283.0745 - val_mae: 13.9063\n",
      "Epoch 548/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 285.2883 - mae: 12.9959 - val_loss: 231.8329 - val_mae: 11.9539\n",
      "Epoch 549/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 266.0700 - mae: 12.3610 - val_loss: 251.6938 - val_mae: 12.6160\n",
      "Epoch 550/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 281.4553 - mae: 12.8842 - val_loss: 183.8727 - val_mae: 10.0243\n",
      "Epoch 551/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 273.1833 - mae: 12.5577 - val_loss: 206.6304 - val_mae: 11.1553\n",
      "Epoch 552/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 275.6086 - mae: 12.7562 - val_loss: 243.0012 - val_mae: 12.4285\n",
      "Epoch 553/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 258.6960 - mae: 12.2576 - val_loss: 202.5403 - val_mae: 10.4604\n",
      "Epoch 554/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 274.7502 - mae: 12.7029 - val_loss: 232.2928 - val_mae: 12.0253\n",
      "Epoch 555/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 253.1994 - mae: 12.0818 - val_loss: 524.2568 - val_mae: 19.2754\n",
      "Epoch 556/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 276.8219 - mae: 12.8485 - val_loss: 418.4159 - val_mae: 17.1864\n",
      "Epoch 557/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 264.6932 - mae: 12.4408 - val_loss: 524.4112 - val_mae: 19.3661\n",
      "Epoch 558/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 271.3041 - mae: 12.5308 - val_loss: 351.4860 - val_mae: 15.2468\n",
      "Epoch 559/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 271.9789 - mae: 12.5746 - val_loss: 327.2201 - val_mae: 14.0377\n",
      "Epoch 560/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 262.6489 - mae: 12.5986 - val_loss: 196.9791 - val_mae: 10.5945\n",
      "Epoch 561/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 270.2844 - mae: 12.4747 - val_loss: 214.2111 - val_mae: 11.3180\n",
      "Epoch 562/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 258.5132 - mae: 12.2539 - val_loss: 210.5804 - val_mae: 11.1203\n",
      "Epoch 563/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 257.7318 - mae: 12.2692 - val_loss: 233.9736 - val_mae: 11.7820\n",
      "Epoch 564/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 266.3394 - mae: 12.3962 - val_loss: 249.5344 - val_mae: 12.1153\n",
      "Epoch 565/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 269.5751 - mae: 12.4891 - val_loss: 283.2819 - val_mae: 12.6327\n",
      "Epoch 566/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 260.5495 - mae: 12.2634 - val_loss: 323.3204 - val_mae: 14.9639\n",
      "Epoch 567/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 260.3711 - mae: 12.4237 - val_loss: 285.5963 - val_mae: 13.3908\n",
      "Epoch 568/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 266.7158 - mae: 12.5247 - val_loss: 237.1385 - val_mae: 12.0214\n",
      "Epoch 569/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 262.3844 - mae: 12.5462 - val_loss: 225.8835 - val_mae: 11.0930\n",
      "Epoch 570/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 256.5880 - mae: 12.0927 - val_loss: 659.3943 - val_mae: 21.8808\n",
      "Epoch 571/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 265.6743 - mae: 12.5504 - val_loss: 236.4172 - val_mae: 12.0368\n",
      "Epoch 572/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 256.0626 - mae: 12.3925 - val_loss: 474.6392 - val_mae: 17.8129\n",
      "Epoch 573/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 276.5935 - mae: 12.6956 - val_loss: 357.0343 - val_mae: 15.6316\n",
      "Epoch 574/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 256.8744 - mae: 12.3005 - val_loss: 263.9491 - val_mae: 13.1734\n",
      "Epoch 575/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 245.6225 - mae: 11.9267 - val_loss: 204.8773 - val_mae: 11.0266\n",
      "Epoch 576/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 267.1435 - mae: 12.6175 - val_loss: 330.5889 - val_mae: 14.7423\n",
      "Epoch 577/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 259.3499 - mae: 12.4162 - val_loss: 190.2090 - val_mae: 10.3933\n",
      "Epoch 578/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 263.3470 - mae: 12.3627 - val_loss: 554.6748 - val_mae: 20.0536\n",
      "Epoch 579/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 257.2077 - mae: 12.2626 - val_loss: 599.8943 - val_mae: 20.4493\n",
      "Epoch 580/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 249.6494 - mae: 12.0646 - val_loss: 194.1337 - val_mae: 10.6247\n",
      "Epoch 581/2000\n",
      "65/65 [==============================] - 1s 13ms/step - loss: 256.7849 - mae: 12.5011 - val_loss: 235.5045 - val_mae: 12.0324\n",
      "Epoch 582/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 261.9684 - mae: 12.4607 - val_loss: 380.8207 - val_mae: 15.4882\n",
      "Epoch 583/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 249.7704 - mae: 12.1613 - val_loss: 391.2541 - val_mae: 16.6302\n",
      "Epoch 584/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 258.0025 - mae: 12.3084 - val_loss: 202.3916 - val_mae: 10.7779\n",
      "Epoch 585/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 248.9088 - mae: 12.0371 - val_loss: 220.1219 - val_mae: 11.3257\n",
      "Epoch 586/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 255.2447 - mae: 12.2628 - val_loss: 573.0004 - val_mae: 19.4322\n",
      "Epoch 587/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 245.2470 - mae: 11.9955 - val_loss: 450.3279 - val_mae: 17.1026\n",
      "Epoch 588/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 251.9606 - mae: 12.2310 - val_loss: 503.3818 - val_mae: 19.2643\n",
      "Epoch 589/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 254.9377 - mae: 12.2672 - val_loss: 256.4114 - val_mae: 12.7312\n",
      "Epoch 590/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 247.5650 - mae: 12.2022 - val_loss: 184.9957 - val_mae: 10.4002\n",
      "Epoch 591/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 250.1051 - mae: 12.1663 - val_loss: 213.3170 - val_mae: 11.1061\n",
      "Epoch 592/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 247.4717 - mae: 12.0780 - val_loss: 350.9681 - val_mae: 15.6218\n",
      "Epoch 593/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 250.6963 - mae: 12.0602 - val_loss: 163.4452 - val_mae: 9.5750\n",
      "Epoch 594/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 254.4026 - mae: 12.1645 - val_loss: 193.3089 - val_mae: 10.4665\n",
      "Epoch 595/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 245.8479 - mae: 12.1130 - val_loss: 164.7693 - val_mae: 9.6514\n",
      "Epoch 596/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 249.2619 - mae: 12.0839 - val_loss: 383.3655 - val_mae: 15.6643\n",
      "Epoch 597/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 254.1065 - mae: 12.0924 - val_loss: 372.5275 - val_mae: 16.3938\n",
      "Epoch 598/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 243.8984 - mae: 12.1118 - val_loss: 216.1142 - val_mae: 11.6022\n",
      "Epoch 599/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 248.2109 - mae: 12.1087 - val_loss: 239.7846 - val_mae: 11.7731\n",
      "Epoch 600/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 245.9161 - mae: 12.0591 - val_loss: 285.2294 - val_mae: 13.3440\n",
      "Epoch 601/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 235.4128 - mae: 11.7134 - val_loss: 178.2667 - val_mae: 10.2413\n",
      "Epoch 602/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 241.6012 - mae: 12.0016 - val_loss: 189.1444 - val_mae: 10.1069\n",
      "Epoch 603/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 248.2691 - mae: 12.2787 - val_loss: 231.5097 - val_mae: 12.2068\n",
      "Epoch 604/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 238.9274 - mae: 12.0100 - val_loss: 187.3664 - val_mae: 10.1892\n",
      "Epoch 605/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 248.0372 - mae: 12.1835 - val_loss: 277.7733 - val_mae: 12.9802\n",
      "Epoch 606/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 233.1822 - mae: 11.7503 - val_loss: 230.4893 - val_mae: 11.6691\n",
      "Epoch 607/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 234.3533 - mae: 11.7597 - val_loss: 578.5609 - val_mae: 19.7993\n",
      "Epoch 608/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 241.4514 - mae: 11.8609 - val_loss: 387.5931 - val_mae: 16.1814\n",
      "Epoch 609/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 249.9261 - mae: 12.1987 - val_loss: 181.5647 - val_mae: 10.3483\n",
      "Epoch 610/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 228.7889 - mae: 11.6800 - val_loss: 273.5078 - val_mae: 13.2774\n",
      "Epoch 611/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 235.6973 - mae: 11.7464 - val_loss: 290.1617 - val_mae: 13.8526\n",
      "Epoch 612/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 243.5285 - mae: 12.0967 - val_loss: 230.4910 - val_mae: 11.7003\n",
      "Epoch 613/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 231.4930 - mae: 11.7239 - val_loss: 598.0656 - val_mae: 20.9043\n",
      "Epoch 614/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 244.3061 - mae: 11.9450 - val_loss: 195.2347 - val_mae: 10.3650\n",
      "Epoch 615/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 234.4384 - mae: 11.7598 - val_loss: 238.7983 - val_mae: 11.4721\n",
      "Epoch 616/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 236.1711 - mae: 11.9085 - val_loss: 293.6996 - val_mae: 13.7791\n",
      "Epoch 617/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 247.1341 - mae: 12.1838 - val_loss: 175.1492 - val_mae: 10.2319\n",
      "Epoch 618/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 238.5130 - mae: 11.7933 - val_loss: 336.0579 - val_mae: 14.7870\n",
      "Epoch 619/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 235.2762 - mae: 12.0110 - val_loss: 266.7731 - val_mae: 12.5799\n",
      "Epoch 620/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 232.5613 - mae: 11.7525 - val_loss: 321.4154 - val_mae: 14.0910\n",
      "Epoch 621/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 230.8205 - mae: 11.6566 - val_loss: 366.1914 - val_mae: 15.6982\n",
      "Epoch 622/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 228.6658 - mae: 11.6095 - val_loss: 300.6456 - val_mae: 13.9837\n",
      "Epoch 623/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 244.7500 - mae: 12.1518 - val_loss: 406.4920 - val_mae: 17.2137\n",
      "Epoch 624/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 234.3477 - mae: 11.7108 - val_loss: 256.4287 - val_mae: 12.3662\n",
      "Epoch 625/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 233.0043 - mae: 11.6629 - val_loss: 184.5695 - val_mae: 10.4241\n",
      "Epoch 626/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 230.0065 - mae: 11.5929 - val_loss: 285.3384 - val_mae: 13.2899\n",
      "Epoch 627/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 226.1845 - mae: 11.5466 - val_loss: 531.6780 - val_mae: 19.4266\n",
      "Epoch 628/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 229.6566 - mae: 11.7172 - val_loss: 235.8066 - val_mae: 12.1886\n",
      "Epoch 629/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 236.3358 - mae: 11.9646 - val_loss: 183.3051 - val_mae: 10.7856\n",
      "Epoch 630/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 224.6333 - mae: 11.5330 - val_loss: 298.1685 - val_mae: 14.0486\n",
      "Epoch 631/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 235.9350 - mae: 11.9981 - val_loss: 234.1767 - val_mae: 11.8532\n",
      "Epoch 632/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 234.6836 - mae: 11.8065 - val_loss: 163.3176 - val_mae: 9.5130\n",
      "Epoch 633/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 223.3983 - mae: 11.5028 - val_loss: 250.2686 - val_mae: 12.6644\n",
      "Epoch 634/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 234.6270 - mae: 11.8176 - val_loss: 196.0406 - val_mae: 10.8292\n",
      "Epoch 635/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 227.4657 - mae: 11.6790 - val_loss: 192.6068 - val_mae: 10.5751\n",
      "Epoch 636/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 218.9268 - mae: 11.4398 - val_loss: 441.2644 - val_mae: 17.5296\n",
      "Epoch 637/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 233.4619 - mae: 11.8405 - val_loss: 189.1409 - val_mae: 10.4889\n",
      "Epoch 638/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 222.7772 - mae: 11.4875 - val_loss: 186.9943 - val_mae: 10.5047\n",
      "Epoch 639/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 226.3574 - mae: 11.6055 - val_loss: 262.6378 - val_mae: 12.6536\n",
      "Epoch 640/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 227.2126 - mae: 11.6449 - val_loss: 302.0797 - val_mae: 13.7525\n",
      "Epoch 641/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 220.1285 - mae: 11.4783 - val_loss: 646.6744 - val_mae: 21.4638\n",
      "Epoch 642/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 222.8580 - mae: 11.4715 - val_loss: 219.0459 - val_mae: 11.7481\n",
      "Epoch 643/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 228.1745 - mae: 11.6421 - val_loss: 383.4604 - val_mae: 15.3915\n",
      "Epoch 644/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 222.4048 - mae: 11.4872 - val_loss: 224.8284 - val_mae: 11.8436\n",
      "Epoch 645/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 211.4393 - mae: 11.1692 - val_loss: 458.2416 - val_mae: 18.2200\n",
      "Epoch 646/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 221.7534 - mae: 11.5630 - val_loss: 225.9563 - val_mae: 11.7508\n",
      "Epoch 647/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 232.5853 - mae: 11.8518 - val_loss: 189.0363 - val_mae: 10.4819\n",
      "Epoch 648/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 216.5652 - mae: 11.3392 - val_loss: 263.3967 - val_mae: 12.4932\n",
      "Epoch 649/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 221.3132 - mae: 11.5780 - val_loss: 406.4720 - val_mae: 16.4849\n",
      "Epoch 650/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 226.6861 - mae: 11.6283 - val_loss: 175.0863 - val_mae: 10.1020\n",
      "Epoch 651/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 221.9217 - mae: 11.4915 - val_loss: 167.3612 - val_mae: 9.9853\n",
      "Epoch 652/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 212.8215 - mae: 11.2387 - val_loss: 241.2216 - val_mae: 11.6670\n",
      "Epoch 653/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 220.4405 - mae: 11.4225 - val_loss: 152.8622 - val_mae: 9.4522\n",
      "Epoch 654/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 220.2496 - mae: 11.5519 - val_loss: 161.9588 - val_mae: 9.8711\n",
      "Epoch 655/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 216.0893 - mae: 11.3098 - val_loss: 177.4972 - val_mae: 9.8707\n",
      "Epoch 656/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 216.9574 - mae: 11.4210 - val_loss: 139.0916 - val_mae: 8.6468\n",
      "Epoch 657/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 211.4064 - mae: 11.3054 - val_loss: 197.8146 - val_mae: 10.8889\n",
      "Epoch 658/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 210.8359 - mae: 11.2245 - val_loss: 270.7541 - val_mae: 12.9373\n",
      "Epoch 659/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 214.4978 - mae: 11.2477 - val_loss: 306.2624 - val_mae: 13.9848\n",
      "Epoch 660/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 223.3020 - mae: 11.5025 - val_loss: 172.5004 - val_mae: 10.0825\n",
      "Epoch 661/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 218.2318 - mae: 11.3729 - val_loss: 163.7322 - val_mae: 9.7906\n",
      "Epoch 662/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 209.5061 - mae: 11.2342 - val_loss: 186.5094 - val_mae: 10.7524\n",
      "Epoch 663/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 213.0660 - mae: 11.3825 - val_loss: 410.0947 - val_mae: 16.8620\n",
      "Epoch 664/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 224.0019 - mae: 11.6064 - val_loss: 135.0098 - val_mae: 8.4740\n",
      "Epoch 665/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 210.6716 - mae: 11.0117 - val_loss: 149.6629 - val_mae: 9.2473\n",
      "Epoch 666/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 214.4971 - mae: 11.3427 - val_loss: 182.9702 - val_mae: 10.5864\n",
      "Epoch 667/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 211.5047 - mae: 11.2307 - val_loss: 233.2956 - val_mae: 11.5539\n",
      "Epoch 668/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 216.7070 - mae: 11.2377 - val_loss: 179.6146 - val_mae: 10.5352\n",
      "Epoch 669/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 202.9581 - mae: 11.0507 - val_loss: 205.1648 - val_mae: 11.2975\n",
      "Epoch 670/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 221.7772 - mae: 11.3372 - val_loss: 284.4019 - val_mae: 13.7538\n",
      "Epoch 671/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 209.6161 - mae: 11.1084 - val_loss: 125.6967 - val_mae: 8.2950\n",
      "Epoch 672/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 207.6787 - mae: 11.0060 - val_loss: 312.1835 - val_mae: 14.6806\n",
      "Epoch 673/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 217.7821 - mae: 11.4326 - val_loss: 133.1432 - val_mae: 8.5795\n",
      "Epoch 674/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 208.1480 - mae: 11.1818 - val_loss: 480.0582 - val_mae: 18.1339\n",
      "Epoch 675/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 215.2975 - mae: 11.4581 - val_loss: 123.7255 - val_mae: 8.1953\n",
      "Epoch 676/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 215.8058 - mae: 11.2399 - val_loss: 185.0749 - val_mae: 10.6695\n",
      "Epoch 677/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 207.8915 - mae: 11.2051 - val_loss: 218.0278 - val_mae: 11.2485\n",
      "Epoch 678/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 216.9074 - mae: 11.4667 - val_loss: 175.8160 - val_mae: 10.3390\n",
      "Epoch 679/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 197.0506 - mae: 10.8961 - val_loss: 132.5897 - val_mae: 8.6669\n",
      "Epoch 680/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 203.2800 - mae: 10.9246 - val_loss: 169.4218 - val_mae: 9.7946\n",
      "Epoch 681/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 207.7662 - mae: 11.2462 - val_loss: 248.2643 - val_mae: 12.4019\n",
      "Epoch 682/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 212.3190 - mae: 11.3054 - val_loss: 221.8250 - val_mae: 11.6029\n",
      "Epoch 683/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 197.2915 - mae: 10.8107 - val_loss: 387.8241 - val_mae: 16.7814\n",
      "Epoch 684/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 202.7669 - mae: 10.9467 - val_loss: 180.8215 - val_mae: 10.5144\n",
      "Epoch 685/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 204.0019 - mae: 11.1043 - val_loss: 286.3126 - val_mae: 13.8274\n",
      "Epoch 686/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 200.6253 - mae: 11.0133 - val_loss: 178.3814 - val_mae: 10.2543\n",
      "Epoch 687/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 196.3827 - mae: 10.7640 - val_loss: 217.2290 - val_mae: 11.4976\n",
      "Epoch 688/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 204.4379 - mae: 11.0504 - val_loss: 158.8240 - val_mae: 9.9734\n",
      "Epoch 689/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 205.9242 - mae: 11.1484 - val_loss: 192.5436 - val_mae: 10.7577\n",
      "Epoch 690/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 201.8850 - mae: 11.0310 - val_loss: 154.8967 - val_mae: 9.3685\n",
      "Epoch 691/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 202.0725 - mae: 11.0925 - val_loss: 191.6424 - val_mae: 10.6164\n",
      "Epoch 692/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 204.3814 - mae: 11.1379 - val_loss: 224.9668 - val_mae: 12.0195\n",
      "Epoch 693/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 199.2328 - mae: 10.8987 - val_loss: 130.5716 - val_mae: 8.6015\n",
      "Epoch 694/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 200.0546 - mae: 10.8210 - val_loss: 283.1622 - val_mae: 13.3218\n",
      "Epoch 695/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 203.0471 - mae: 11.1356 - val_loss: 281.9702 - val_mae: 13.0912\n",
      "Epoch 696/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 200.6205 - mae: 10.9258 - val_loss: 235.7619 - val_mae: 12.7334\n",
      "Epoch 697/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 204.1835 - mae: 11.0537 - val_loss: 171.3633 - val_mae: 10.0767\n",
      "Epoch 698/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 198.5864 - mae: 10.8199 - val_loss: 171.7965 - val_mae: 10.0848\n",
      "Epoch 699/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 198.5732 - mae: 11.0740 - val_loss: 282.8709 - val_mae: 13.5672\n",
      "Epoch 700/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 204.2554 - mae: 11.1606 - val_loss: 153.8708 - val_mae: 9.4743\n",
      "Epoch 701/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 199.5654 - mae: 10.9696 - val_loss: 155.0971 - val_mae: 9.3327\n",
      "Epoch 702/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 197.4233 - mae: 10.8518 - val_loss: 231.2152 - val_mae: 11.9244\n",
      "Epoch 703/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 197.7025 - mae: 10.9438 - val_loss: 170.1435 - val_mae: 9.8451\n",
      "Epoch 704/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 196.1018 - mae: 10.8510 - val_loss: 130.6915 - val_mae: 8.6101\n",
      "Epoch 705/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 190.2142 - mae: 10.7847 - val_loss: 209.3601 - val_mae: 11.2715\n",
      "Epoch 706/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 205.2794 - mae: 11.1368 - val_loss: 322.4707 - val_mae: 15.0501\n",
      "Epoch 707/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 205.3094 - mae: 10.9908 - val_loss: 253.4186 - val_mae: 13.1801\n",
      "Epoch 708/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 192.5437 - mae: 10.7445 - val_loss: 155.3898 - val_mae: 9.4697\n",
      "Epoch 709/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 196.0030 - mae: 10.8141 - val_loss: 156.3203 - val_mae: 9.4933\n",
      "Epoch 710/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 195.9677 - mae: 10.7864 - val_loss: 131.0878 - val_mae: 8.5354\n",
      "Epoch 711/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 190.3631 - mae: 10.7591 - val_loss: 320.9229 - val_mae: 14.6379\n",
      "Epoch 712/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 187.0616 - mae: 10.5741 - val_loss: 191.7432 - val_mae: 10.9811\n",
      "Epoch 713/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 199.3478 - mae: 10.9096 - val_loss: 162.8241 - val_mae: 10.1249\n",
      "Epoch 714/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 197.6819 - mae: 11.0248 - val_loss: 178.5383 - val_mae: 10.6376\n",
      "Epoch 715/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 200.1668 - mae: 11.1012 - val_loss: 222.1481 - val_mae: 12.0694\n",
      "Epoch 716/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 192.8824 - mae: 11.0022 - val_loss: 296.5627 - val_mae: 14.8297\n",
      "Epoch 717/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 192.9835 - mae: 10.9198 - val_loss: 122.9097 - val_mae: 8.3141\n",
      "Epoch 718/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 183.6200 - mae: 10.5210 - val_loss: 197.4903 - val_mae: 11.1712\n",
      "Epoch 719/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 185.4760 - mae: 10.4761 - val_loss: 169.9220 - val_mae: 10.1358\n",
      "Epoch 720/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 193.2911 - mae: 10.9580 - val_loss: 146.6999 - val_mae: 9.1275\n",
      "Epoch 721/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 195.4103 - mae: 10.8343 - val_loss: 194.3436 - val_mae: 11.0449\n",
      "Epoch 722/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 194.8000 - mae: 10.8002 - val_loss: 439.7390 - val_mae: 17.8712\n",
      "Epoch 723/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 194.8882 - mae: 10.8940 - val_loss: 161.7095 - val_mae: 9.7349\n",
      "Epoch 724/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 185.9651 - mae: 10.5540 - val_loss: 202.1916 - val_mae: 11.3723\n",
      "Epoch 725/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 188.1118 - mae: 10.7024 - val_loss: 156.4738 - val_mae: 9.7117\n",
      "Epoch 726/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 177.9297 - mae: 10.3142 - val_loss: 193.1881 - val_mae: 10.7956\n",
      "Epoch 727/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 183.8442 - mae: 10.5621 - val_loss: 217.4660 - val_mae: 12.0079\n",
      "Epoch 728/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 188.6892 - mae: 10.7926 - val_loss: 159.9663 - val_mae: 9.5875\n",
      "Epoch 729/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 180.7110 - mae: 10.3947 - val_loss: 111.9635 - val_mae: 7.8223\n",
      "Epoch 730/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 190.6037 - mae: 10.6909 - val_loss: 137.7852 - val_mae: 8.9530\n",
      "Epoch 731/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 191.3588 - mae: 10.6889 - val_loss: 246.7140 - val_mae: 12.3050\n",
      "Epoch 732/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 183.2949 - mae: 10.4454 - val_loss: 120.7484 - val_mae: 8.1455\n",
      "Epoch 733/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 193.6289 - mae: 10.9323 - val_loss: 157.5586 - val_mae: 9.7419\n",
      "Epoch 734/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 191.3033 - mae: 10.5909 - val_loss: 316.7584 - val_mae: 14.5829\n",
      "Epoch 735/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 180.2273 - mae: 10.4755 - val_loss: 139.5842 - val_mae: 9.3338\n",
      "Epoch 736/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 178.2574 - mae: 10.4420 - val_loss: 278.7637 - val_mae: 13.1321\n",
      "Epoch 737/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 189.2022 - mae: 10.6293 - val_loss: 230.2159 - val_mae: 12.0395\n",
      "Epoch 738/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 187.8421 - mae: 10.8010 - val_loss: 126.4428 - val_mae: 8.5784\n",
      "Epoch 739/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 186.4518 - mae: 10.5158 - val_loss: 159.8537 - val_mae: 9.8913\n",
      "Epoch 740/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 183.9779 - mae: 10.4534 - val_loss: 136.9843 - val_mae: 8.8260\n",
      "Epoch 741/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 185.0548 - mae: 10.5896 - val_loss: 124.2194 - val_mae: 8.4741\n",
      "Epoch 742/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 179.3534 - mae: 10.3275 - val_loss: 207.4396 - val_mae: 11.8126\n",
      "Epoch 743/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 182.3854 - mae: 10.5830 - val_loss: 176.4695 - val_mae: 10.4489\n",
      "Epoch 744/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 185.9264 - mae: 10.4528 - val_loss: 287.7804 - val_mae: 13.5001\n",
      "Epoch 745/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 179.8657 - mae: 10.3525 - val_loss: 180.1989 - val_mae: 10.2555\n",
      "Epoch 746/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 174.8018 - mae: 10.2191 - val_loss: 236.9686 - val_mae: 12.6166\n",
      "Epoch 747/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 187.2946 - mae: 10.7533 - val_loss: 129.4416 - val_mae: 8.7525\n",
      "Epoch 748/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 182.5659 - mae: 10.5020 - val_loss: 266.6306 - val_mae: 13.1404\n",
      "Epoch 749/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 180.5828 - mae: 10.4459 - val_loss: 176.2830 - val_mae: 10.7896\n",
      "Epoch 750/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 175.5335 - mae: 10.3362 - val_loss: 115.5028 - val_mae: 7.9982\n",
      "Epoch 751/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 175.7617 - mae: 10.3402 - val_loss: 135.9978 - val_mae: 9.0027\n",
      "Epoch 752/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 178.8611 - mae: 10.3752 - val_loss: 160.1232 - val_mae: 9.7819\n",
      "Epoch 753/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 184.7919 - mae: 10.4861 - val_loss: 153.2663 - val_mae: 9.3491\n",
      "Epoch 754/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 177.1099 - mae: 10.4219 - val_loss: 225.4819 - val_mae: 11.7302\n",
      "Epoch 755/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 176.5057 - mae: 10.2950 - val_loss: 469.0569 - val_mae: 18.6349\n",
      "Epoch 756/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 183.4011 - mae: 10.4872 - val_loss: 157.4644 - val_mae: 9.7151\n",
      "Epoch 757/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 174.6895 - mae: 10.2688 - val_loss: 147.4078 - val_mae: 9.5130\n",
      "Epoch 758/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 177.1681 - mae: 10.3302 - val_loss: 104.3002 - val_mae: 7.5917\n",
      "Epoch 759/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 174.7386 - mae: 10.2685 - val_loss: 212.8399 - val_mae: 11.6615\n",
      "Epoch 760/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 188.5155 - mae: 10.7330 - val_loss: 114.0079 - val_mae: 8.0822\n",
      "Epoch 761/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 169.7754 - mae: 10.2027 - val_loss: 262.4202 - val_mae: 13.2551\n",
      "Epoch 762/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 174.1875 - mae: 10.4323 - val_loss: 296.5663 - val_mae: 13.9825\n",
      "Epoch 763/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 174.3746 - mae: 10.3159 - val_loss: 193.8548 - val_mae: 10.9294\n",
      "Epoch 764/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 186.3622 - mae: 10.7238 - val_loss: 108.0542 - val_mae: 7.7591\n",
      "Epoch 765/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 172.5564 - mae: 10.0533 - val_loss: 123.5355 - val_mae: 8.2281\n",
      "Epoch 766/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 170.2527 - mae: 10.1953 - val_loss: 281.4054 - val_mae: 13.5707\n",
      "Epoch 767/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 173.4760 - mae: 10.1358 - val_loss: 539.9788 - val_mae: 19.2791\n",
      "Epoch 768/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 179.6419 - mae: 10.3575 - val_loss: 163.9071 - val_mae: 9.7933\n",
      "Epoch 769/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 171.1584 - mae: 10.2172 - val_loss: 129.2835 - val_mae: 8.7081\n",
      "Epoch 770/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 181.2699 - mae: 10.5996 - val_loss: 127.6594 - val_mae: 8.5534\n",
      "Epoch 771/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 170.9941 - mae: 10.1665 - val_loss: 171.3070 - val_mae: 10.1995\n",
      "Epoch 772/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 171.9271 - mae: 10.1566 - val_loss: 110.1856 - val_mae: 7.8727\n",
      "Epoch 773/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 178.7695 - mae: 10.4880 - val_loss: 205.9122 - val_mae: 11.1447\n",
      "Epoch 774/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 175.9464 - mae: 10.2886 - val_loss: 256.2663 - val_mae: 12.6373\n",
      "Epoch 775/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 169.5383 - mae: 10.1096 - val_loss: 151.5071 - val_mae: 9.6752\n",
      "Epoch 776/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 162.6419 - mae: 9.9250 - val_loss: 101.2803 - val_mae: 7.5190\n",
      "Epoch 777/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 173.4697 - mae: 10.2756 - val_loss: 226.5946 - val_mae: 12.2168\n",
      "Epoch 778/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 173.6196 - mae: 10.2432 - val_loss: 173.4643 - val_mae: 10.1721\n",
      "Epoch 779/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 163.1013 - mae: 9.9239 - val_loss: 204.2165 - val_mae: 11.2984\n",
      "Epoch 780/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 173.6690 - mae: 10.3059 - val_loss: 115.5790 - val_mae: 8.2644\n",
      "Epoch 781/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 166.7425 - mae: 10.0248 - val_loss: 226.5315 - val_mae: 12.5801\n",
      "Epoch 782/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 166.6014 - mae: 10.0136 - val_loss: 115.3267 - val_mae: 8.0110\n",
      "Epoch 783/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 165.9841 - mae: 9.9883 - val_loss: 194.1322 - val_mae: 10.7558\n",
      "Epoch 784/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 177.9865 - mae: 10.5156 - val_loss: 301.1957 - val_mae: 14.9542\n",
      "Epoch 785/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 170.3472 - mae: 10.1470 - val_loss: 241.0382 - val_mae: 12.4654\n",
      "Epoch 786/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 169.3038 - mae: 10.2363 - val_loss: 138.7858 - val_mae: 9.1329\n",
      "Epoch 787/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 165.0241 - mae: 10.0630 - val_loss: 145.5044 - val_mae: 9.2703\n",
      "Epoch 788/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 179.5206 - mae: 10.5116 - val_loss: 135.5047 - val_mae: 8.9013\n",
      "Epoch 789/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 163.2241 - mae: 9.9054 - val_loss: 167.0449 - val_mae: 10.1373\n",
      "Epoch 790/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 177.4317 - mae: 10.4080 - val_loss: 371.9972 - val_mae: 16.5056\n",
      "Epoch 791/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 167.1449 - mae: 10.1427 - val_loss: 219.8460 - val_mae: 11.9358\n",
      "Epoch 792/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 167.2764 - mae: 10.0388 - val_loss: 118.1447 - val_mae: 8.1983\n",
      "Epoch 793/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 164.8273 - mae: 9.8082 - val_loss: 120.0215 - val_mae: 8.4624\n",
      "Epoch 794/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 156.0768 - mae: 9.5797 - val_loss: 232.7345 - val_mae: 12.7463\n",
      "Epoch 795/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 179.3498 - mae: 10.3588 - val_loss: 229.2760 - val_mae: 12.0537\n",
      "Epoch 796/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 168.9014 - mae: 10.1981 - val_loss: 131.2475 - val_mae: 8.9995\n",
      "Epoch 797/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 166.7968 - mae: 9.9729 - val_loss: 170.9836 - val_mae: 10.4713\n",
      "Epoch 798/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 166.8461 - mae: 10.1512 - val_loss: 127.1912 - val_mae: 8.8062\n",
      "Epoch 799/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 172.6269 - mae: 10.2816 - val_loss: 132.3489 - val_mae: 8.6580\n",
      "Epoch 800/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 165.1232 - mae: 9.9714 - val_loss: 132.7935 - val_mae: 8.8363\n",
      "Epoch 801/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 164.5685 - mae: 10.0309 - val_loss: 247.9749 - val_mae: 13.1636\n",
      "Epoch 802/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 160.7186 - mae: 9.9139 - val_loss: 163.3842 - val_mae: 10.0069\n",
      "Epoch 803/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 172.8687 - mae: 10.2915 - val_loss: 129.5936 - val_mae: 8.8369\n",
      "Epoch 804/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 155.5602 - mae: 9.7215 - val_loss: 171.1138 - val_mae: 10.1376\n",
      "Epoch 805/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 171.9450 - mae: 10.1986 - val_loss: 113.1524 - val_mae: 8.0049\n",
      "Epoch 806/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 155.2781 - mae: 9.6767 - val_loss: 259.8996 - val_mae: 13.5186\n",
      "Epoch 807/2000\n",
      "65/65 [==============================] - 1s 11ms/step - loss: 167.0841 - mae: 10.1853 - val_loss: 206.8504 - val_mae: 11.5474\n",
      "Epoch 808/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 160.2100 - mae: 9.8457 - val_loss: 166.5479 - val_mae: 10.1474\n",
      "Epoch 809/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 165.7173 - mae: 10.0482 - val_loss: 130.5715 - val_mae: 8.5226\n",
      "Epoch 810/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 156.0347 - mae: 9.7191 - val_loss: 113.3241 - val_mae: 7.9566\n",
      "Epoch 811/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 157.0839 - mae: 9.7236 - val_loss: 296.4810 - val_mae: 14.0396\n",
      "Epoch 812/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 170.4653 - mae: 10.2369 - val_loss: 97.4259 - val_mae: 7.3587\n",
      "Epoch 813/2000\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 154.4384 - mae: 9.6957 - val_loss: 273.4514 - val_mae: 13.4638\n",
      "Epoch 814/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 159.5623 - mae: 9.7969 - val_loss: 115.7226 - val_mae: 8.1787\n",
      "Epoch 815/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 159.7439 - mae: 9.8227 - val_loss: 100.3828 - val_mae: 7.6314\n",
      "Epoch 816/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 160.9808 - mae: 10.0060 - val_loss: 172.4253 - val_mae: 10.5658\n",
      "Epoch 817/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 156.5946 - mae: 9.8673 - val_loss: 123.8980 - val_mae: 8.6688\n",
      "Epoch 818/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 162.7062 - mae: 10.0479 - val_loss: 214.1592 - val_mae: 11.7103\n",
      "Epoch 819/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 154.7660 - mae: 9.6121 - val_loss: 187.4226 - val_mae: 10.8823\n",
      "Epoch 820/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 149.9426 - mae: 9.4729 - val_loss: 156.1058 - val_mae: 9.5558\n",
      "Epoch 821/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 161.1891 - mae: 9.8444 - val_loss: 290.3693 - val_mae: 13.8547\n",
      "Epoch 822/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 158.6590 - mae: 9.5983 - val_loss: 114.9851 - val_mae: 8.1312\n",
      "Epoch 823/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 149.2218 - mae: 9.5085 - val_loss: 98.9834 - val_mae: 7.4961\n",
      "Epoch 824/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 159.8458 - mae: 9.7010 - val_loss: 241.1024 - val_mae: 12.2938\n",
      "Epoch 825/2000\n",
      "65/65 [==============================] - 1s 11ms/step - loss: 163.1035 - mae: 9.9984 - val_loss: 153.4407 - val_mae: 9.8216\n",
      "Epoch 826/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 162.1034 - mae: 9.9934 - val_loss: 250.0754 - val_mae: 12.9767\n",
      "Epoch 827/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 154.9542 - mae: 9.5771 - val_loss: 186.9140 - val_mae: 11.1378\n",
      "Epoch 828/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 158.4774 - mae: 9.9604 - val_loss: 173.9267 - val_mae: 10.5469\n",
      "Epoch 829/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 152.3526 - mae: 9.5852 - val_loss: 111.2821 - val_mae: 8.0291\n",
      "Epoch 830/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 156.1986 - mae: 9.6258 - val_loss: 134.7152 - val_mae: 8.9065\n",
      "Epoch 831/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 152.5776 - mae: 9.7163 - val_loss: 170.1895 - val_mae: 10.4594\n",
      "Epoch 832/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 159.6488 - mae: 10.0097 - val_loss: 153.7820 - val_mae: 9.9781\n",
      "Epoch 833/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 154.6299 - mae: 9.6735 - val_loss: 221.5842 - val_mae: 12.5438\n",
      "Epoch 834/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 154.2337 - mae: 9.7060 - val_loss: 180.0780 - val_mae: 10.7882\n",
      "Epoch 835/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 153.3089 - mae: 9.7816 - val_loss: 133.1314 - val_mae: 8.7643\n",
      "Epoch 836/2000\n",
      "65/65 [==============================] - 1s 11ms/step - loss: 156.7935 - mae: 9.7691 - val_loss: 88.5246 - val_mae: 7.1183\n",
      "Epoch 837/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 151.6681 - mae: 9.6230 - val_loss: 322.8655 - val_mae: 14.3241\n",
      "Epoch 838/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 151.0838 - mae: 9.5291 - val_loss: 93.2443 - val_mae: 7.4357\n",
      "Epoch 839/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 159.9878 - mae: 9.8046 - val_loss: 134.7010 - val_mae: 8.8680\n",
      "Epoch 840/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 143.1486 - mae: 9.2749 - val_loss: 115.2972 - val_mae: 8.3057\n",
      "Epoch 841/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 160.7724 - mae: 9.8956 - val_loss: 166.0065 - val_mae: 9.6930\n",
      "Epoch 842/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 155.2834 - mae: 9.8361 - val_loss: 190.9543 - val_mae: 10.6630\n",
      "Epoch 843/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 146.0131 - mae: 9.4243 - val_loss: 139.7418 - val_mae: 9.1957\n",
      "Epoch 844/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 159.9813 - mae: 9.9296 - val_loss: 114.6306 - val_mae: 8.2290\n",
      "Epoch 845/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 147.3846 - mae: 9.5242 - val_loss: 114.1311 - val_mae: 8.1367\n",
      "Epoch 846/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 153.1142 - mae: 9.5554 - val_loss: 148.5188 - val_mae: 9.1533\n",
      "Epoch 847/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 155.0598 - mae: 9.8088 - val_loss: 91.9296 - val_mae: 7.0628\n",
      "Epoch 848/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 149.9915 - mae: 9.5190 - val_loss: 97.2326 - val_mae: 7.4164\n",
      "Epoch 849/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 152.7618 - mae: 9.7679 - val_loss: 155.8137 - val_mae: 9.9920\n",
      "Epoch 850/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 144.0921 - mae: 9.2644 - val_loss: 120.7949 - val_mae: 8.4578\n",
      "Epoch 851/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 147.5845 - mae: 9.6014 - val_loss: 106.9535 - val_mae: 7.9593\n",
      "Epoch 852/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 158.3363 - mae: 9.8409 - val_loss: 155.4494 - val_mae: 9.8770\n",
      "Epoch 853/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 142.3769 - mae: 9.3029 - val_loss: 388.5072 - val_mae: 16.8304\n",
      "Epoch 854/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 153.7377 - mae: 9.8064 - val_loss: 165.6831 - val_mae: 10.0714\n",
      "Epoch 855/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 145.5511 - mae: 9.5095 - val_loss: 140.6077 - val_mae: 9.1498\n",
      "Epoch 856/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 151.2561 - mae: 9.5820 - val_loss: 119.4591 - val_mae: 8.2549\n",
      "Epoch 857/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 155.4230 - mae: 9.6422 - val_loss: 92.4318 - val_mae: 7.1190\n",
      "Epoch 858/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 150.5049 - mae: 9.7241 - val_loss: 189.7947 - val_mae: 11.3769\n",
      "Epoch 859/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 153.7091 - mae: 9.6967 - val_loss: 115.3773 - val_mae: 8.2299\n",
      "Epoch 860/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 149.4301 - mae: 9.2777 - val_loss: 98.9127 - val_mae: 7.4221\n",
      "Epoch 861/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 146.9610 - mae: 9.2232 - val_loss: 126.5087 - val_mae: 8.9685\n",
      "Epoch 862/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 147.6377 - mae: 9.4636 - val_loss: 98.3600 - val_mae: 7.4735\n",
      "Epoch 863/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 145.3722 - mae: 9.3130 - val_loss: 255.1975 - val_mae: 13.1594\n",
      "Epoch 864/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 147.5064 - mae: 9.5513 - val_loss: 147.1381 - val_mae: 9.3966\n",
      "Epoch 865/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 143.2536 - mae: 9.3779 - val_loss: 371.9909 - val_mae: 16.8281\n",
      "Epoch 866/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 150.8095 - mae: 9.5849 - val_loss: 192.7187 - val_mae: 10.8801\n",
      "Epoch 867/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 142.7661 - mae: 9.3261 - val_loss: 100.3980 - val_mae: 7.7488\n",
      "Epoch 868/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 143.5780 - mae: 9.3135 - val_loss: 461.3478 - val_mae: 18.5482\n",
      "Epoch 869/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 147.1636 - mae: 9.4534 - val_loss: 290.3490 - val_mae: 13.9539\n",
      "Epoch 870/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 146.1678 - mae: 9.4173 - val_loss: 158.2418 - val_mae: 9.9063\n",
      "Epoch 871/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 151.2660 - mae: 9.5540 - val_loss: 171.7670 - val_mae: 10.2395\n",
      "Epoch 872/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 141.3767 - mae: 9.1742 - val_loss: 151.9608 - val_mae: 9.7605\n",
      "Epoch 873/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 149.9130 - mae: 9.6376 - val_loss: 177.5051 - val_mae: 10.0539\n",
      "Epoch 874/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 143.0856 - mae: 9.4074 - val_loss: 183.1471 - val_mae: 11.3755\n",
      "Epoch 875/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 147.7432 - mae: 9.5278 - val_loss: 245.5136 - val_mae: 12.9550\n",
      "Epoch 876/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 134.6580 - mae: 8.9671 - val_loss: 88.6117 - val_mae: 7.1461\n",
      "Epoch 877/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 148.3019 - mae: 9.3622 - val_loss: 189.6557 - val_mae: 11.0840\n",
      "Epoch 878/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 133.4678 - mae: 8.9532 - val_loss: 347.1043 - val_mae: 15.2029\n",
      "Epoch 879/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 150.6289 - mae: 9.4837 - val_loss: 146.6648 - val_mae: 10.0364\n",
      "Epoch 880/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 147.8181 - mae: 9.6461 - val_loss: 116.3202 - val_mae: 8.4036\n",
      "Epoch 881/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 146.8615 - mae: 9.2435 - val_loss: 328.3207 - val_mae: 14.1255\n",
      "Epoch 882/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 139.1276 - mae: 9.1594 - val_loss: 242.7530 - val_mae: 12.3256\n",
      "Epoch 883/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 137.1289 - mae: 9.1194 - val_loss: 179.4571 - val_mae: 10.6904\n",
      "Epoch 884/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 148.8939 - mae: 9.5497 - val_loss: 217.6116 - val_mae: 12.3391\n",
      "Epoch 885/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 140.7155 - mae: 9.3128 - val_loss: 286.3976 - val_mae: 13.5947\n",
      "Epoch 886/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 143.2193 - mae: 9.4191 - val_loss: 119.5663 - val_mae: 8.5315\n",
      "Epoch 887/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 147.5099 - mae: 9.4370 - val_loss: 85.2948 - val_mae: 6.9534\n",
      "Epoch 888/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 135.5789 - mae: 9.1198 - val_loss: 173.1707 - val_mae: 10.3159\n",
      "Epoch 889/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 142.7655 - mae: 9.3537 - val_loss: 81.3553 - val_mae: 6.8590\n",
      "Epoch 890/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 146.0271 - mae: 9.5355 - val_loss: 81.9736 - val_mae: 6.8366\n",
      "Epoch 891/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 147.4369 - mae: 9.3989 - val_loss: 75.4740 - val_mae: 6.4742\n",
      "Epoch 892/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 143.1742 - mae: 9.3414 - val_loss: 84.9881 - val_mae: 6.9751\n",
      "Epoch 893/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 135.9289 - mae: 9.1304 - val_loss: 124.4925 - val_mae: 8.4676\n",
      "Epoch 894/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 139.8347 - mae: 9.2643 - val_loss: 108.7254 - val_mae: 7.8098\n",
      "Epoch 895/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 134.2263 - mae: 8.9121 - val_loss: 193.7024 - val_mae: 11.1246\n",
      "Epoch 896/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 138.9833 - mae: 9.1864 - val_loss: 128.1158 - val_mae: 9.1893\n",
      "Epoch 897/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 148.4699 - mae: 9.6246 - val_loss: 122.2967 - val_mae: 8.9239\n",
      "Epoch 898/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 136.9788 - mae: 9.0436 - val_loss: 119.9396 - val_mae: 8.6904\n",
      "Epoch 899/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 140.7035 - mae: 9.3639 - val_loss: 100.0629 - val_mae: 7.6021\n",
      "Epoch 900/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 141.0234 - mae: 9.3779 - val_loss: 171.8448 - val_mae: 10.8217\n",
      "Epoch 901/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 132.6015 - mae: 8.9112 - val_loss: 293.3813 - val_mae: 14.1692\n",
      "Epoch 902/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 140.6192 - mae: 9.2731 - val_loss: 84.1084 - val_mae: 7.0626\n",
      "Epoch 903/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 132.3748 - mae: 8.9985 - val_loss: 156.1384 - val_mae: 9.8926\n",
      "Epoch 904/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 142.4265 - mae: 9.3388 - val_loss: 92.8316 - val_mae: 7.3279\n",
      "Epoch 905/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 133.4971 - mae: 8.9879 - val_loss: 119.9664 - val_mae: 8.6687\n",
      "Epoch 906/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 148.2090 - mae: 9.7382 - val_loss: 130.8841 - val_mae: 8.7534\n",
      "Epoch 907/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 131.2006 - mae: 8.8472 - val_loss: 306.8429 - val_mae: 13.5323\n",
      "Epoch 908/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 141.7900 - mae: 9.3261 - val_loss: 90.7297 - val_mae: 7.2548\n",
      "Epoch 909/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 131.6297 - mae: 8.9252 - val_loss: 116.5657 - val_mae: 8.6461\n",
      "Epoch 910/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 144.1326 - mae: 9.4246 - val_loss: 128.2691 - val_mae: 8.9216\n",
      "Epoch 911/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 139.2494 - mae: 9.4165 - val_loss: 71.6062 - val_mae: 6.3899\n",
      "Epoch 912/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 136.0000 - mae: 8.9552 - val_loss: 81.7389 - val_mae: 6.5783\n",
      "Epoch 913/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 137.3189 - mae: 9.1247 - val_loss: 73.2708 - val_mae: 6.4937\n",
      "Epoch 914/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 135.7951 - mae: 9.0475 - val_loss: 114.8469 - val_mae: 8.3176\n",
      "Epoch 915/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 135.7348 - mae: 9.2399 - val_loss: 120.6450 - val_mae: 8.5330\n",
      "Epoch 916/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 132.3969 - mae: 8.7931 - val_loss: 208.4508 - val_mae: 11.7908\n",
      "Epoch 917/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 134.0552 - mae: 9.0434 - val_loss: 136.1365 - val_mae: 8.9855\n",
      "Epoch 918/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 128.6855 - mae: 8.7146 - val_loss: 136.2061 - val_mae: 8.8085\n",
      "Epoch 919/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 131.5504 - mae: 9.0259 - val_loss: 97.0923 - val_mae: 7.5631\n",
      "Epoch 920/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 131.1384 - mae: 9.0598 - val_loss: 84.5213 - val_mae: 7.0257\n",
      "Epoch 921/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 137.7018 - mae: 9.1898 - val_loss: 186.3320 - val_mae: 11.4844\n",
      "Epoch 922/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 128.4650 - mae: 8.8706 - val_loss: 152.1598 - val_mae: 9.6734\n",
      "Epoch 923/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 139.7708 - mae: 9.2293 - val_loss: 100.0271 - val_mae: 7.7649\n",
      "Epoch 924/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 131.2800 - mae: 8.8736 - val_loss: 155.5699 - val_mae: 9.8238\n",
      "Epoch 925/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 130.0322 - mae: 8.9065 - val_loss: 129.5877 - val_mae: 8.8572\n",
      "Epoch 926/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 140.6641 - mae: 9.2687 - val_loss: 123.3224 - val_mae: 9.0243\n",
      "Epoch 927/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 135.9808 - mae: 9.1482 - val_loss: 92.5662 - val_mae: 7.6116\n",
      "Epoch 928/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 128.9858 - mae: 8.9205 - val_loss: 98.0327 - val_mae: 7.7281\n",
      "Epoch 929/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 131.9463 - mae: 8.9082 - val_loss: 73.3762 - val_mae: 6.4844\n",
      "Epoch 930/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 134.3999 - mae: 8.9810 - val_loss: 90.3346 - val_mae: 7.3850\n",
      "Epoch 931/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 137.4475 - mae: 9.2240 - val_loss: 113.2536 - val_mae: 8.3329\n",
      "Epoch 932/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 126.1469 - mae: 8.7770 - val_loss: 172.0191 - val_mae: 11.0443\n",
      "Epoch 933/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 130.1038 - mae: 8.9237 - val_loss: 106.0969 - val_mae: 8.0149\n",
      "Epoch 934/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 124.5783 - mae: 8.5557 - val_loss: 104.0077 - val_mae: 7.7638\n",
      "Epoch 935/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 137.6919 - mae: 9.1809 - val_loss: 90.5960 - val_mae: 7.2449\n",
      "Epoch 936/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 136.5588 - mae: 9.1795 - val_loss: 197.8009 - val_mae: 11.3617\n",
      "Epoch 937/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 128.6871 - mae: 8.7138 - val_loss: 157.1669 - val_mae: 10.1174\n",
      "Epoch 938/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 129.8729 - mae: 8.7975 - val_loss: 68.3465 - val_mae: 6.1515\n",
      "Epoch 939/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 125.4044 - mae: 8.7426 - val_loss: 193.6344 - val_mae: 11.4978\n",
      "Epoch 940/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 134.9625 - mae: 9.2581 - val_loss: 157.7619 - val_mae: 9.5336\n",
      "Epoch 941/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 127.1311 - mae: 8.8655 - val_loss: 288.3187 - val_mae: 14.1373\n",
      "Epoch 942/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 135.4973 - mae: 9.0123 - val_loss: 130.6045 - val_mae: 8.8889\n",
      "Epoch 943/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 130.6389 - mae: 8.9629 - val_loss: 117.0962 - val_mae: 8.0888\n",
      "Epoch 944/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 130.7648 - mae: 9.0910 - val_loss: 170.4423 - val_mae: 10.5949\n",
      "Epoch 945/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 129.5276 - mae: 8.9443 - val_loss: 201.5312 - val_mae: 11.0609\n",
      "Epoch 946/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 138.7450 - mae: 9.2885 - val_loss: 113.4502 - val_mae: 8.0023\n",
      "Epoch 947/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 121.8773 - mae: 8.6776 - val_loss: 114.2361 - val_mae: 8.3336\n",
      "Epoch 948/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 130.3537 - mae: 8.9993 - val_loss: 230.6360 - val_mae: 12.0964\n",
      "Epoch 949/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 130.3678 - mae: 9.0185 - val_loss: 100.7607 - val_mae: 7.3134\n",
      "Epoch 950/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 127.6242 - mae: 8.9035 - val_loss: 294.8522 - val_mae: 13.5737\n",
      "Epoch 951/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 123.6259 - mae: 8.6638 - val_loss: 144.3342 - val_mae: 9.6850\n",
      "Epoch 952/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 132.5400 - mae: 9.1600 - val_loss: 101.8617 - val_mae: 7.8082\n",
      "Epoch 953/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 126.2077 - mae: 8.6840 - val_loss: 314.3132 - val_mae: 15.3629\n",
      "Epoch 954/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 126.7650 - mae: 8.9358 - val_loss: 97.7901 - val_mae: 7.6740\n",
      "Epoch 955/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 132.3690 - mae: 9.0493 - val_loss: 181.1420 - val_mae: 10.9162\n",
      "Epoch 956/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 130.6430 - mae: 8.8661 - val_loss: 67.8093 - val_mae: 6.1650\n",
      "Epoch 957/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 122.3828 - mae: 8.6816 - val_loss: 121.0344 - val_mae: 8.8198\n",
      "Epoch 958/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 131.4042 - mae: 8.8703 - val_loss: 195.2689 - val_mae: 10.9317\n",
      "Epoch 959/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 126.0798 - mae: 8.8764 - val_loss: 108.0548 - val_mae: 7.6963\n",
      "Epoch 960/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 124.6649 - mae: 8.7971 - val_loss: 78.9503 - val_mae: 6.5956\n",
      "Epoch 961/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 121.8275 - mae: 8.4603 - val_loss: 133.7635 - val_mae: 8.8478\n",
      "Epoch 962/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 127.4378 - mae: 8.8224 - val_loss: 139.5296 - val_mae: 9.0973\n",
      "Epoch 963/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 130.4700 - mae: 8.9955 - val_loss: 113.1757 - val_mae: 8.0782\n",
      "Epoch 964/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 130.7931 - mae: 8.9565 - val_loss: 69.0394 - val_mae: 6.1199\n",
      "Epoch 965/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 128.0634 - mae: 8.8579 - val_loss: 110.0616 - val_mae: 8.1180\n",
      "Epoch 966/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 128.5898 - mae: 8.8830 - val_loss: 192.5479 - val_mae: 11.6139\n",
      "Epoch 967/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 124.7609 - mae: 8.7584 - val_loss: 85.5972 - val_mae: 7.1733\n",
      "Epoch 968/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 124.1946 - mae: 8.8037 - val_loss: 191.5650 - val_mae: 11.2416\n",
      "Epoch 969/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 127.7815 - mae: 8.8489 - val_loss: 89.2498 - val_mae: 7.2319\n",
      "Epoch 970/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 126.2948 - mae: 8.8642 - val_loss: 102.6255 - val_mae: 7.8560\n",
      "Epoch 971/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 124.8523 - mae: 8.7634 - val_loss: 145.7822 - val_mae: 9.6869\n",
      "Epoch 972/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 122.2353 - mae: 8.6658 - val_loss: 182.4893 - val_mae: 11.4395\n",
      "Epoch 973/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 126.9990 - mae: 8.9879 - val_loss: 109.1770 - val_mae: 8.5697\n",
      "Epoch 974/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 120.5514 - mae: 8.6784 - val_loss: 92.7095 - val_mae: 7.2817\n",
      "Epoch 975/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 122.1420 - mae: 8.5227 - val_loss: 83.3388 - val_mae: 6.7949\n",
      "Epoch 976/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 126.3811 - mae: 8.7192 - val_loss: 73.8037 - val_mae: 6.6215\n",
      "Epoch 977/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 125.6897 - mae: 8.6959 - val_loss: 120.0117 - val_mae: 8.6819\n",
      "Epoch 978/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 126.9786 - mae: 8.7383 - val_loss: 86.4240 - val_mae: 7.1301\n",
      "Epoch 979/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 126.8200 - mae: 8.9077 - val_loss: 96.3376 - val_mae: 7.4372\n",
      "Epoch 980/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 113.7681 - mae: 8.3187 - val_loss: 197.6401 - val_mae: 12.1781\n",
      "Epoch 981/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 127.0536 - mae: 8.7863 - val_loss: 155.6904 - val_mae: 10.2659\n",
      "Epoch 982/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 120.2478 - mae: 8.6726 - val_loss: 77.7487 - val_mae: 6.7095\n",
      "Epoch 983/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 121.1100 - mae: 8.5889 - val_loss: 89.4923 - val_mae: 7.3094\n",
      "Epoch 984/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 124.6760 - mae: 8.8409 - val_loss: 137.7483 - val_mae: 9.9444\n",
      "Epoch 985/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 124.7416 - mae: 8.8349 - val_loss: 91.3257 - val_mae: 7.5173\n",
      "Epoch 986/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 126.3282 - mae: 8.8488 - val_loss: 74.6886 - val_mae: 6.5532\n",
      "Epoch 987/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 125.5168 - mae: 8.8842 - val_loss: 107.9337 - val_mae: 7.9667\n",
      "Epoch 988/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 120.9746 - mae: 8.7106 - val_loss: 125.2883 - val_mae: 9.0497\n",
      "Epoch 989/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 125.6785 - mae: 8.8171 - val_loss: 346.4588 - val_mae: 15.1934\n",
      "Epoch 990/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 121.8462 - mae: 8.5741 - val_loss: 281.5723 - val_mae: 13.1381\n",
      "Epoch 991/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 124.3418 - mae: 8.6044 - val_loss: 97.6875 - val_mae: 7.5370\n",
      "Epoch 992/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 122.2544 - mae: 8.6320 - val_loss: 79.8240 - val_mae: 6.8480\n",
      "Epoch 993/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 125.5700 - mae: 8.8924 - val_loss: 213.1836 - val_mae: 10.8830\n",
      "Epoch 994/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 122.1295 - mae: 8.6227 - val_loss: 70.9645 - val_mae: 6.4002\n",
      "Epoch 995/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 119.1931 - mae: 8.5770 - val_loss: 140.8848 - val_mae: 9.8764\n",
      "Epoch 996/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 119.2857 - mae: 8.6194 - val_loss: 158.1753 - val_mae: 10.0334\n",
      "Epoch 997/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 120.8094 - mae: 8.5174 - val_loss: 113.9547 - val_mae: 7.9288\n",
      "Epoch 998/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 123.7097 - mae: 8.7569 - val_loss: 64.8509 - val_mae: 6.0580\n",
      "Epoch 999/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 119.0208 - mae: 8.5802 - val_loss: 63.9976 - val_mae: 6.0406\n",
      "Epoch 1000/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 114.2207 - mae: 8.2574 - val_loss: 190.8762 - val_mae: 11.3435\n",
      "Epoch 1001/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 124.6900 - mae: 8.7429 - val_loss: 97.1418 - val_mae: 7.4416\n",
      "Epoch 1002/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 124.4484 - mae: 8.6566 - val_loss: 98.6473 - val_mae: 7.7067\n",
      "Epoch 1003/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 121.5852 - mae: 8.7518 - val_loss: 71.0090 - val_mae: 6.4684\n",
      "Epoch 1004/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 116.2395 - mae: 8.5428 - val_loss: 127.6040 - val_mae: 8.8635\n",
      "Epoch 1005/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 115.3992 - mae: 8.4663 - val_loss: 196.6522 - val_mae: 10.7246\n",
      "Epoch 1006/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 125.1111 - mae: 8.8353 - val_loss: 66.3678 - val_mae: 6.0970\n",
      "Epoch 1007/2000\n",
      "65/65 [==============================] - 1s 12ms/step - loss: 118.5352 - mae: 8.5451 - val_loss: 106.3147 - val_mae: 8.0738\n",
      "Epoch 1008/2000\n",
      "65/65 [==============================] - 1s 18ms/step - loss: 114.1302 - mae: 8.4736 - val_loss: 74.3039 - val_mae: 6.6049\n",
      "Epoch 1009/2000\n",
      "65/65 [==============================] - 1s 13ms/step - loss: 114.1714 - mae: 8.4127 - val_loss: 121.8078 - val_mae: 9.2754\n",
      "Epoch 1010/2000\n",
      "65/65 [==============================] - 1s 12ms/step - loss: 122.9346 - mae: 8.7392 - val_loss: 203.1844 - val_mae: 11.9220\n",
      "Epoch 1011/2000\n",
      "65/65 [==============================] - 1s 11ms/step - loss: 120.6134 - mae: 8.7128 - val_loss: 78.1390 - val_mae: 6.6566\n",
      "Epoch 1012/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 121.1203 - mae: 8.6382 - val_loss: 221.8475 - val_mae: 12.5351\n",
      "Epoch 1013/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 117.4493 - mae: 8.4737 - val_loss: 202.7068 - val_mae: 11.5763\n",
      "Epoch 1014/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 119.5000 - mae: 8.4977 - val_loss: 175.6832 - val_mae: 11.0148\n",
      "Epoch 1015/2000\n",
      "65/65 [==============================] - 1s 12ms/step - loss: 109.0940 - mae: 8.1670 - val_loss: 339.5832 - val_mae: 16.1650\n",
      "Epoch 1016/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 122.4521 - mae: 8.6936 - val_loss: 159.2783 - val_mae: 10.4850\n",
      "Epoch 1017/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 110.9463 - mae: 8.0428 - val_loss: 158.7993 - val_mae: 10.5618\n",
      "Epoch 1018/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 114.0456 - mae: 8.2444 - val_loss: 126.8770 - val_mae: 8.9347\n",
      "Epoch 1019/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 117.1094 - mae: 8.4109 - val_loss: 119.2807 - val_mae: 8.9593\n",
      "Epoch 1020/2000\n",
      "65/65 [==============================] - 1s 11ms/step - loss: 115.5496 - mae: 8.4587 - val_loss: 115.0413 - val_mae: 8.7074\n",
      "Epoch 1021/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 121.3812 - mae: 8.6747 - val_loss: 164.5244 - val_mae: 10.6269\n",
      "Epoch 1022/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 117.0921 - mae: 8.5267 - val_loss: 78.6219 - val_mae: 6.8101\n",
      "Epoch 1023/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 116.8868 - mae: 8.5645 - val_loss: 207.6337 - val_mae: 12.3248\n",
      "Epoch 1024/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 121.6336 - mae: 8.6023 - val_loss: 65.4639 - val_mae: 5.9619\n",
      "Epoch 1025/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 110.9766 - mae: 8.1393 - val_loss: 61.2684 - val_mae: 5.9177\n",
      "Epoch 1026/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 115.3439 - mae: 8.3915 - val_loss: 98.5750 - val_mae: 7.6038\n",
      "Epoch 1027/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 120.9121 - mae: 8.6269 - val_loss: 66.7742 - val_mae: 6.1950\n",
      "Epoch 1028/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 114.8892 - mae: 8.4466 - val_loss: 242.9526 - val_mae: 12.6256\n",
      "Epoch 1029/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 114.4257 - mae: 8.4317 - val_loss: 256.0374 - val_mae: 13.5357\n",
      "Epoch 1030/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 112.8051 - mae: 8.2475 - val_loss: 87.7866 - val_mae: 7.4662\n",
      "Epoch 1031/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 112.5934 - mae: 8.4043 - val_loss: 69.8606 - val_mae: 6.3795\n",
      "Epoch 1032/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 120.2991 - mae: 8.6543 - val_loss: 138.5618 - val_mae: 9.2911\n",
      "Epoch 1033/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 115.1401 - mae: 8.5235 - val_loss: 75.1539 - val_mae: 6.8066\n",
      "Epoch 1034/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 109.1682 - mae: 8.1802 - val_loss: 185.2033 - val_mae: 11.3041\n",
      "Epoch 1035/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 118.4664 - mae: 8.5674 - val_loss: 197.3640 - val_mae: 12.0057\n",
      "Epoch 1036/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 116.3343 - mae: 8.5274 - val_loss: 168.6823 - val_mae: 10.4632\n",
      "Epoch 1037/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 115.2275 - mae: 8.4093 - val_loss: 201.7181 - val_mae: 11.7182\n",
      "Epoch 1038/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 108.2013 - mae: 8.1030 - val_loss: 83.1023 - val_mae: 6.8943\n",
      "Epoch 1039/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 120.4411 - mae: 8.6230 - val_loss: 147.4900 - val_mae: 10.1338\n",
      "Epoch 1040/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 112.7585 - mae: 8.4513 - val_loss: 84.2265 - val_mae: 7.1764\n",
      "Epoch 1041/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 113.0061 - mae: 8.4352 - val_loss: 163.2596 - val_mae: 10.3441\n",
      "Epoch 1042/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 116.7768 - mae: 8.5861 - val_loss: 181.3207 - val_mae: 11.1060\n",
      "Epoch 1043/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 111.5070 - mae: 8.3223 - val_loss: 87.9213 - val_mae: 7.0643\n",
      "Epoch 1044/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 118.1440 - mae: 8.4164 - val_loss: 165.8238 - val_mae: 10.6588\n",
      "Epoch 1045/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 113.3586 - mae: 8.2137 - val_loss: 122.0098 - val_mae: 8.5495\n",
      "Epoch 1046/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 109.7912 - mae: 8.2603 - val_loss: 65.6549 - val_mae: 6.1254\n",
      "Epoch 1047/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 110.9942 - mae: 8.1668 - val_loss: 283.5642 - val_mae: 14.5186\n",
      "Epoch 1048/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 117.0211 - mae: 8.4040 - val_loss: 81.4336 - val_mae: 7.0767\n",
      "Epoch 1049/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 114.4987 - mae: 8.3350 - val_loss: 97.7343 - val_mae: 7.6320\n",
      "Epoch 1050/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 114.1334 - mae: 8.4043 - val_loss: 243.1911 - val_mae: 13.0775\n",
      "Epoch 1051/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 108.4405 - mae: 8.0219 - val_loss: 164.5106 - val_mae: 10.6850\n",
      "Epoch 1052/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 118.4826 - mae: 8.6110 - val_loss: 138.6027 - val_mae: 9.3449\n",
      "Epoch 1053/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 112.1879 - mae: 8.2417 - val_loss: 131.8984 - val_mae: 9.0666\n",
      "Epoch 1054/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 108.4522 - mae: 8.1478 - val_loss: 290.5384 - val_mae: 14.9824\n",
      "Epoch 1055/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 117.6242 - mae: 8.4083 - val_loss: 149.3802 - val_mae: 9.4850\n",
      "Epoch 1056/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 112.3305 - mae: 8.2959 - val_loss: 189.7128 - val_mae: 11.5309\n",
      "Epoch 1057/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 116.6442 - mae: 8.4149 - val_loss: 118.6500 - val_mae: 8.5815\n",
      "Epoch 1058/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 106.9688 - mae: 8.1296 - val_loss: 219.0347 - val_mae: 12.3890\n",
      "Epoch 1059/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 111.8238 - mae: 8.1473 - val_loss: 88.5897 - val_mae: 7.2446\n",
      "Epoch 1060/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 112.1978 - mae: 8.4226 - val_loss: 84.2850 - val_mae: 7.1280\n",
      "Epoch 1061/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 108.9072 - mae: 8.1007 - val_loss: 227.0200 - val_mae: 12.3906\n",
      "Epoch 1062/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 105.4885 - mae: 8.0575 - val_loss: 99.2871 - val_mae: 7.8213\n",
      "Epoch 1063/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 114.2087 - mae: 8.4339 - val_loss: 96.4686 - val_mae: 7.6487\n",
      "Epoch 1064/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 104.6751 - mae: 7.9480 - val_loss: 68.1043 - val_mae: 6.3423\n",
      "Epoch 1065/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 111.8022 - mae: 8.2520 - val_loss: 194.9752 - val_mae: 11.8119\n",
      "Epoch 1066/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 111.3844 - mae: 8.1629 - val_loss: 61.8977 - val_mae: 5.9456\n",
      "Epoch 1067/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 111.2621 - mae: 8.2493 - val_loss: 118.2191 - val_mae: 8.1826\n",
      "Epoch 1068/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 116.6087 - mae: 8.5494 - val_loss: 56.6641 - val_mae: 5.6238\n",
      "Epoch 1069/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 110.6334 - mae: 8.2706 - val_loss: 169.2261 - val_mae: 10.6466\n",
      "Epoch 1070/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 116.1936 - mae: 8.5337 - val_loss: 69.9914 - val_mae: 6.3941\n",
      "Epoch 1071/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 106.6068 - mae: 8.0208 - val_loss: 69.9480 - val_mae: 6.4182\n",
      "Epoch 1072/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 114.0649 - mae: 8.4720 - val_loss: 154.1354 - val_mae: 10.3794\n",
      "Epoch 1073/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 103.4944 - mae: 7.7913 - val_loss: 287.0190 - val_mae: 14.8435\n",
      "Epoch 1074/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 116.8647 - mae: 8.6111 - val_loss: 126.1049 - val_mae: 8.8717\n",
      "Epoch 1075/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 106.9440 - mae: 8.1952 - val_loss: 183.9250 - val_mae: 11.3231\n",
      "Epoch 1076/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 112.8931 - mae: 8.3139 - val_loss: 65.3095 - val_mae: 6.0245\n",
      "Epoch 1077/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 113.6371 - mae: 8.4716 - val_loss: 70.4287 - val_mae: 6.5284\n",
      "Epoch 1078/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 104.6377 - mae: 8.0375 - val_loss: 82.0982 - val_mae: 7.0522\n",
      "Epoch 1079/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 109.7866 - mae: 8.2640 - val_loss: 58.8282 - val_mae: 5.8530\n",
      "Epoch 1080/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 112.8942 - mae: 8.2904 - val_loss: 89.4026 - val_mae: 7.5940\n",
      "Epoch 1081/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 107.1787 - mae: 8.1944 - val_loss: 168.4739 - val_mae: 9.9726\n",
      "Epoch 1082/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 105.5876 - mae: 8.0457 - val_loss: 166.1825 - val_mae: 10.5691\n",
      "Epoch 1083/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 109.1653 - mae: 8.2982 - val_loss: 158.3298 - val_mae: 10.4881\n",
      "Epoch 1084/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 115.2440 - mae: 8.5496 - val_loss: 82.1082 - val_mae: 7.1368\n",
      "Epoch 1085/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 107.6364 - mae: 8.2761 - val_loss: 66.9485 - val_mae: 6.3503\n",
      "Epoch 1086/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 110.5709 - mae: 8.3774 - val_loss: 99.6567 - val_mae: 8.1398\n",
      "Epoch 1087/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 101.9437 - mae: 7.8741 - val_loss: 126.0059 - val_mae: 9.1349\n",
      "Epoch 1088/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 112.2117 - mae: 8.3430 - val_loss: 132.0668 - val_mae: 9.5211\n",
      "Epoch 1089/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 113.7460 - mae: 8.3608 - val_loss: 132.1025 - val_mae: 9.3409\n",
      "Epoch 1090/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 109.1184 - mae: 8.2978 - val_loss: 130.7462 - val_mae: 9.3683\n",
      "Epoch 1091/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 104.4089 - mae: 7.9951 - val_loss: 49.9894 - val_mae: 5.2073\n",
      "Epoch 1092/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 113.7424 - mae: 8.5131 - val_loss: 134.6333 - val_mae: 9.1413\n",
      "Epoch 1093/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 112.5885 - mae: 8.3847 - val_loss: 155.3917 - val_mae: 10.3452\n",
      "Epoch 1094/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 99.8599 - mae: 7.8423 - val_loss: 319.4030 - val_mae: 15.7435\n",
      "Epoch 1095/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 110.4215 - mae: 8.2326 - val_loss: 100.1981 - val_mae: 7.9123\n",
      "Epoch 1096/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 108.1453 - mae: 8.2638 - val_loss: 79.9125 - val_mae: 6.9014\n",
      "Epoch 1097/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 108.1236 - mae: 8.1752 - val_loss: 87.9757 - val_mae: 7.0840\n",
      "Epoch 1098/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 106.2564 - mae: 8.0608 - val_loss: 92.6290 - val_mae: 7.4636\n",
      "Epoch 1099/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 96.5042 - mae: 7.5970 - val_loss: 203.0998 - val_mae: 11.6503\n",
      "Epoch 1100/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 114.0727 - mae: 8.5457 - val_loss: 137.9146 - val_mae: 9.3423\n",
      "Epoch 1101/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 99.7413 - mae: 7.9555 - val_loss: 85.1525 - val_mae: 7.1103\n",
      "Epoch 1102/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 113.0077 - mae: 8.3466 - val_loss: 110.3179 - val_mae: 8.2863\n",
      "Epoch 1103/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 103.5882 - mae: 7.9250 - val_loss: 105.1321 - val_mae: 8.2144\n",
      "Epoch 1104/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 108.7570 - mae: 8.2267 - val_loss: 97.1718 - val_mae: 7.9597\n",
      "Epoch 1105/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 103.4013 - mae: 8.1082 - val_loss: 56.3522 - val_mae: 5.6557\n",
      "Epoch 1106/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 108.1603 - mae: 8.1099 - val_loss: 152.9595 - val_mae: 9.5034\n",
      "Epoch 1107/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 103.3599 - mae: 8.1347 - val_loss: 119.3819 - val_mae: 8.5610\n",
      "Epoch 1108/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 106.1188 - mae: 8.1538 - val_loss: 113.8083 - val_mae: 8.9210\n",
      "Epoch 1109/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 108.4105 - mae: 8.3523 - val_loss: 93.8300 - val_mae: 7.3614\n",
      "Epoch 1110/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 105.6350 - mae: 8.2048 - val_loss: 157.4779 - val_mae: 10.4326\n",
      "Epoch 1111/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 108.4141 - mae: 8.2748 - val_loss: 125.8340 - val_mae: 8.7252\n",
      "Epoch 1112/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 99.8181 - mae: 7.7829 - val_loss: 215.3265 - val_mae: 12.1509\n",
      "Epoch 1113/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 103.3854 - mae: 7.9588 - val_loss: 124.9802 - val_mae: 8.5905\n",
      "Epoch 1114/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 108.7494 - mae: 8.1471 - val_loss: 59.4356 - val_mae: 5.9171\n",
      "Epoch 1115/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 95.8733 - mae: 7.5261 - val_loss: 171.5775 - val_mae: 10.0940\n",
      "Epoch 1116/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 106.7791 - mae: 8.1119 - val_loss: 153.9896 - val_mae: 10.1729\n",
      "Epoch 1117/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 101.6165 - mae: 7.9310 - val_loss: 152.2109 - val_mae: 9.5099\n",
      "Epoch 1118/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 108.4098 - mae: 8.2554 - val_loss: 78.4965 - val_mae: 6.9744\n",
      "Epoch 1119/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 106.7399 - mae: 8.1657 - val_loss: 79.8324 - val_mae: 6.9451\n",
      "Epoch 1120/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 102.9990 - mae: 8.0101 - val_loss: 69.8160 - val_mae: 6.5162\n",
      "Epoch 1121/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 105.7757 - mae: 8.0485 - val_loss: 63.1597 - val_mae: 6.0756\n",
      "Epoch 1122/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 99.6837 - mae: 7.8724 - val_loss: 204.2719 - val_mae: 12.2071\n",
      "Epoch 1123/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 100.9556 - mae: 7.9369 - val_loss: 193.7426 - val_mae: 11.9004\n",
      "Epoch 1124/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 108.5563 - mae: 8.1897 - val_loss: 99.7246 - val_mae: 7.5145\n",
      "Epoch 1125/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 104.4291 - mae: 7.9802 - val_loss: 76.7462 - val_mae: 6.6054\n",
      "Epoch 1126/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 101.9714 - mae: 8.0321 - val_loss: 73.9014 - val_mae: 6.5333\n",
      "Epoch 1127/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 97.2155 - mae: 7.5010 - val_loss: 175.7428 - val_mae: 11.6079\n",
      "Epoch 1128/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 107.5979 - mae: 8.2450 - val_loss: 109.9330 - val_mae: 8.3721\n",
      "Epoch 1129/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 96.1932 - mae: 7.6945 - val_loss: 84.1252 - val_mae: 7.0788\n",
      "Epoch 1130/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 110.8461 - mae: 8.1950 - val_loss: 57.3031 - val_mae: 5.6157\n",
      "Epoch 1131/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 102.4856 - mae: 7.8645 - val_loss: 124.4337 - val_mae: 8.8816\n",
      "Epoch 1132/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 104.1482 - mae: 8.1260 - val_loss: 183.8273 - val_mae: 11.3499\n",
      "Epoch 1133/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 96.9514 - mae: 7.5507 - val_loss: 131.7395 - val_mae: 9.1763\n",
      "Epoch 1134/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 108.3054 - mae: 8.2692 - val_loss: 101.7960 - val_mae: 8.2100\n",
      "Epoch 1135/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 107.5832 - mae: 8.1207 - val_loss: 120.9319 - val_mae: 8.6265\n",
      "Epoch 1136/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 100.8181 - mae: 8.0389 - val_loss: 70.4921 - val_mae: 6.6673\n",
      "Epoch 1137/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 100.8706 - mae: 7.9518 - val_loss: 254.8472 - val_mae: 14.0529\n",
      "Epoch 1138/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 100.5608 - mae: 7.9179 - val_loss: 87.2531 - val_mae: 7.2549\n",
      "Epoch 1139/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 105.5234 - mae: 7.9997 - val_loss: 48.2069 - val_mae: 5.2012\n",
      "Epoch 1140/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 105.8018 - mae: 8.1845 - val_loss: 97.6102 - val_mae: 7.9382\n",
      "Epoch 1141/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 96.3330 - mae: 7.7402 - val_loss: 70.2718 - val_mae: 6.4518\n",
      "Epoch 1142/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 104.0425 - mae: 8.0899 - val_loss: 71.1598 - val_mae: 6.2031\n",
      "Epoch 1143/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 102.2322 - mae: 7.9980 - val_loss: 151.6183 - val_mae: 9.8582\n",
      "Epoch 1144/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 100.9719 - mae: 7.9057 - val_loss: 67.5315 - val_mae: 6.2331\n",
      "Epoch 1145/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 101.8243 - mae: 7.9140 - val_loss: 66.4895 - val_mae: 6.3716\n",
      "Epoch 1146/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 101.6014 - mae: 8.0308 - val_loss: 91.9299 - val_mae: 7.6163\n",
      "Epoch 1147/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 101.3232 - mae: 7.9383 - val_loss: 128.2000 - val_mae: 8.4722\n",
      "Epoch 1148/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 96.0083 - mae: 7.6727 - val_loss: 299.8625 - val_mae: 15.5103\n",
      "Epoch 1149/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 101.8744 - mae: 7.9694 - val_loss: 75.1974 - val_mae: 6.9292\n",
      "Epoch 1150/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 99.6727 - mae: 7.7965 - val_loss: 55.9063 - val_mae: 5.7170\n",
      "Epoch 1151/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 105.4877 - mae: 8.0022 - val_loss: 89.3601 - val_mae: 7.5120\n",
      "Epoch 1152/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 95.7187 - mae: 7.6376 - val_loss: 59.6571 - val_mae: 5.7834\n",
      "Epoch 1153/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 104.9183 - mae: 8.2137 - val_loss: 57.5549 - val_mae: 5.7493\n",
      "Epoch 1154/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 99.5098 - mae: 7.9217 - val_loss: 141.6967 - val_mae: 10.2198\n",
      "Epoch 1155/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 104.0626 - mae: 8.1157 - val_loss: 93.8988 - val_mae: 7.4806\n",
      "Epoch 1156/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 96.4483 - mae: 7.6847 - val_loss: 98.9214 - val_mae: 7.6302\n",
      "Epoch 1157/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 103.3317 - mae: 7.9612 - val_loss: 186.7749 - val_mae: 11.6279\n",
      "Epoch 1158/2000\n",
      "65/65 [==============================] - 1s 11ms/step - loss: 99.8820 - mae: 7.8777 - val_loss: 72.2995 - val_mae: 6.3800\n",
      "Epoch 1159/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 95.7632 - mae: 7.6387 - val_loss: 67.7462 - val_mae: 6.0416\n",
      "Epoch 1160/2000\n",
      "65/65 [==============================] - 1s 11ms/step - loss: 99.5854 - mae: 7.9590 - val_loss: 65.0140 - val_mae: 6.0868\n",
      "Epoch 1161/2000\n",
      "65/65 [==============================] - 1s 11ms/step - loss: 98.8429 - mae: 7.9614 - val_loss: 43.7792 - val_mae: 4.9082\n",
      "Epoch 1162/2000\n",
      "65/65 [==============================] - 1s 11ms/step - loss: 95.5598 - mae: 7.7046 - val_loss: 97.0847 - val_mae: 7.9317\n",
      "Epoch 1163/2000\n",
      "65/65 [==============================] - 1s 13ms/step - loss: 99.3420 - mae: 7.8701 - val_loss: 138.1998 - val_mae: 9.5374\n",
      "Epoch 1164/2000\n",
      "65/65 [==============================] - 1s 12ms/step - loss: 106.1147 - mae: 8.2386 - val_loss: 86.6956 - val_mae: 7.4129\n",
      "Epoch 1165/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 97.4342 - mae: 7.7864 - val_loss: 232.6313 - val_mae: 13.2089\n",
      "Epoch 1166/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 101.9781 - mae: 8.0467 - val_loss: 78.8773 - val_mae: 7.1450\n",
      "Epoch 1167/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 95.7306 - mae: 7.7251 - val_loss: 155.3472 - val_mae: 9.4400\n",
      "Epoch 1168/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 96.4848 - mae: 7.7718 - val_loss: 92.6499 - val_mae: 7.8482\n",
      "Epoch 1169/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 103.0537 - mae: 8.0127 - val_loss: 58.9278 - val_mae: 5.8312\n",
      "Epoch 1170/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 106.5303 - mae: 8.0780 - val_loss: 56.3739 - val_mae: 5.5429\n",
      "Epoch 1171/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 95.6127 - mae: 7.5970 - val_loss: 107.8838 - val_mae: 8.6379\n",
      "Epoch 1172/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 99.6964 - mae: 7.7561 - val_loss: 48.9053 - val_mae: 5.2864\n",
      "Epoch 1173/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 96.8331 - mae: 7.7654 - val_loss: 60.0489 - val_mae: 5.7214\n",
      "Epoch 1174/2000\n",
      "65/65 [==============================] - 1s 11ms/step - loss: 98.5793 - mae: 7.8870 - val_loss: 66.2743 - val_mae: 6.3961\n",
      "Epoch 1175/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 100.1629 - mae: 7.8537 - val_loss: 188.9781 - val_mae: 11.4767\n",
      "Epoch 1176/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 92.3225 - mae: 7.3777 - val_loss: 69.7686 - val_mae: 6.5064\n",
      "Epoch 1177/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 99.9669 - mae: 7.8730 - val_loss: 99.1783 - val_mae: 8.0212\n",
      "Epoch 1178/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 99.5177 - mae: 7.9858 - val_loss: 159.7057 - val_mae: 10.1546\n",
      "Epoch 1179/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 99.1447 - mae: 7.6939 - val_loss: 162.3205 - val_mae: 10.5666\n",
      "Epoch 1180/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 95.3323 - mae: 7.5972 - val_loss: 87.5856 - val_mae: 7.2042\n",
      "Epoch 1181/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 95.1341 - mae: 7.7727 - val_loss: 48.8003 - val_mae: 5.2737\n",
      "Epoch 1182/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 95.4534 - mae: 7.6709 - val_loss: 78.8107 - val_mae: 7.2124\n",
      "Epoch 1183/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 98.4956 - mae: 7.6798 - val_loss: 54.2504 - val_mae: 5.3910\n",
      "Epoch 1184/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 96.5081 - mae: 7.6898 - val_loss: 131.4769 - val_mae: 9.1880\n",
      "Epoch 1185/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 96.2606 - mae: 7.8272 - val_loss: 229.6307 - val_mae: 12.6161\n",
      "Epoch 1186/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 95.6157 - mae: 7.5764 - val_loss: 88.4768 - val_mae: 7.1111\n",
      "Epoch 1187/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 97.3648 - mae: 7.7377 - val_loss: 62.0865 - val_mae: 5.9190\n",
      "Epoch 1188/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 98.7777 - mae: 7.9159 - val_loss: 48.9612 - val_mae: 5.2668\n",
      "Epoch 1189/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 92.5394 - mae: 7.5797 - val_loss: 66.5809 - val_mae: 6.1141\n",
      "Epoch 1190/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 96.6417 - mae: 7.7269 - val_loss: 109.1860 - val_mae: 7.6140\n",
      "Epoch 1191/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 95.7617 - mae: 7.7425 - val_loss: 265.9734 - val_mae: 13.2929\n",
      "Epoch 1192/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 98.6453 - mae: 7.8151 - val_loss: 152.7970 - val_mae: 10.5012\n",
      "Epoch 1193/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 97.8407 - mae: 7.8640 - val_loss: 145.4705 - val_mae: 10.1992\n",
      "Epoch 1194/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 97.1479 - mae: 7.8054 - val_loss: 54.3284 - val_mae: 5.5747\n",
      "Epoch 1195/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 94.1718 - mae: 7.3536 - val_loss: 180.6411 - val_mae: 10.5037\n",
      "Epoch 1196/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 96.7287 - mae: 7.6575 - val_loss: 58.2829 - val_mae: 5.7913\n",
      "Epoch 1197/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 97.6114 - mae: 7.6962 - val_loss: 75.9127 - val_mae: 6.7341\n",
      "Epoch 1198/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 91.7442 - mae: 7.4369 - val_loss: 224.7515 - val_mae: 12.7065\n",
      "Epoch 1199/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 94.2329 - mae: 7.6176 - val_loss: 62.4820 - val_mae: 6.0428\n",
      "Epoch 1200/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 92.1007 - mae: 7.4631 - val_loss: 84.1577 - val_mae: 7.4948\n",
      "Epoch 1201/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 97.2193 - mae: 7.7834 - val_loss: 181.8747 - val_mae: 11.1723\n",
      "Epoch 1202/2000\n",
      "65/65 [==============================] - 1s 11ms/step - loss: 99.8941 - mae: 7.8613 - val_loss: 57.6867 - val_mae: 6.0756\n",
      "Epoch 1203/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 95.8155 - mae: 7.6562 - val_loss: 74.8999 - val_mae: 6.8434\n",
      "Epoch 1204/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 94.5588 - mae: 7.6567 - val_loss: 116.8584 - val_mae: 8.8459\n",
      "Epoch 1205/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 96.6281 - mae: 7.8409 - val_loss: 45.0054 - val_mae: 4.9625\n",
      "Epoch 1206/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 101.3505 - mae: 7.9579 - val_loss: 157.1051 - val_mae: 10.0688\n",
      "Epoch 1207/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 89.5386 - mae: 7.1576 - val_loss: 70.2248 - val_mae: 6.4855\n",
      "Epoch 1208/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 95.0681 - mae: 7.5382 - val_loss: 50.1766 - val_mae: 5.3519\n",
      "Epoch 1209/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 90.8442 - mae: 7.5241 - val_loss: 93.5245 - val_mae: 7.6712\n",
      "Epoch 1210/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 90.5316 - mae: 7.3967 - val_loss: 282.1634 - val_mae: 14.8012\n",
      "Epoch 1211/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 98.4281 - mae: 7.7448 - val_loss: 73.1390 - val_mae: 6.5793\n",
      "Epoch 1212/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 97.4635 - mae: 7.8051 - val_loss: 54.4579 - val_mae: 5.6312\n",
      "Epoch 1213/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 89.5092 - mae: 7.4242 - val_loss: 99.6448 - val_mae: 7.9240\n",
      "Epoch 1214/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 90.0240 - mae: 7.6291 - val_loss: 99.4392 - val_mae: 7.4789\n",
      "Epoch 1215/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 96.5692 - mae: 7.7410 - val_loss: 92.0160 - val_mae: 7.5002\n",
      "Epoch 1216/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 92.8624 - mae: 7.6380 - val_loss: 107.5239 - val_mae: 8.0918\n",
      "Epoch 1217/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 90.7568 - mae: 7.4830 - val_loss: 80.4997 - val_mae: 6.6266\n",
      "Epoch 1218/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 94.8532 - mae: 7.7682 - val_loss: 57.1054 - val_mae: 5.7621\n",
      "Epoch 1219/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 92.2607 - mae: 7.6157 - val_loss: 75.4549 - val_mae: 6.5264\n",
      "Epoch 1220/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 101.0238 - mae: 8.0338 - val_loss: 117.0234 - val_mae: 8.6467\n",
      "Epoch 1221/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 91.5065 - mae: 7.6882 - val_loss: 74.1575 - val_mae: 6.9238\n",
      "Epoch 1222/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 94.0278 - mae: 7.6330 - val_loss: 108.3717 - val_mae: 8.6995\n",
      "Epoch 1223/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 90.4850 - mae: 7.5178 - val_loss: 44.5120 - val_mae: 5.0336\n",
      "Epoch 1224/2000\n",
      "65/65 [==============================] - 1s 12ms/step - loss: 97.0439 - mae: 7.7135 - val_loss: 58.5577 - val_mae: 5.8721\n",
      "Epoch 1225/2000\n",
      "65/65 [==============================] - 1s 11ms/step - loss: 91.4998 - mae: 7.5692 - val_loss: 100.0938 - val_mae: 8.4094\n",
      "Epoch 1226/2000\n",
      "65/65 [==============================] - 1s 11ms/step - loss: 90.8982 - mae: 7.5389 - val_loss: 119.7798 - val_mae: 7.8498\n",
      "Epoch 1227/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 93.6998 - mae: 7.6166 - val_loss: 65.0338 - val_mae: 6.2523\n",
      "Epoch 1228/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 93.3910 - mae: 7.6711 - val_loss: 66.9332 - val_mae: 6.2967\n",
      "Epoch 1229/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 93.1268 - mae: 7.6072 - val_loss: 96.4483 - val_mae: 7.6249\n",
      "Epoch 1230/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 94.4572 - mae: 7.7556 - val_loss: 104.2997 - val_mae: 8.1587\n",
      "Epoch 1231/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 95.0077 - mae: 7.7544 - val_loss: 84.3057 - val_mae: 7.2585\n",
      "Epoch 1232/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 94.0132 - mae: 7.5783 - val_loss: 103.8234 - val_mae: 8.3444\n",
      "Epoch 1233/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 89.6117 - mae: 7.5595 - val_loss: 93.8824 - val_mae: 7.7033\n",
      "Epoch 1234/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 88.1900 - mae: 7.4530 - val_loss: 222.0163 - val_mae: 12.5295\n",
      "Epoch 1235/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 95.6378 - mae: 7.7997 - val_loss: 155.3426 - val_mae: 10.4609\n",
      "Epoch 1236/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 87.6941 - mae: 7.2898 - val_loss: 54.3665 - val_mae: 5.3792\n",
      "Epoch 1237/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 96.5521 - mae: 7.8458 - val_loss: 86.8257 - val_mae: 7.6717\n",
      "Epoch 1238/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 94.7893 - mae: 7.6445 - val_loss: 68.4919 - val_mae: 6.6221\n",
      "Epoch 1239/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 87.9132 - mae: 7.3689 - val_loss: 50.5987 - val_mae: 5.5225\n",
      "Epoch 1240/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 92.5039 - mae: 7.7358 - val_loss: 128.2806 - val_mae: 9.0420\n",
      "Epoch 1241/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 89.6491 - mae: 7.4875 - val_loss: 125.3047 - val_mae: 8.6880\n",
      "Epoch 1242/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 87.1959 - mae: 7.3995 - val_loss: 112.5561 - val_mae: 8.7709\n",
      "Epoch 1243/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 94.8632 - mae: 7.5969 - val_loss: 181.6910 - val_mae: 11.3439\n",
      "Epoch 1244/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 88.1738 - mae: 7.3650 - val_loss: 50.5286 - val_mae: 5.4438\n",
      "Epoch 1245/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 89.2818 - mae: 7.3159 - val_loss: 55.5074 - val_mae: 5.7956\n",
      "Epoch 1246/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 88.0134 - mae: 7.3122 - val_loss: 121.4628 - val_mae: 8.5745\n",
      "Epoch 1247/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 92.5292 - mae: 7.6518 - val_loss: 56.8018 - val_mae: 5.7841\n",
      "Epoch 1248/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 93.1247 - mae: 7.6628 - val_loss: 58.5579 - val_mae: 5.8161\n",
      "Epoch 1249/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 90.3301 - mae: 7.3194 - val_loss: 70.9856 - val_mae: 6.6319\n",
      "Epoch 1250/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 82.5791 - mae: 7.1507 - val_loss: 123.8599 - val_mae: 8.8835\n",
      "Epoch 1251/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 91.0233 - mae: 7.6297 - val_loss: 48.9277 - val_mae: 5.3716\n",
      "Epoch 1252/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 89.1273 - mae: 7.2487 - val_loss: 168.7822 - val_mae: 10.3932\n",
      "Epoch 1253/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 88.6330 - mae: 7.2502 - val_loss: 83.4378 - val_mae: 7.1811\n",
      "Epoch 1254/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 87.4634 - mae: 7.1895 - val_loss: 158.0638 - val_mae: 10.4944\n",
      "Epoch 1255/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 94.0403 - mae: 7.6013 - val_loss: 80.9155 - val_mae: 7.0781\n",
      "Epoch 1256/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 91.9727 - mae: 7.6331 - val_loss: 45.6639 - val_mae: 5.1264\n",
      "Epoch 1257/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 89.2939 - mae: 7.5580 - val_loss: 56.2537 - val_mae: 5.7525\n",
      "Epoch 1258/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 90.1408 - mae: 7.5391 - val_loss: 83.6791 - val_mae: 6.6922\n",
      "Epoch 1259/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 89.9274 - mae: 7.5932 - val_loss: 65.2382 - val_mae: 6.1556\n",
      "Epoch 1260/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 93.3255 - mae: 7.5874 - val_loss: 77.8666 - val_mae: 7.0654\n",
      "Epoch 1261/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 94.1946 - mae: 7.8090 - val_loss: 45.3752 - val_mae: 5.0327\n",
      "Epoch 1262/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 88.2711 - mae: 7.3526 - val_loss: 124.4303 - val_mae: 9.2150\n",
      "Epoch 1263/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 86.9144 - mae: 7.4663 - val_loss: 144.9843 - val_mae: 9.2291\n",
      "Epoch 1264/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 96.6972 - mae: 7.7393 - val_loss: 55.3144 - val_mae: 5.6797\n",
      "Epoch 1265/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 90.2285 - mae: 7.4931 - val_loss: 75.9097 - val_mae: 6.6025\n",
      "Epoch 1266/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 85.7495 - mae: 7.2684 - val_loss: 72.8292 - val_mae: 6.7664\n",
      "Epoch 1267/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 85.1059 - mae: 7.2284 - val_loss: 100.2291 - val_mae: 8.2106\n",
      "Epoch 1268/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 90.3283 - mae: 7.5891 - val_loss: 115.4778 - val_mae: 9.0932\n",
      "Epoch 1269/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 84.5050 - mae: 7.1625 - val_loss: 67.0331 - val_mae: 6.4092\n",
      "Epoch 1270/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 88.9277 - mae: 7.4104 - val_loss: 77.2787 - val_mae: 6.8904\n",
      "Epoch 1271/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 93.6586 - mae: 7.5864 - val_loss: 43.8446 - val_mae: 4.9270\n",
      "Epoch 1272/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 87.4665 - mae: 7.4383 - val_loss: 123.2714 - val_mae: 9.0881\n",
      "Epoch 1273/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 85.7681 - mae: 7.2019 - val_loss: 191.8550 - val_mae: 11.3190\n",
      "Epoch 1274/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 90.1696 - mae: 7.4375 - val_loss: 103.5776 - val_mae: 7.5977\n",
      "Epoch 1275/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 84.4287 - mae: 7.2809 - val_loss: 108.8494 - val_mae: 8.6598\n",
      "Epoch 1276/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 90.4932 - mae: 7.3463 - val_loss: 77.2575 - val_mae: 6.8464\n",
      "Epoch 1277/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 85.4666 - mae: 7.3779 - val_loss: 151.8606 - val_mae: 10.5058\n",
      "Epoch 1278/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 89.2452 - mae: 7.5451 - val_loss: 148.8162 - val_mae: 10.0946\n",
      "Epoch 1279/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 87.0677 - mae: 7.2171 - val_loss: 63.6701 - val_mae: 6.1258\n",
      "Epoch 1280/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 93.4327 - mae: 7.7040 - val_loss: 52.0678 - val_mae: 5.3466\n",
      "Epoch 1281/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 86.2797 - mae: 7.2910 - val_loss: 94.6662 - val_mae: 7.8429\n",
      "Epoch 1282/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 89.5482 - mae: 7.4694 - val_loss: 53.8497 - val_mae: 5.6371\n",
      "Epoch 1283/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 91.5550 - mae: 7.3377 - val_loss: 74.3404 - val_mae: 6.8362\n",
      "Epoch 1284/2000\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 79.2194 - mae: 7.0800 - val_loss: 195.2814 - val_mae: 10.9091\n",
      "Epoch 1285/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 89.7693 - mae: 7.6070 - val_loss: 206.5090 - val_mae: 12.2114\n",
      "Epoch 1286/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 88.6823 - mae: 7.3628 - val_loss: 40.2347 - val_mae: 4.7744\n",
      "Epoch 1287/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 82.2539 - mae: 6.8972 - val_loss: 83.4613 - val_mae: 7.2745\n",
      "Epoch 1288/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 92.9626 - mae: 7.7682 - val_loss: 70.7907 - val_mae: 6.4782\n",
      "Epoch 1289/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 85.5274 - mae: 7.1988 - val_loss: 226.0741 - val_mae: 12.4717\n",
      "Epoch 1290/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 89.5421 - mae: 7.4272 - val_loss: 160.0825 - val_mae: 10.6513\n",
      "Epoch 1291/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 87.7664 - mae: 7.3432 - val_loss: 77.8705 - val_mae: 6.7958\n",
      "Epoch 1292/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 82.3444 - mae: 7.0648 - val_loss: 66.6235 - val_mae: 6.5137\n",
      "Epoch 1293/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 85.4829 - mae: 7.3487 - val_loss: 40.1503 - val_mae: 4.7554\n",
      "Epoch 1294/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 88.3995 - mae: 7.4201 - val_loss: 169.5532 - val_mae: 10.8410\n",
      "Epoch 1295/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 87.5163 - mae: 7.5032 - val_loss: 90.0417 - val_mae: 7.5728\n",
      "Epoch 1296/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 83.7943 - mae: 7.1816 - val_loss: 57.2475 - val_mae: 5.7839\n",
      "Epoch 1297/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 86.6593 - mae: 7.4133 - val_loss: 89.4487 - val_mae: 7.6154\n",
      "Epoch 1298/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 87.7324 - mae: 7.3565 - val_loss: 71.0937 - val_mae: 6.5488\n",
      "Epoch 1299/2000\n",
      "65/65 [==============================] - 1s 11ms/step - loss: 90.2681 - mae: 7.5219 - val_loss: 52.7805 - val_mae: 5.6326\n",
      "Epoch 1300/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 81.3868 - mae: 7.1174 - val_loss: 127.1977 - val_mae: 9.2145\n",
      "Epoch 1301/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 87.9708 - mae: 7.1975 - val_loss: 158.3053 - val_mae: 9.8206\n",
      "Epoch 1302/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 89.1205 - mae: 7.4174 - val_loss: 50.0671 - val_mae: 5.4266\n",
      "Epoch 1303/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 79.2580 - mae: 6.9608 - val_loss: 126.1873 - val_mae: 9.3671\n",
      "Epoch 1304/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 87.0232 - mae: 7.4307 - val_loss: 130.5499 - val_mae: 9.5509\n",
      "Epoch 1305/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 91.1078 - mae: 7.4995 - val_loss: 71.7125 - val_mae: 6.3786\n",
      "Epoch 1306/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 86.1592 - mae: 7.2608 - val_loss: 83.2096 - val_mae: 7.4654\n",
      "Epoch 1307/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 85.2181 - mae: 7.3228 - val_loss: 73.6527 - val_mae: 6.7666\n",
      "Epoch 1308/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 90.5830 - mae: 7.6661 - val_loss: 56.9438 - val_mae: 5.8905\n",
      "Epoch 1309/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 82.5508 - mae: 7.1493 - val_loss: 131.2025 - val_mae: 8.3554\n",
      "Epoch 1310/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 87.1041 - mae: 7.3139 - val_loss: 133.1419 - val_mae: 9.6663\n",
      "Epoch 1311/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 82.3402 - mae: 7.3473 - val_loss: 181.6904 - val_mae: 10.6051\n",
      "Epoch 1312/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 86.5029 - mae: 7.3364 - val_loss: 98.5909 - val_mae: 7.8219\n",
      "Epoch 1313/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 89.8262 - mae: 7.5603 - val_loss: 199.0430 - val_mae: 11.3812\n",
      "Epoch 1314/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 86.6346 - mae: 7.3934 - val_loss: 81.3683 - val_mae: 7.2081\n",
      "Epoch 1315/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 84.3203 - mae: 7.2831 - val_loss: 127.6881 - val_mae: 8.8632\n",
      "Epoch 1316/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 87.7600 - mae: 7.5746 - val_loss: 65.2717 - val_mae: 6.2851\n",
      "Epoch 1317/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 82.6385 - mae: 7.2837 - val_loss: 78.5140 - val_mae: 7.1431\n",
      "Epoch 1318/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 86.8448 - mae: 7.4843 - val_loss: 54.0635 - val_mae: 5.8412\n",
      "Epoch 1319/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 85.2646 - mae: 7.2587 - val_loss: 32.8571 - val_mae: 4.1837\n",
      "Epoch 1320/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 82.0757 - mae: 7.1264 - val_loss: 114.3973 - val_mae: 8.7080\n",
      "Epoch 1321/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 81.5841 - mae: 7.1017 - val_loss: 52.4377 - val_mae: 5.3840\n",
      "Epoch 1322/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 85.4216 - mae: 7.3232 - val_loss: 199.9196 - val_mae: 12.3841\n",
      "Epoch 1323/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 83.5625 - mae: 7.1430 - val_loss: 358.4996 - val_mae: 17.7362\n",
      "Epoch 1324/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 81.8409 - mae: 7.0361 - val_loss: 126.1465 - val_mae: 8.9941\n",
      "Epoch 1325/2000\n",
      "65/65 [==============================] - 1s 11ms/step - loss: 85.6751 - mae: 7.3379 - val_loss: 328.8228 - val_mae: 14.1557\n",
      "Epoch 1326/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 78.6482 - mae: 6.7516 - val_loss: 197.0059 - val_mae: 12.4704\n",
      "Epoch 1327/2000\n",
      "65/65 [==============================] - 1s 11ms/step - loss: 89.9060 - mae: 7.4117 - val_loss: 57.1532 - val_mae: 5.9353\n",
      "Epoch 1328/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 83.8769 - mae: 7.1691 - val_loss: 118.3770 - val_mae: 8.5190\n",
      "Epoch 1329/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 81.6374 - mae: 7.0564 - val_loss: 48.3916 - val_mae: 5.3390\n",
      "Epoch 1330/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 89.4181 - mae: 7.3611 - val_loss: 47.6807 - val_mae: 5.3854\n",
      "Epoch 1331/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 82.7588 - mae: 7.2541 - val_loss: 50.7840 - val_mae: 5.4601\n",
      "Epoch 1332/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 84.6420 - mae: 7.2605 - val_loss: 46.6940 - val_mae: 5.1533\n",
      "Epoch 1333/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 80.8444 - mae: 7.1275 - val_loss: 102.1019 - val_mae: 7.8362\n",
      "Epoch 1334/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 89.0548 - mae: 7.4604 - val_loss: 65.7143 - val_mae: 6.3910\n",
      "Epoch 1335/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 79.0521 - mae: 6.9859 - val_loss: 58.2833 - val_mae: 6.0513\n",
      "Epoch 1336/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 79.4308 - mae: 6.9813 - val_loss: 133.6313 - val_mae: 9.7361\n",
      "Epoch 1337/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 85.5523 - mae: 7.2730 - val_loss: 79.2471 - val_mae: 7.1747\n",
      "Epoch 1338/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 89.3981 - mae: 7.6743 - val_loss: 149.4156 - val_mae: 10.5614\n",
      "Epoch 1339/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 79.5539 - mae: 6.9673 - val_loss: 37.3936 - val_mae: 4.6542\n",
      "Epoch 1340/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 85.4733 - mae: 7.2674 - val_loss: 129.8080 - val_mae: 9.7259\n",
      "Epoch 1341/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 78.7173 - mae: 6.9509 - val_loss: 169.3758 - val_mae: 11.2737\n",
      "Epoch 1342/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 86.8898 - mae: 7.3423 - val_loss: 119.8636 - val_mae: 8.4724\n",
      "Epoch 1343/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 88.0455 - mae: 7.5123 - val_loss: 61.6516 - val_mae: 6.0123\n",
      "Epoch 1344/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 82.1987 - mae: 7.0694 - val_loss: 69.6210 - val_mae: 6.2212\n",
      "Epoch 1345/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 81.5884 - mae: 7.3410 - val_loss: 145.4536 - val_mae: 9.4627\n",
      "Epoch 1346/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 83.0630 - mae: 6.9734 - val_loss: 70.7718 - val_mae: 6.7778\n",
      "Epoch 1347/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 84.6439 - mae: 7.3910 - val_loss: 46.9880 - val_mae: 5.2982\n",
      "Epoch 1348/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 83.6047 - mae: 7.1647 - val_loss: 101.1409 - val_mae: 8.2110\n",
      "Epoch 1349/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 78.2612 - mae: 6.9521 - val_loss: 88.1945 - val_mae: 6.9927\n",
      "Epoch 1350/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 82.8222 - mae: 7.1849 - val_loss: 110.9701 - val_mae: 8.5715\n",
      "Epoch 1351/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 80.2915 - mae: 7.0956 - val_loss: 116.4993 - val_mae: 8.8567\n",
      "Epoch 1352/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 81.4293 - mae: 7.1961 - val_loss: 58.7635 - val_mae: 6.0563\n",
      "Epoch 1353/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 84.2872 - mae: 7.2791 - val_loss: 41.4852 - val_mae: 4.9130\n",
      "Epoch 1354/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 82.6717 - mae: 7.0627 - val_loss: 64.1333 - val_mae: 6.3260\n",
      "Epoch 1355/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 77.6950 - mae: 6.9852 - val_loss: 73.7370 - val_mae: 6.6177\n",
      "Epoch 1356/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 83.4226 - mae: 7.1359 - val_loss: 44.0675 - val_mae: 4.8900\n",
      "Epoch 1357/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 78.4995 - mae: 6.9843 - val_loss: 106.4872 - val_mae: 7.7723\n",
      "Epoch 1358/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 86.9370 - mae: 7.5079 - val_loss: 54.6924 - val_mae: 5.4494\n",
      "Epoch 1359/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 77.3752 - mae: 6.8522 - val_loss: 157.1963 - val_mae: 9.7658\n",
      "Epoch 1360/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 81.3561 - mae: 6.9538 - val_loss: 51.9910 - val_mae: 5.6632\n",
      "Epoch 1361/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 85.1815 - mae: 7.3997 - val_loss: 108.1491 - val_mae: 8.1550\n",
      "Epoch 1362/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 81.4952 - mae: 7.3283 - val_loss: 81.7361 - val_mae: 7.3878\n",
      "Epoch 1363/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 83.9610 - mae: 7.3919 - val_loss: 172.7430 - val_mae: 11.6297\n",
      "Epoch 1364/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 78.5806 - mae: 7.0204 - val_loss: 117.5652 - val_mae: 8.6033\n",
      "Epoch 1365/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 81.1963 - mae: 7.0634 - val_loss: 55.6081 - val_mae: 5.8428\n",
      "Epoch 1366/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 82.5111 - mae: 7.0713 - val_loss: 43.7331 - val_mae: 4.9112\n",
      "Epoch 1367/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 85.9713 - mae: 7.4708 - val_loss: 66.9118 - val_mae: 6.4470\n",
      "Epoch 1368/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 77.6225 - mae: 6.9173 - val_loss: 121.2867 - val_mae: 9.1417\n",
      "Epoch 1369/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 83.0160 - mae: 7.3101 - val_loss: 58.1316 - val_mae: 5.9151\n",
      "Epoch 1370/2000\n",
      "65/65 [==============================] - 1s 11ms/step - loss: 79.2828 - mae: 7.0227 - val_loss: 79.8011 - val_mae: 7.1380\n",
      "Epoch 1371/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 79.3959 - mae: 7.0332 - val_loss: 120.4278 - val_mae: 8.9403\n",
      "Epoch 1372/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 79.6091 - mae: 6.8173 - val_loss: 234.0144 - val_mae: 12.3490\n",
      "Epoch 1373/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 78.9027 - mae: 7.0186 - val_loss: 80.5023 - val_mae: 7.3406\n",
      "Epoch 1374/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 82.5441 - mae: 6.9358 - val_loss: 152.0987 - val_mae: 9.4694\n",
      "Epoch 1375/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 83.9099 - mae: 7.1857 - val_loss: 50.8259 - val_mae: 5.3573\n",
      "Epoch 1376/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 72.3200 - mae: 6.6431 - val_loss: 34.3198 - val_mae: 4.3671\n",
      "Epoch 1377/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 85.4802 - mae: 7.2547 - val_loss: 147.0797 - val_mae: 9.5539\n",
      "Epoch 1378/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 77.4855 - mae: 7.0780 - val_loss: 75.3315 - val_mae: 6.8295\n",
      "Epoch 1379/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 80.2887 - mae: 7.1320 - val_loss: 144.7409 - val_mae: 9.1685\n",
      "Epoch 1380/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 83.9368 - mae: 7.3340 - val_loss: 90.4930 - val_mae: 7.7176\n",
      "Epoch 1381/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 83.0189 - mae: 7.1640 - val_loss: 43.2469 - val_mae: 5.0391\n",
      "Epoch 1382/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 76.0458 - mae: 6.8772 - val_loss: 105.3521 - val_mae: 8.3494\n",
      "Epoch 1383/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 81.7794 - mae: 7.2159 - val_loss: 46.9639 - val_mae: 5.2571\n",
      "Epoch 1384/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 85.5398 - mae: 7.2956 - val_loss: 40.4470 - val_mae: 4.7855\n",
      "Epoch 1385/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 72.8909 - mae: 6.6085 - val_loss: 206.7213 - val_mae: 12.0129\n",
      "Epoch 1386/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 82.9954 - mae: 7.0699 - val_loss: 63.8261 - val_mae: 6.3272\n",
      "Epoch 1387/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 82.8432 - mae: 7.1873 - val_loss: 75.6316 - val_mae: 6.9760\n",
      "Epoch 1388/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 79.0219 - mae: 7.1079 - val_loss: 40.3727 - val_mae: 4.9192\n",
      "Epoch 1389/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 79.4722 - mae: 7.1938 - val_loss: 54.8130 - val_mae: 5.6095\n",
      "Epoch 1390/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 75.2139 - mae: 6.8501 - val_loss: 50.6320 - val_mae: 5.5597\n",
      "Epoch 1391/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 75.7874 - mae: 6.9179 - val_loss: 112.9893 - val_mae: 8.7756\n",
      "Epoch 1392/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 86.3733 - mae: 7.5055 - val_loss: 49.9653 - val_mae: 5.3158\n",
      "Epoch 1393/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 78.4393 - mae: 6.8628 - val_loss: 42.4630 - val_mae: 4.8149\n",
      "Epoch 1394/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 84.9747 - mae: 7.0346 - val_loss: 109.4024 - val_mae: 8.7576\n",
      "Epoch 1395/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 73.2281 - mae: 6.5904 - val_loss: 106.0981 - val_mae: 7.9382\n",
      "Epoch 1396/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 86.0083 - mae: 7.1964 - val_loss: 49.2305 - val_mae: 5.2476\n",
      "Epoch 1397/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 77.7701 - mae: 6.8310 - val_loss: 129.9886 - val_mae: 9.4046\n",
      "Epoch 1398/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 79.1715 - mae: 6.9644 - val_loss: 99.3338 - val_mae: 7.8931\n",
      "Epoch 1399/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 77.3245 - mae: 6.9898 - val_loss: 139.0854 - val_mae: 10.0093\n",
      "Epoch 1400/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 76.4062 - mae: 6.8364 - val_loss: 105.3822 - val_mae: 8.2414\n",
      "Epoch 1401/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 76.1331 - mae: 7.0203 - val_loss: 141.9393 - val_mae: 9.1349\n",
      "Epoch 1402/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 77.4273 - mae: 6.9349 - val_loss: 128.3283 - val_mae: 9.2562\n",
      "Epoch 1403/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 74.3624 - mae: 6.8035 - val_loss: 119.5475 - val_mae: 8.9142\n",
      "Epoch 1404/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 78.2715 - mae: 7.0512 - val_loss: 48.3106 - val_mae: 5.2217\n",
      "Epoch 1405/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 82.1707 - mae: 7.1645 - val_loss: 65.5828 - val_mae: 6.3602\n",
      "Epoch 1406/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 79.0764 - mae: 7.1058 - val_loss: 56.6163 - val_mae: 6.0583\n",
      "Epoch 1407/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 81.1900 - mae: 7.1761 - val_loss: 68.9837 - val_mae: 6.6782\n",
      "Epoch 1408/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 79.4691 - mae: 7.0542 - val_loss: 142.1605 - val_mae: 9.9877\n",
      "Epoch 1409/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 77.6111 - mae: 6.9729 - val_loss: 169.3277 - val_mae: 11.3216\n",
      "Epoch 1410/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 79.7826 - mae: 6.9951 - val_loss: 65.8057 - val_mae: 6.2362\n",
      "Epoch 1411/2000\n",
      "65/65 [==============================] - 1s 12ms/step - loss: 75.9550 - mae: 6.8766 - val_loss: 109.4113 - val_mae: 8.4974\n",
      "Epoch 1412/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 83.7886 - mae: 7.0745 - val_loss: 87.7976 - val_mae: 7.2040\n",
      "Epoch 1413/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 76.8641 - mae: 6.8655 - val_loss: 50.7844 - val_mae: 5.4427\n",
      "Epoch 1414/2000\n",
      "65/65 [==============================] - 1s 12ms/step - loss: 75.4751 - mae: 6.8725 - val_loss: 141.6264 - val_mae: 9.6300\n",
      "Epoch 1415/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 75.7567 - mae: 6.8274 - val_loss: 183.7819 - val_mae: 11.1968\n",
      "Epoch 1416/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 80.4728 - mae: 7.1925 - val_loss: 63.4663 - val_mae: 6.1734\n",
      "Epoch 1417/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 75.1405 - mae: 6.7994 - val_loss: 79.1082 - val_mae: 7.0418\n",
      "Epoch 1418/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 79.1034 - mae: 6.7322 - val_loss: 53.3461 - val_mae: 5.6680\n",
      "Epoch 1419/2000\n",
      "65/65 [==============================] - 1s 14ms/step - loss: 75.7875 - mae: 6.8375 - val_loss: 69.8498 - val_mae: 6.8301\n",
      "Epoch 1420/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 77.9951 - mae: 6.9768 - val_loss: 71.6643 - val_mae: 6.3855\n",
      "Epoch 1421/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 77.5065 - mae: 7.0109 - val_loss: 81.1415 - val_mae: 7.2771\n",
      "Epoch 1422/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 77.4439 - mae: 6.9837 - val_loss: 54.0106 - val_mae: 5.8596\n",
      "Epoch 1423/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 71.6843 - mae: 6.5644 - val_loss: 71.1299 - val_mae: 6.7675\n",
      "Epoch 1424/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 82.7971 - mae: 7.0493 - val_loss: 92.1719 - val_mae: 7.8533\n",
      "Epoch 1425/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 76.6368 - mae: 6.8195 - val_loss: 75.9750 - val_mae: 7.0819\n",
      "Epoch 1426/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 78.8574 - mae: 6.9098 - val_loss: 86.6067 - val_mae: 7.5604\n",
      "Epoch 1427/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 77.0651 - mae: 6.9351 - val_loss: 131.2605 - val_mae: 8.6377\n",
      "Epoch 1428/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 78.7352 - mae: 6.9609 - val_loss: 134.0542 - val_mae: 8.9071\n",
      "Epoch 1429/2000\n",
      "65/65 [==============================] - 1s 12ms/step - loss: 75.3075 - mae: 6.8069 - val_loss: 152.1570 - val_mae: 10.4059\n",
      "Epoch 1430/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 73.9833 - mae: 6.6656 - val_loss: 68.2644 - val_mae: 6.3788\n",
      "Epoch 1431/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 76.9223 - mae: 6.8657 - val_loss: 89.3184 - val_mae: 7.7693\n",
      "Epoch 1432/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 81.1372 - mae: 7.1010 - val_loss: 63.4811 - val_mae: 6.1924\n",
      "Epoch 1433/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 71.0504 - mae: 6.6638 - val_loss: 67.6761 - val_mae: 6.3461\n",
      "Epoch 1434/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 75.3621 - mae: 6.9885 - val_loss: 48.3706 - val_mae: 5.2544\n",
      "Epoch 1435/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 80.8516 - mae: 6.9937 - val_loss: 83.5127 - val_mae: 6.9812\n",
      "Epoch 1436/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 77.4964 - mae: 7.0430 - val_loss: 130.0582 - val_mae: 9.5518\n",
      "Epoch 1437/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 78.9857 - mae: 7.0720 - val_loss: 63.9541 - val_mae: 6.2005\n",
      "Epoch 1438/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 74.9911 - mae: 6.8240 - val_loss: 56.8735 - val_mae: 6.0530\n",
      "Epoch 1439/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 77.2045 - mae: 7.0004 - val_loss: 96.3373 - val_mae: 7.7180\n",
      "Epoch 1440/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 74.9394 - mae: 6.7717 - val_loss: 49.2503 - val_mae: 5.4174\n",
      "Epoch 1441/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 77.9787 - mae: 7.0451 - val_loss: 120.3192 - val_mae: 8.9581\n",
      "Epoch 1442/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 75.3806 - mae: 6.7602 - val_loss: 71.9762 - val_mae: 6.6569\n",
      "Epoch 1443/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 75.2197 - mae: 6.9218 - val_loss: 52.4976 - val_mae: 5.6802\n",
      "Epoch 1444/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 77.4162 - mae: 7.0157 - val_loss: 101.8959 - val_mae: 8.4636\n",
      "Epoch 1445/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 80.8142 - mae: 7.0715 - val_loss: 117.9050 - val_mae: 8.7565\n",
      "Epoch 1446/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 75.8549 - mae: 6.8333 - val_loss: 42.2441 - val_mae: 5.0113\n",
      "Epoch 1447/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 78.7763 - mae: 7.2336 - val_loss: 176.4826 - val_mae: 10.7109\n",
      "Epoch 1448/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 76.8380 - mae: 6.8195 - val_loss: 106.3905 - val_mae: 8.0918\n",
      "Epoch 1449/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 75.3615 - mae: 6.9142 - val_loss: 52.0156 - val_mae: 5.6168\n",
      "Epoch 1450/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 80.8045 - mae: 7.1122 - val_loss: 124.0181 - val_mae: 9.3710\n",
      "Epoch 1451/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 71.8454 - mae: 6.7827 - val_loss: 100.1875 - val_mae: 8.2843\n",
      "Epoch 1452/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 79.2256 - mae: 6.8772 - val_loss: 68.1505 - val_mae: 6.5723\n",
      "Epoch 1453/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 77.4716 - mae: 7.0716 - val_loss: 84.9572 - val_mae: 7.2709\n",
      "Epoch 1454/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 75.9447 - mae: 6.9229 - val_loss: 34.5503 - val_mae: 4.5494\n",
      "Epoch 1455/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 73.9430 - mae: 6.6324 - val_loss: 153.1443 - val_mae: 10.6716\n",
      "Epoch 1456/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 79.0678 - mae: 7.0209 - val_loss: 83.3856 - val_mae: 7.4364\n",
      "Epoch 1457/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 72.2763 - mae: 6.8241 - val_loss: 108.4421 - val_mae: 8.5494\n",
      "Epoch 1458/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 78.2782 - mae: 6.9475 - val_loss: 63.4032 - val_mae: 6.1761\n",
      "Epoch 1459/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 75.6832 - mae: 6.9986 - val_loss: 58.8916 - val_mae: 5.9322\n",
      "Epoch 1460/2000\n",
      "65/65 [==============================] - 1s 11ms/step - loss: 73.5003 - mae: 6.6906 - val_loss: 92.1830 - val_mae: 7.6495\n",
      "Epoch 1461/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 78.6721 - mae: 6.9817 - val_loss: 42.3583 - val_mae: 4.8579\n",
      "Epoch 1462/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 76.9041 - mae: 6.9348 - val_loss: 67.2629 - val_mae: 6.2755\n",
      "Epoch 1463/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 70.9259 - mae: 6.7300 - val_loss: 117.9729 - val_mae: 8.2858\n",
      "Epoch 1464/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 78.2462 - mae: 6.9210 - val_loss: 59.3986 - val_mae: 5.8491\n",
      "Epoch 1465/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 69.9799 - mae: 6.6598 - val_loss: 40.5713 - val_mae: 4.7455\n",
      "Epoch 1466/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 77.5833 - mae: 6.9998 - val_loss: 41.6231 - val_mae: 4.8439\n",
      "Epoch 1467/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 83.0466 - mae: 7.3252 - val_loss: 75.2370 - val_mae: 6.5645\n",
      "Epoch 1468/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 73.7334 - mae: 6.8351 - val_loss: 46.1322 - val_mae: 5.4007\n",
      "Epoch 1469/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 73.6698 - mae: 6.7437 - val_loss: 98.3823 - val_mae: 8.2664\n",
      "Epoch 1470/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 74.9511 - mae: 6.9432 - val_loss: 105.1653 - val_mae: 8.5480\n",
      "Epoch 1471/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 72.5407 - mae: 6.7213 - val_loss: 34.2227 - val_mae: 4.4009\n",
      "Epoch 1472/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 76.5719 - mae: 7.0527 - val_loss: 54.3513 - val_mae: 5.7239\n",
      "Epoch 1473/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 70.3225 - mae: 6.5045 - val_loss: 96.0305 - val_mae: 7.8772\n",
      "Epoch 1474/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 79.8300 - mae: 7.0733 - val_loss: 72.4950 - val_mae: 6.7093\n",
      "Epoch 1475/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 73.2828 - mae: 6.7079 - val_loss: 54.4964 - val_mae: 5.9927\n",
      "Epoch 1476/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 75.3566 - mae: 6.9885 - val_loss: 36.2423 - val_mae: 4.5907\n",
      "Epoch 1477/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 75.2905 - mae: 6.6912 - val_loss: 69.3335 - val_mae: 6.4355\n",
      "Epoch 1478/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 76.0138 - mae: 6.8344 - val_loss: 69.7528 - val_mae: 6.2244\n",
      "Epoch 1479/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 77.0435 - mae: 7.0641 - val_loss: 58.6406 - val_mae: 6.2061\n",
      "Epoch 1480/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 78.8938 - mae: 7.0927 - val_loss: 89.5481 - val_mae: 7.6370\n",
      "Epoch 1481/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 73.1952 - mae: 6.6413 - val_loss: 81.4974 - val_mae: 6.9727\n",
      "Epoch 1482/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 72.3334 - mae: 6.6745 - val_loss: 73.1971 - val_mae: 6.8677\n",
      "Epoch 1483/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 70.8761 - mae: 6.6605 - val_loss: 163.4353 - val_mae: 11.4540\n",
      "Epoch 1484/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 75.2455 - mae: 6.9305 - val_loss: 86.1511 - val_mae: 7.4398\n",
      "Epoch 1485/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 73.8970 - mae: 6.8401 - val_loss: 104.7883 - val_mae: 8.4505\n",
      "Epoch 1486/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 79.9613 - mae: 7.1638 - val_loss: 96.5801 - val_mae: 7.7911\n",
      "Epoch 1487/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 72.9793 - mae: 6.8670 - val_loss: 81.0716 - val_mae: 7.4483\n",
      "Epoch 1488/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 75.5202 - mae: 6.9550 - val_loss: 39.6411 - val_mae: 4.9231\n",
      "Epoch 1489/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 72.3442 - mae: 6.6166 - val_loss: 144.1577 - val_mae: 9.6345\n",
      "Epoch 1490/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 77.3436 - mae: 7.0711 - val_loss: 94.6759 - val_mae: 7.9129\n",
      "Epoch 1491/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 74.2340 - mae: 6.8489 - val_loss: 77.5437 - val_mae: 6.8195\n",
      "Epoch 1492/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 72.3286 - mae: 6.7292 - val_loss: 33.9125 - val_mae: 4.5006\n",
      "Epoch 1493/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 72.7287 - mae: 6.7914 - val_loss: 159.8924 - val_mae: 10.9580\n",
      "Epoch 1494/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 72.7932 - mae: 6.7476 - val_loss: 48.8687 - val_mae: 5.3583\n",
      "Epoch 1495/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 77.6279 - mae: 6.9471 - val_loss: 39.9606 - val_mae: 4.9267\n",
      "Epoch 1496/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 70.8497 - mae: 6.6100 - val_loss: 150.8016 - val_mae: 10.4743\n",
      "Epoch 1497/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 74.5049 - mae: 6.7727 - val_loss: 95.7774 - val_mae: 8.2455\n",
      "Epoch 1498/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 71.6862 - mae: 6.5549 - val_loss: 65.1956 - val_mae: 6.4907\n",
      "Epoch 1499/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 73.9848 - mae: 6.9154 - val_loss: 53.2749 - val_mae: 5.7561\n",
      "Epoch 1500/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 75.6435 - mae: 6.9966 - val_loss: 48.1104 - val_mae: 5.4356\n",
      "Epoch 1501/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 73.7019 - mae: 6.6513 - val_loss: 62.9541 - val_mae: 6.2288\n",
      "Epoch 1502/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 71.0556 - mae: 6.5803 - val_loss: 103.0226 - val_mae: 8.4161\n",
      "Epoch 1503/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 72.7777 - mae: 6.7133 - val_loss: 40.7142 - val_mae: 4.8243\n",
      "Epoch 1504/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 73.6827 - mae: 6.8108 - val_loss: 80.2860 - val_mae: 7.1307\n",
      "Epoch 1505/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 76.8358 - mae: 7.0267 - val_loss: 159.8822 - val_mae: 9.8222\n",
      "Epoch 1506/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 71.4335 - mae: 6.6631 - val_loss: 117.7219 - val_mae: 9.0107\n",
      "Epoch 1507/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 74.8791 - mae: 7.0158 - val_loss: 38.3605 - val_mae: 4.6738\n",
      "Epoch 1508/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 76.2439 - mae: 6.9294 - val_loss: 51.2188 - val_mae: 5.5513\n",
      "Epoch 1509/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 68.0112 - mae: 6.5505 - val_loss: 44.1289 - val_mae: 4.9991\n",
      "Epoch 1510/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 71.7695 - mae: 6.6237 - val_loss: 58.6992 - val_mae: 5.9399\n",
      "Epoch 1511/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 76.4263 - mae: 6.8566 - val_loss: 36.2256 - val_mae: 4.5413\n",
      "Epoch 1512/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 66.8922 - mae: 6.3137 - val_loss: 130.9787 - val_mae: 9.6135\n",
      "Epoch 1513/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 78.6492 - mae: 7.0734 - val_loss: 66.8303 - val_mae: 6.4769\n",
      "Epoch 1514/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 70.1966 - mae: 6.6314 - val_loss: 58.7603 - val_mae: 5.9396\n",
      "Epoch 1515/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 73.6274 - mae: 6.9105 - val_loss: 57.9159 - val_mae: 5.9976\n",
      "Epoch 1516/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 71.7088 - mae: 6.7283 - val_loss: 39.5034 - val_mae: 4.7865\n",
      "Epoch 1517/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 73.7764 - mae: 6.9585 - val_loss: 99.2275 - val_mae: 8.3035\n",
      "Epoch 1518/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 67.3813 - mae: 6.3608 - val_loss: 30.0342 - val_mae: 4.0944\n",
      "Epoch 1519/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 79.1928 - mae: 7.0777 - val_loss: 33.5072 - val_mae: 4.3682\n",
      "Epoch 1520/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 65.9547 - mae: 6.2806 - val_loss: 186.3481 - val_mae: 11.4215\n",
      "Epoch 1521/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 73.5064 - mae: 6.7571 - val_loss: 47.3773 - val_mae: 5.4959\n",
      "Epoch 1522/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 72.9646 - mae: 6.8199 - val_loss: 107.5793 - val_mae: 8.6930\n",
      "Epoch 1523/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 68.6277 - mae: 6.6295 - val_loss: 37.3514 - val_mae: 4.5759\n",
      "Epoch 1524/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 76.5621 - mae: 7.0066 - val_loss: 35.4393 - val_mae: 4.5825\n",
      "Epoch 1525/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 70.2115 - mae: 6.6892 - val_loss: 34.3185 - val_mae: 4.4040\n",
      "Epoch 1526/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 71.7515 - mae: 6.6491 - val_loss: 137.6945 - val_mae: 9.7242\n",
      "Epoch 1527/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 72.7947 - mae: 6.9058 - val_loss: 95.2425 - val_mae: 8.3011\n",
      "Epoch 1528/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 71.4644 - mae: 6.6833 - val_loss: 84.0358 - val_mae: 7.4861\n",
      "Epoch 1529/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 70.7890 - mae: 6.6842 - val_loss: 125.1319 - val_mae: 8.7145\n",
      "Epoch 1530/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 71.4211 - mae: 6.6651 - val_loss: 66.1634 - val_mae: 6.5126\n",
      "Epoch 1531/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 71.6560 - mae: 6.7184 - val_loss: 143.7789 - val_mae: 10.0607\n",
      "Epoch 1532/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 71.0837 - mae: 6.6940 - val_loss: 45.9926 - val_mae: 5.2179\n",
      "Epoch 1533/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 67.3679 - mae: 6.4228 - val_loss: 67.8719 - val_mae: 6.5099\n",
      "Epoch 1534/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 73.4638 - mae: 6.8502 - val_loss: 44.8991 - val_mae: 5.1867\n",
      "Epoch 1535/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 73.4762 - mae: 6.8524 - val_loss: 55.4195 - val_mae: 5.7371\n",
      "Epoch 1536/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 66.0738 - mae: 6.3409 - val_loss: 94.6544 - val_mae: 7.8000\n",
      "Epoch 1537/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 73.3092 - mae: 6.9262 - val_loss: 44.7178 - val_mae: 5.1665\n",
      "Epoch 1538/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 67.5662 - mae: 6.5567 - val_loss: 38.5840 - val_mae: 4.8236\n",
      "Epoch 1539/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 67.4952 - mae: 6.3107 - val_loss: 72.7009 - val_mae: 6.7525\n",
      "Epoch 1540/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 74.3692 - mae: 6.8606 - val_loss: 41.2511 - val_mae: 4.9100\n",
      "Epoch 1541/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 69.0155 - mae: 6.4455 - val_loss: 37.5560 - val_mae: 4.5616\n",
      "Epoch 1542/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 67.8275 - mae: 6.5259 - val_loss: 124.1039 - val_mae: 9.7974\n",
      "Epoch 1543/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 71.2950 - mae: 6.6574 - val_loss: 45.8297 - val_mae: 5.3182\n",
      "Epoch 1544/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 67.6750 - mae: 6.2777 - val_loss: 46.3156 - val_mae: 5.3465\n",
      "Epoch 1545/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 69.2903 - mae: 6.6267 - val_loss: 57.1546 - val_mae: 5.8302\n",
      "Epoch 1546/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 66.5201 - mae: 6.4921 - val_loss: 136.7316 - val_mae: 9.9104\n",
      "Epoch 1547/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 74.6859 - mae: 6.9716 - val_loss: 47.5822 - val_mae: 5.4040\n",
      "Epoch 1548/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 70.2770 - mae: 6.7805 - val_loss: 149.6244 - val_mae: 10.2092\n",
      "Epoch 1549/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 70.8162 - mae: 6.5486 - val_loss: 45.6240 - val_mae: 5.0765\n",
      "Epoch 1550/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 69.2465 - mae: 6.6147 - val_loss: 88.6930 - val_mae: 7.9361\n",
      "Epoch 1551/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 73.3671 - mae: 6.8234 - val_loss: 38.6889 - val_mae: 4.8682\n",
      "Epoch 1552/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 69.9387 - mae: 6.7070 - val_loss: 82.2686 - val_mae: 7.4891\n",
      "Epoch 1553/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 69.7977 - mae: 6.5681 - val_loss: 40.6286 - val_mae: 4.7617\n",
      "Epoch 1554/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 73.0604 - mae: 6.7896 - val_loss: 73.5346 - val_mae: 7.0156\n",
      "Epoch 1555/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 69.2652 - mae: 6.4653 - val_loss: 41.1402 - val_mae: 4.9838\n",
      "Epoch 1556/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 73.3090 - mae: 6.6908 - val_loss: 40.5558 - val_mae: 4.9560\n",
      "Epoch 1557/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 69.9685 - mae: 6.6713 - val_loss: 43.5785 - val_mae: 4.9134\n",
      "Epoch 1558/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 67.3200 - mae: 6.3756 - val_loss: 173.2399 - val_mae: 11.4865\n",
      "Epoch 1559/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 74.0146 - mae: 6.8036 - val_loss: 45.4047 - val_mae: 5.3424\n",
      "Epoch 1560/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 65.0646 - mae: 6.3986 - val_loss: 202.5631 - val_mae: 12.1154\n",
      "Epoch 1561/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 73.7368 - mae: 6.7125 - val_loss: 32.6427 - val_mae: 4.2980\n",
      "Epoch 1562/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 68.2479 - mae: 6.5515 - val_loss: 105.0819 - val_mae: 8.3410\n",
      "Epoch 1563/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 68.6320 - mae: 6.5198 - val_loss: 53.4840 - val_mae: 5.6620\n",
      "Epoch 1564/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 70.1149 - mae: 6.6020 - val_loss: 26.0394 - val_mae: 3.8493\n",
      "Epoch 1565/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 67.4888 - mae: 6.3140 - val_loss: 38.7161 - val_mae: 4.6954\n",
      "Epoch 1566/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 67.3418 - mae: 6.6154 - val_loss: 81.7502 - val_mae: 7.2657\n",
      "Epoch 1567/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 74.7805 - mae: 6.9171 - val_loss: 45.8786 - val_mae: 5.0993\n",
      "Epoch 1568/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 69.1591 - mae: 6.4785 - val_loss: 34.3905 - val_mae: 4.3897\n",
      "Epoch 1569/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 68.2021 - mae: 6.5461 - val_loss: 57.5222 - val_mae: 5.8401\n",
      "Epoch 1570/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 68.0291 - mae: 6.5740 - val_loss: 74.2222 - val_mae: 6.8511\n",
      "Epoch 1571/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 67.7862 - mae: 6.5868 - val_loss: 30.0527 - val_mae: 4.1128\n",
      "Epoch 1572/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 68.9954 - mae: 6.5933 - val_loss: 152.3082 - val_mae: 10.4721\n",
      "Epoch 1573/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 69.7078 - mae: 6.5218 - val_loss: 31.8361 - val_mae: 4.2842\n",
      "Epoch 1574/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 69.1021 - mae: 6.5783 - val_loss: 109.2913 - val_mae: 8.1525\n",
      "Epoch 1575/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 68.7886 - mae: 6.6580 - val_loss: 74.4006 - val_mae: 7.0134\n",
      "Epoch 1576/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 68.2931 - mae: 6.4794 - val_loss: 41.6073 - val_mae: 4.9883\n",
      "Epoch 1577/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 73.2380 - mae: 6.7707 - val_loss: 117.9477 - val_mae: 9.2166\n",
      "Epoch 1578/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 69.2235 - mae: 6.7044 - val_loss: 75.0072 - val_mae: 6.7162\n",
      "Epoch 1579/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 67.5675 - mae: 6.5360 - val_loss: 59.9170 - val_mae: 5.8547\n",
      "Epoch 1580/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 74.1839 - mae: 7.0091 - val_loss: 80.8121 - val_mae: 7.2620\n",
      "Epoch 1581/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 62.2758 - mae: 6.3367 - val_loss: 44.6797 - val_mae: 5.1390\n",
      "Epoch 1582/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 70.1687 - mae: 6.6850 - val_loss: 99.5098 - val_mae: 8.0904\n",
      "Epoch 1583/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 64.1870 - mae: 6.1004 - val_loss: 64.8141 - val_mae: 6.4068\n",
      "Epoch 1584/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 73.8922 - mae: 6.7683 - val_loss: 124.0079 - val_mae: 8.9122\n",
      "Epoch 1585/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 69.5305 - mae: 6.6834 - val_loss: 118.9392 - val_mae: 9.4092\n",
      "Epoch 1586/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 68.5327 - mae: 6.5121 - val_loss: 82.3549 - val_mae: 7.1029\n",
      "Epoch 1587/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 72.0065 - mae: 6.6647 - val_loss: 42.3319 - val_mae: 4.8632\n",
      "Epoch 1588/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 68.7711 - mae: 6.6110 - val_loss: 103.2983 - val_mae: 8.8928\n",
      "Epoch 1589/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 70.8362 - mae: 6.7827 - val_loss: 34.8330 - val_mae: 4.5528\n",
      "Epoch 1590/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 68.5978 - mae: 6.5762 - val_loss: 144.2388 - val_mae: 9.8313\n",
      "Epoch 1591/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 68.9042 - mae: 6.4364 - val_loss: 57.4543 - val_mae: 6.0627\n",
      "Epoch 1592/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 66.6891 - mae: 6.3809 - val_loss: 107.2460 - val_mae: 7.7856\n",
      "Epoch 1593/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 68.4286 - mae: 6.5122 - val_loss: 58.2582 - val_mae: 6.0445\n",
      "Epoch 1594/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 66.9963 - mae: 6.4995 - val_loss: 115.4749 - val_mae: 9.2414\n",
      "Epoch 1595/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 70.1128 - mae: 6.7549 - val_loss: 136.6696 - val_mae: 9.5001\n",
      "Epoch 1596/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 69.4451 - mae: 6.6178 - val_loss: 50.7093 - val_mae: 5.5785\n",
      "Epoch 1597/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 66.5328 - mae: 6.4837 - val_loss: 55.2990 - val_mae: 5.7264\n",
      "Epoch 1598/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 60.2716 - mae: 6.0768 - val_loss: 184.0938 - val_mae: 12.1465\n",
      "Epoch 1599/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 72.6892 - mae: 6.7518 - val_loss: 51.7440 - val_mae: 5.7472\n",
      "Epoch 1600/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 68.3807 - mae: 6.4495 - val_loss: 52.4552 - val_mae: 5.5339\n",
      "Epoch 1601/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 65.7213 - mae: 6.4942 - val_loss: 143.8340 - val_mae: 10.0543\n",
      "Epoch 1602/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 66.1536 - mae: 6.4318 - val_loss: 81.8834 - val_mae: 7.2233\n",
      "Epoch 1603/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 69.9943 - mae: 6.7981 - val_loss: 64.7611 - val_mae: 6.3834\n",
      "Epoch 1604/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 67.2500 - mae: 6.4939 - val_loss: 112.8975 - val_mae: 8.8803\n",
      "Epoch 1605/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 65.2681 - mae: 6.1781 - val_loss: 40.0085 - val_mae: 4.8763\n",
      "Epoch 1606/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 66.8111 - mae: 6.3910 - val_loss: 92.8339 - val_mae: 8.0461\n",
      "Epoch 1607/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 62.8649 - mae: 6.1675 - val_loss: 58.7989 - val_mae: 6.1326\n",
      "Epoch 1608/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 66.5476 - mae: 6.4589 - val_loss: 31.9199 - val_mae: 4.2559\n",
      "Epoch 1609/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 70.4842 - mae: 6.7049 - val_loss: 58.0158 - val_mae: 6.1621\n",
      "Epoch 1610/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 66.4879 - mae: 6.5211 - val_loss: 29.9689 - val_mae: 4.1499\n",
      "Epoch 1611/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 65.2335 - mae: 6.4075 - val_loss: 57.3104 - val_mae: 5.9050\n",
      "Epoch 1612/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 66.6201 - mae: 6.4422 - val_loss: 98.0912 - val_mae: 8.2895\n",
      "Epoch 1613/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 72.8640 - mae: 6.6906 - val_loss: 40.8107 - val_mae: 5.0414\n",
      "Epoch 1614/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 68.4260 - mae: 6.6802 - val_loss: 124.7308 - val_mae: 9.5257\n",
      "Epoch 1615/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 66.1737 - mae: 6.4993 - val_loss: 60.2414 - val_mae: 5.9871\n",
      "Epoch 1616/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 70.1845 - mae: 6.6709 - val_loss: 33.8893 - val_mae: 4.4672\n",
      "Epoch 1617/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 65.5360 - mae: 6.3231 - val_loss: 61.8650 - val_mae: 6.0809\n",
      "Epoch 1618/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 64.9922 - mae: 6.3754 - val_loss: 79.3563 - val_mae: 7.5062\n",
      "Epoch 1619/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 68.2542 - mae: 6.6267 - val_loss: 99.2314 - val_mae: 8.3549\n",
      "Epoch 1620/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 66.3570 - mae: 6.5362 - val_loss: 84.7004 - val_mae: 7.5192\n",
      "Epoch 1621/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 66.9856 - mae: 6.4040 - val_loss: 78.0926 - val_mae: 7.1704\n",
      "Epoch 1622/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 65.1990 - mae: 6.4369 - val_loss: 56.8821 - val_mae: 6.0690\n",
      "Epoch 1623/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 65.5539 - mae: 6.4417 - val_loss: 110.7690 - val_mae: 9.0108\n",
      "Epoch 1624/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 68.5024 - mae: 6.5633 - val_loss: 105.5936 - val_mae: 8.7709\n",
      "Epoch 1625/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 63.5911 - mae: 6.2742 - val_loss: 77.7322 - val_mae: 7.1062\n",
      "Epoch 1626/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 72.4657 - mae: 6.8429 - val_loss: 44.4358 - val_mae: 5.1244\n",
      "Epoch 1627/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 63.8900 - mae: 6.2939 - val_loss: 41.5771 - val_mae: 5.1824\n",
      "Epoch 1628/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 67.4438 - mae: 6.5097 - val_loss: 56.1055 - val_mae: 5.8841\n",
      "Epoch 1629/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 69.4195 - mae: 6.5636 - val_loss: 35.1892 - val_mae: 4.5923\n",
      "Epoch 1630/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 63.1615 - mae: 6.2514 - val_loss: 59.9782 - val_mae: 6.0113\n",
      "Epoch 1631/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 67.7028 - mae: 6.5855 - val_loss: 176.0002 - val_mae: 9.4432\n",
      "Epoch 1632/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 63.7696 - mae: 6.2094 - val_loss: 240.7169 - val_mae: 14.1813\n",
      "Epoch 1633/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 69.9603 - mae: 6.5632 - val_loss: 103.2567 - val_mae: 8.1362\n",
      "Epoch 1634/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 64.0680 - mae: 6.3308 - val_loss: 58.7698 - val_mae: 5.9554\n",
      "Epoch 1635/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 66.2568 - mae: 6.5272 - val_loss: 38.0214 - val_mae: 4.6064\n",
      "Epoch 1636/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 69.1914 - mae: 6.6157 - val_loss: 31.4387 - val_mae: 4.3116\n",
      "Epoch 1637/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 63.5285 - mae: 6.2873 - val_loss: 33.6340 - val_mae: 4.3637\n",
      "Epoch 1638/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 66.6195 - mae: 6.4173 - val_loss: 90.2884 - val_mae: 8.0854\n",
      "Epoch 1639/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 65.4686 - mae: 6.4246 - val_loss: 90.0968 - val_mae: 8.2522\n",
      "Epoch 1640/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 68.5725 - mae: 6.7339 - val_loss: 56.8524 - val_mae: 5.9421\n",
      "Epoch 1641/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 69.8723 - mae: 6.5969 - val_loss: 39.7591 - val_mae: 4.9622\n",
      "Epoch 1642/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 64.1678 - mae: 6.2707 - val_loss: 38.5662 - val_mae: 4.8006\n",
      "Epoch 1643/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 63.0982 - mae: 6.3666 - val_loss: 108.2043 - val_mae: 8.5787\n",
      "Epoch 1644/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 69.3017 - mae: 6.6179 - val_loss: 90.9404 - val_mae: 7.7742\n",
      "Epoch 1645/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 65.5700 - mae: 6.4743 - val_loss: 55.8595 - val_mae: 6.0567\n",
      "Epoch 1646/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 63.1321 - mae: 6.3409 - val_loss: 102.4512 - val_mae: 8.6210\n",
      "Epoch 1647/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 66.6251 - mae: 6.4093 - val_loss: 76.0701 - val_mae: 7.0733\n",
      "Epoch 1648/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 60.6330 - mae: 6.1263 - val_loss: 99.0627 - val_mae: 7.9938\n",
      "Epoch 1649/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 64.8246 - mae: 6.2045 - val_loss: 87.2019 - val_mae: 7.5216\n",
      "Epoch 1650/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 63.7806 - mae: 6.1601 - val_loss: 84.4123 - val_mae: 7.5487\n",
      "Epoch 1651/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 68.1997 - mae: 6.4883 - val_loss: 66.6286 - val_mae: 5.9341\n",
      "Epoch 1652/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 65.5899 - mae: 6.5099 - val_loss: 57.0277 - val_mae: 5.9341\n",
      "Epoch 1653/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 66.1423 - mae: 6.4236 - val_loss: 68.5411 - val_mae: 6.3973\n",
      "Epoch 1654/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 59.3381 - mae: 6.0153 - val_loss: 59.1224 - val_mae: 5.9736\n",
      "Epoch 1655/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 69.2713 - mae: 6.5734 - val_loss: 32.2344 - val_mae: 4.3150\n",
      "Epoch 1656/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 62.8447 - mae: 6.2766 - val_loss: 36.6544 - val_mae: 4.6491\n",
      "Epoch 1657/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 67.0863 - mae: 6.6478 - val_loss: 68.1351 - val_mae: 6.5939\n",
      "Epoch 1658/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 60.9398 - mae: 6.1165 - val_loss: 97.1750 - val_mae: 7.8905\n",
      "Epoch 1659/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 71.5290 - mae: 6.8461 - val_loss: 42.4267 - val_mae: 4.9288\n",
      "Epoch 1660/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 63.0807 - mae: 6.4336 - val_loss: 85.3651 - val_mae: 7.6645\n",
      "Epoch 1661/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 69.1177 - mae: 6.7462 - val_loss: 97.8128 - val_mae: 7.6477\n",
      "Epoch 1662/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 63.7773 - mae: 6.4079 - val_loss: 89.1388 - val_mae: 7.7501\n",
      "Epoch 1663/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 64.5229 - mae: 6.4327 - val_loss: 79.9771 - val_mae: 7.3980\n",
      "Epoch 1664/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 63.1275 - mae: 6.2995 - val_loss: 114.5887 - val_mae: 9.2769\n",
      "Epoch 1665/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 64.1170 - mae: 6.3209 - val_loss: 124.7857 - val_mae: 9.5872\n",
      "Epoch 1666/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 64.5007 - mae: 6.3754 - val_loss: 85.7947 - val_mae: 7.4856\n",
      "Epoch 1667/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 65.7953 - mae: 6.5370 - val_loss: 44.1203 - val_mae: 5.0834\n",
      "Epoch 1668/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 64.6654 - mae: 6.4724 - val_loss: 29.7612 - val_mae: 4.0323\n",
      "Epoch 1669/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 65.1806 - mae: 6.3746 - val_loss: 60.1650 - val_mae: 6.2623\n",
      "Epoch 1670/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 61.1640 - mae: 6.0938 - val_loss: 42.7310 - val_mae: 5.1438\n",
      "Epoch 1671/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 64.6720 - mae: 6.4052 - val_loss: 87.7353 - val_mae: 7.2804\n",
      "Epoch 1672/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 63.2059 - mae: 6.2720 - val_loss: 54.7998 - val_mae: 5.9193\n",
      "Epoch 1673/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 64.9635 - mae: 6.3444 - val_loss: 25.7350 - val_mae: 3.7755\n",
      "Epoch 1674/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 63.2451 - mae: 6.3230 - val_loss: 89.1433 - val_mae: 7.7578\n",
      "Epoch 1675/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 61.5973 - mae: 6.2042 - val_loss: 174.0772 - val_mae: 11.0783\n",
      "Epoch 1676/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 65.6121 - mae: 6.5592 - val_loss: 91.7377 - val_mae: 8.1263\n",
      "Epoch 1677/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 61.6158 - mae: 6.3126 - val_loss: 46.4071 - val_mae: 5.3178\n",
      "Epoch 1678/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 65.2676 - mae: 6.4145 - val_loss: 54.1877 - val_mae: 5.6876\n",
      "Epoch 1679/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 67.1896 - mae: 6.4686 - val_loss: 82.3044 - val_mae: 7.6594\n",
      "Epoch 1680/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 62.1546 - mae: 6.1552 - val_loss: 83.4092 - val_mae: 7.1212\n",
      "Epoch 1681/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 62.8915 - mae: 6.1898 - val_loss: 63.2516 - val_mae: 5.9426\n",
      "Epoch 1682/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 64.6348 - mae: 6.3300 - val_loss: 66.6245 - val_mae: 6.6417\n",
      "Epoch 1683/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 61.9271 - mae: 6.1145 - val_loss: 99.0275 - val_mae: 8.0881\n",
      "Epoch 1684/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 62.1490 - mae: 6.3263 - val_loss: 47.8007 - val_mae: 5.4007\n",
      "Epoch 1685/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 64.9558 - mae: 6.3810 - val_loss: 67.8723 - val_mae: 6.8356\n",
      "Epoch 1686/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 68.5233 - mae: 6.5081 - val_loss: 58.7414 - val_mae: 6.1825\n",
      "Epoch 1687/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 63.6317 - mae: 6.3394 - val_loss: 120.8579 - val_mae: 8.9174\n",
      "Epoch 1688/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 61.3685 - mae: 6.2341 - val_loss: 99.4364 - val_mae: 8.0105\n",
      "Epoch 1689/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 63.5633 - mae: 6.2861 - val_loss: 69.2103 - val_mae: 6.7340\n",
      "Epoch 1690/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 62.6570 - mae: 6.3119 - val_loss: 76.2634 - val_mae: 6.9272\n",
      "Epoch 1691/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 61.2937 - mae: 6.2369 - val_loss: 69.5853 - val_mae: 6.8344\n",
      "Epoch 1692/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 64.9369 - mae: 6.2815 - val_loss: 37.3435 - val_mae: 4.7238\n",
      "Epoch 1693/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 61.1466 - mae: 6.1572 - val_loss: 66.7285 - val_mae: 6.6173\n",
      "Epoch 1694/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 62.2096 - mae: 6.1852 - val_loss: 30.4988 - val_mae: 4.2019\n",
      "Epoch 1695/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 65.5742 - mae: 6.5779 - val_loss: 47.0998 - val_mae: 5.4326\n",
      "Epoch 1696/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 61.6333 - mae: 6.2627 - val_loss: 51.6780 - val_mae: 5.8168\n",
      "Epoch 1697/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 60.0103 - mae: 6.1511 - val_loss: 181.0890 - val_mae: 10.9601\n",
      "Epoch 1698/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 67.8532 - mae: 6.5193 - val_loss: 41.4366 - val_mae: 5.0577\n",
      "Epoch 1699/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 66.8436 - mae: 6.5637 - val_loss: 56.1837 - val_mae: 6.1035\n",
      "Epoch 1700/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 62.5272 - mae: 6.2324 - val_loss: 168.2319 - val_mae: 11.5342\n",
      "Epoch 1701/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 59.8658 - mae: 6.0661 - val_loss: 217.1001 - val_mae: 13.5832\n",
      "Epoch 1702/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 61.4944 - mae: 6.0596 - val_loss: 188.4392 - val_mae: 11.0781\n",
      "Epoch 1703/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 65.1682 - mae: 6.4643 - val_loss: 129.7112 - val_mae: 9.4843\n",
      "Epoch 1704/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 62.7500 - mae: 6.3015 - val_loss: 109.7086 - val_mae: 8.3128\n",
      "Epoch 1705/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 61.7820 - mae: 6.1883 - val_loss: 61.8851 - val_mae: 6.3296\n",
      "Epoch 1706/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 62.0349 - mae: 6.2435 - val_loss: 85.4453 - val_mae: 7.7847\n",
      "Epoch 1707/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 64.7972 - mae: 6.5515 - val_loss: 31.2146 - val_mae: 4.1603\n",
      "Epoch 1708/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 64.2206 - mae: 6.3577 - val_loss: 48.9780 - val_mae: 5.3095\n",
      "Epoch 1709/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 61.7651 - mae: 6.1685 - val_loss: 38.0497 - val_mae: 4.7110\n",
      "Epoch 1710/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 63.5420 - mae: 6.3496 - val_loss: 90.3996 - val_mae: 7.5982\n",
      "Epoch 1711/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 63.3970 - mae: 6.4373 - val_loss: 88.2767 - val_mae: 7.8461\n",
      "Epoch 1712/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 61.4268 - mae: 6.2646 - val_loss: 141.4502 - val_mae: 10.1236\n",
      "Epoch 1713/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 62.7345 - mae: 6.0892 - val_loss: 105.2276 - val_mae: 8.8356\n",
      "Epoch 1714/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 62.4958 - mae: 6.2882 - val_loss: 35.0164 - val_mae: 4.5700\n",
      "Epoch 1715/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 62.7663 - mae: 6.2243 - val_loss: 139.1059 - val_mae: 9.4332\n",
      "Epoch 1716/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 60.5115 - mae: 5.9932 - val_loss: 104.2919 - val_mae: 8.4072\n",
      "Epoch 1717/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 62.8805 - mae: 6.3288 - val_loss: 61.9535 - val_mae: 6.1293\n",
      "Epoch 1718/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 60.5868 - mae: 6.1176 - val_loss: 36.8872 - val_mae: 4.7575\n",
      "Epoch 1719/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 60.6660 - mae: 6.2002 - val_loss: 51.3714 - val_mae: 5.7546\n",
      "Epoch 1720/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 65.5677 - mae: 6.5127 - val_loss: 28.9869 - val_mae: 4.1239\n",
      "Epoch 1721/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 60.5843 - mae: 6.2470 - val_loss: 34.2569 - val_mae: 4.5183\n",
      "Epoch 1722/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 64.5748 - mae: 6.3338 - val_loss: 73.5503 - val_mae: 7.0919\n",
      "Epoch 1723/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 62.3382 - mae: 6.2545 - val_loss: 74.3116 - val_mae: 6.7074\n",
      "Epoch 1724/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 60.3501 - mae: 6.0620 - val_loss: 129.7398 - val_mae: 9.7237\n",
      "Epoch 1725/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 62.9748 - mae: 6.2576 - val_loss: 28.6307 - val_mae: 4.0325\n",
      "Epoch 1726/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 56.8060 - mae: 5.9502 - val_loss: 100.5561 - val_mae: 8.9156\n",
      "Epoch 1727/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 67.9607 - mae: 6.5018 - val_loss: 30.5736 - val_mae: 4.1644\n",
      "Epoch 1728/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 59.6651 - mae: 6.0654 - val_loss: 48.0814 - val_mae: 5.5102\n",
      "Epoch 1729/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 64.1253 - mae: 6.5299 - val_loss: 144.9913 - val_mae: 8.9947\n",
      "Epoch 1730/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 62.8153 - mae: 6.2285 - val_loss: 79.4249 - val_mae: 7.4547\n",
      "Epoch 1731/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 62.6250 - mae: 6.3171 - val_loss: 77.1062 - val_mae: 7.1290\n",
      "Epoch 1732/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 58.0468 - mae: 5.9352 - val_loss: 24.7427 - val_mae: 3.7629\n",
      "Epoch 1733/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 65.5941 - mae: 6.5561 - val_loss: 100.3258 - val_mae: 7.9220\n",
      "Epoch 1734/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 61.8834 - mae: 6.1728 - val_loss: 104.9542 - val_mae: 8.2548\n",
      "Epoch 1735/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 62.2484 - mae: 6.3254 - val_loss: 39.6411 - val_mae: 4.9183\n",
      "Epoch 1736/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 59.3344 - mae: 5.9530 - val_loss: 173.9417 - val_mae: 11.2133\n",
      "Epoch 1737/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 59.9475 - mae: 6.0028 - val_loss: 124.7673 - val_mae: 9.3431\n",
      "Epoch 1738/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 60.2255 - mae: 6.1199 - val_loss: 46.1378 - val_mae: 5.2381\n",
      "Epoch 1739/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 61.0804 - mae: 6.2858 - val_loss: 56.7088 - val_mae: 6.1328\n",
      "Epoch 1740/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 62.2486 - mae: 6.2846 - val_loss: 74.8200 - val_mae: 7.0084\n",
      "Epoch 1741/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 58.5549 - mae: 6.0111 - val_loss: 39.1506 - val_mae: 4.8739\n",
      "Epoch 1742/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 62.9875 - mae: 6.3396 - val_loss: 24.2771 - val_mae: 3.7145\n",
      "Epoch 1743/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 59.3698 - mae: 6.2044 - val_loss: 49.6439 - val_mae: 5.7433\n",
      "Epoch 1744/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 62.5330 - mae: 6.3847 - val_loss: 72.7364 - val_mae: 7.1602\n",
      "Epoch 1745/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 63.1663 - mae: 6.1622 - val_loss: 87.1805 - val_mae: 7.8388\n",
      "Epoch 1746/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 61.6160 - mae: 6.3393 - val_loss: 40.5908 - val_mae: 4.8929\n",
      "Epoch 1747/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 62.5058 - mae: 6.3196 - val_loss: 66.9235 - val_mae: 6.3122\n",
      "Epoch 1748/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 60.3139 - mae: 6.2792 - val_loss: 51.7314 - val_mae: 5.5364\n",
      "Epoch 1749/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 59.1068 - mae: 6.1131 - val_loss: 43.1468 - val_mae: 5.0545\n",
      "Epoch 1750/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 60.2723 - mae: 6.2639 - val_loss: 45.5576 - val_mae: 5.3389\n",
      "Epoch 1751/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 63.7618 - mae: 6.4424 - val_loss: 48.4954 - val_mae: 5.4389\n",
      "Epoch 1752/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 59.6578 - mae: 6.2652 - val_loss: 30.4917 - val_mae: 4.3794\n",
      "Epoch 1753/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 58.7593 - mae: 6.0381 - val_loss: 197.7514 - val_mae: 12.7307\n",
      "Epoch 1754/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 59.9355 - mae: 6.1784 - val_loss: 73.5632 - val_mae: 6.9458\n",
      "Epoch 1755/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 65.0435 - mae: 6.4959 - val_loss: 44.0626 - val_mae: 5.2078\n",
      "Epoch 1756/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 58.3276 - mae: 6.0586 - val_loss: 198.9288 - val_mae: 12.4310\n",
      "Epoch 1757/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 63.7819 - mae: 6.2233 - val_loss: 23.2035 - val_mae: 3.6549\n",
      "Epoch 1758/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 57.8502 - mae: 5.9442 - val_loss: 108.5331 - val_mae: 8.9208\n",
      "Epoch 1759/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 63.7970 - mae: 6.4411 - val_loss: 62.5393 - val_mae: 6.3025\n",
      "Epoch 1760/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 58.7539 - mae: 6.0233 - val_loss: 123.9488 - val_mae: 8.9522\n",
      "Epoch 1761/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 60.1363 - mae: 6.1861 - val_loss: 84.2048 - val_mae: 7.4396\n",
      "Epoch 1762/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 60.6863 - mae: 6.1595 - val_loss: 52.0721 - val_mae: 5.6247\n",
      "Epoch 1763/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 62.8458 - mae: 6.3178 - val_loss: 84.8548 - val_mae: 7.5092\n",
      "Epoch 1764/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 58.7947 - mae: 6.1141 - val_loss: 33.9486 - val_mae: 4.5849\n",
      "Epoch 1765/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 64.3297 - mae: 6.3208 - val_loss: 70.3392 - val_mae: 6.7601\n",
      "Epoch 1766/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 61.8895 - mae: 6.3002 - val_loss: 80.6923 - val_mae: 7.3103\n",
      "Epoch 1767/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 60.1381 - mae: 6.1265 - val_loss: 65.6983 - val_mae: 6.5806\n",
      "Epoch 1768/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 61.0343 - mae: 6.2646 - val_loss: 32.6141 - val_mae: 4.4193\n",
      "Epoch 1769/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 59.4576 - mae: 6.0616 - val_loss: 196.3658 - val_mae: 12.7149\n",
      "Epoch 1770/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 62.8741 - mae: 6.4545 - val_loss: 32.7725 - val_mae: 4.3884\n",
      "Epoch 1771/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 59.8117 - mae: 6.1908 - val_loss: 28.1617 - val_mae: 3.9893\n",
      "Epoch 1772/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 63.0454 - mae: 6.1394 - val_loss: 26.5612 - val_mae: 3.8207\n",
      "Epoch 1773/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 55.8603 - mae: 5.8681 - val_loss: 58.3723 - val_mae: 6.2468\n",
      "Epoch 1774/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 61.9452 - mae: 6.3322 - val_loss: 47.9319 - val_mae: 5.1049\n",
      "Epoch 1775/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 60.1822 - mae: 6.0557 - val_loss: 82.5180 - val_mae: 7.6350\n",
      "Epoch 1776/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 62.2562 - mae: 6.3078 - val_loss: 48.8260 - val_mae: 5.7322\n",
      "Epoch 1777/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 61.2181 - mae: 6.2611 - val_loss: 42.8586 - val_mae: 5.3101\n",
      "Epoch 1778/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 60.0361 - mae: 6.1699 - val_loss: 56.9200 - val_mae: 6.2379\n",
      "Epoch 1779/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 59.8940 - mae: 6.2830 - val_loss: 42.6137 - val_mae: 5.0423\n",
      "Epoch 1780/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 59.7639 - mae: 6.1133 - val_loss: 46.7895 - val_mae: 5.2708\n",
      "Epoch 1781/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 60.6596 - mae: 6.1885 - val_loss: 96.7647 - val_mae: 8.2081\n",
      "Epoch 1782/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 61.4779 - mae: 6.2339 - val_loss: 56.9590 - val_mae: 5.9587\n",
      "Epoch 1783/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 59.2535 - mae: 6.1926 - val_loss: 77.1540 - val_mae: 7.4215\n",
      "Epoch 1784/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 59.8219 - mae: 6.1673 - val_loss: 56.9253 - val_mae: 6.1942\n",
      "Epoch 1785/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 58.4831 - mae: 6.1781 - val_loss: 102.5545 - val_mae: 8.8201\n",
      "Epoch 1786/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 60.3695 - mae: 6.1914 - val_loss: 129.2530 - val_mae: 9.2984\n",
      "Epoch 1787/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 56.0273 - mae: 5.8018 - val_loss: 24.8092 - val_mae: 3.8159\n",
      "Epoch 1788/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 62.5975 - mae: 6.3208 - val_loss: 55.3803 - val_mae: 5.5165\n",
      "Epoch 1789/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 59.6765 - mae: 6.0466 - val_loss: 58.2903 - val_mae: 6.0008\n",
      "Epoch 1790/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 56.3150 - mae: 6.0671 - val_loss: 175.2511 - val_mae: 12.2504\n",
      "Epoch 1791/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 55.5273 - mae: 5.7686 - val_loss: 34.5953 - val_mae: 4.4399\n",
      "Epoch 1792/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 57.0432 - mae: 5.9693 - val_loss: 22.0227 - val_mae: 3.4504\n",
      "Epoch 1793/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 64.2832 - mae: 6.3241 - val_loss: 144.1235 - val_mae: 10.6582\n",
      "Epoch 1794/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 59.0851 - mae: 6.1808 - val_loss: 57.2038 - val_mae: 6.0105\n",
      "Epoch 1795/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 57.6987 - mae: 5.9277 - val_loss: 36.4145 - val_mae: 4.7781\n",
      "Epoch 1796/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 59.1959 - mae: 6.1645 - val_loss: 105.1976 - val_mae: 8.8982\n",
      "Epoch 1797/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 56.3411 - mae: 5.9624 - val_loss: 139.8853 - val_mae: 9.1470\n",
      "Epoch 1798/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 64.0399 - mae: 6.4051 - val_loss: 44.0774 - val_mae: 5.3486\n",
      "Epoch 1799/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 56.1975 - mae: 5.8948 - val_loss: 84.2252 - val_mae: 7.3197\n",
      "Epoch 1800/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 55.6421 - mae: 5.9476 - val_loss: 69.9121 - val_mae: 6.7224\n",
      "Epoch 1801/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 63.2720 - mae: 6.2279 - val_loss: 41.0319 - val_mae: 4.9718\n",
      "Epoch 1802/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 55.8167 - mae: 5.7861 - val_loss: 28.7465 - val_mae: 4.0635\n",
      "Epoch 1803/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 60.9571 - mae: 6.1788 - val_loss: 114.5247 - val_mae: 8.8358\n",
      "Epoch 1804/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 59.7646 - mae: 6.1339 - val_loss: 26.7752 - val_mae: 3.9785\n",
      "Epoch 1805/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 59.7806 - mae: 6.1572 - val_loss: 26.1683 - val_mae: 3.9134\n",
      "Epoch 1806/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 59.2992 - mae: 6.1571 - val_loss: 46.7532 - val_mae: 5.3753\n",
      "Epoch 1807/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 55.6907 - mae: 5.9663 - val_loss: 126.4834 - val_mae: 9.1690\n",
      "Epoch 1808/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 60.0774 - mae: 6.0551 - val_loss: 88.9771 - val_mae: 7.9342\n",
      "Epoch 1809/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 61.0749 - mae: 6.2230 - val_loss: 34.4569 - val_mae: 4.5543\n",
      "Epoch 1810/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 54.4294 - mae: 5.7735 - val_loss: 24.6083 - val_mae: 3.7240\n",
      "Epoch 1811/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 62.0051 - mae: 6.3086 - val_loss: 25.0826 - val_mae: 3.7596\n",
      "Epoch 1812/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 56.7688 - mae: 5.9239 - val_loss: 110.2355 - val_mae: 8.8299\n",
      "Epoch 1813/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 59.0391 - mae: 6.1893 - val_loss: 44.5963 - val_mae: 5.1985\n",
      "Epoch 1814/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 57.4845 - mae: 6.1600 - val_loss: 90.3029 - val_mae: 7.9521\n",
      "Epoch 1815/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 60.3830 - mae: 6.0532 - val_loss: 63.7098 - val_mae: 6.2082\n",
      "Epoch 1816/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 57.8672 - mae: 6.1195 - val_loss: 87.9250 - val_mae: 7.2212\n",
      "Epoch 1817/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 54.7343 - mae: 5.7590 - val_loss: 53.0600 - val_mae: 5.7980\n",
      "Epoch 1818/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 59.3013 - mae: 6.1628 - val_loss: 25.4139 - val_mae: 3.8014\n",
      "Epoch 1819/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 58.7829 - mae: 6.2101 - val_loss: 133.4659 - val_mae: 9.6146\n",
      "Epoch 1820/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 59.0645 - mae: 6.0724 - val_loss: 37.4080 - val_mae: 4.7237\n",
      "Epoch 1821/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 57.0335 - mae: 5.9921 - val_loss: 37.5269 - val_mae: 4.7625\n",
      "Epoch 1822/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 52.2534 - mae: 5.4175 - val_loss: 48.3425 - val_mae: 5.0377\n",
      "Epoch 1823/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 59.9231 - mae: 6.2062 - val_loss: 65.0191 - val_mae: 6.2665\n",
      "Epoch 1824/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 56.8392 - mae: 5.9262 - val_loss: 73.6948 - val_mae: 6.8943\n",
      "Epoch 1825/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 58.1456 - mae: 6.0286 - val_loss: 62.8078 - val_mae: 6.3232\n",
      "Epoch 1826/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 57.2642 - mae: 5.9712 - val_loss: 31.8993 - val_mae: 4.3276\n",
      "Epoch 1827/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 55.0700 - mae: 5.9881 - val_loss: 57.1548 - val_mae: 6.1234\n",
      "Epoch 1828/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 60.2989 - mae: 6.2353 - val_loss: 85.7838 - val_mae: 7.2191\n",
      "Epoch 1829/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 59.2850 - mae: 6.1405 - val_loss: 34.0371 - val_mae: 4.6613\n",
      "Epoch 1830/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 58.7796 - mae: 6.2135 - val_loss: 30.6085 - val_mae: 4.1610\n",
      "Epoch 1831/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 59.1177 - mae: 6.1902 - val_loss: 81.9093 - val_mae: 7.5940\n",
      "Epoch 1832/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 59.4444 - mae: 6.2504 - val_loss: 33.1693 - val_mae: 4.3406\n",
      "Epoch 1833/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 57.2535 - mae: 6.0822 - val_loss: 57.7792 - val_mae: 6.1587\n",
      "Epoch 1834/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 56.9524 - mae: 5.9943 - val_loss: 76.0183 - val_mae: 7.4476\n",
      "Epoch 1835/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 59.2945 - mae: 6.1911 - val_loss: 47.9687 - val_mae: 5.3506\n",
      "Epoch 1836/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 55.3548 - mae: 5.9566 - val_loss: 49.3391 - val_mae: 5.3966\n",
      "Epoch 1837/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 55.7487 - mae: 5.6953 - val_loss: 23.1350 - val_mae: 3.5939\n",
      "Epoch 1838/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 55.5852 - mae: 5.9656 - val_loss: 27.7982 - val_mae: 4.0258\n",
      "Epoch 1839/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 59.4747 - mae: 6.1239 - val_loss: 41.0551 - val_mae: 4.9780\n",
      "Epoch 1840/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 62.0639 - mae: 6.2620 - val_loss: 118.2237 - val_mae: 8.5713\n",
      "Epoch 1841/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 56.0738 - mae: 5.8864 - val_loss: 48.0101 - val_mae: 5.3223\n",
      "Epoch 1842/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 59.1787 - mae: 6.1978 - val_loss: 36.5607 - val_mae: 4.7041\n",
      "Epoch 1843/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 60.9456 - mae: 6.3511 - val_loss: 50.6751 - val_mae: 5.7915\n",
      "Epoch 1844/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 53.2971 - mae: 5.6747 - val_loss: 79.2957 - val_mae: 7.4062\n",
      "Epoch 1845/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 57.4937 - mae: 6.0828 - val_loss: 70.7856 - val_mae: 6.8350\n",
      "Epoch 1846/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 56.8456 - mae: 6.0157 - val_loss: 36.2657 - val_mae: 4.5329\n",
      "Epoch 1847/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 56.9274 - mae: 6.0943 - val_loss: 137.9297 - val_mae: 9.7276\n",
      "Epoch 1848/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 56.9086 - mae: 5.9443 - val_loss: 97.2469 - val_mae: 7.4019\n",
      "Epoch 1849/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 59.3661 - mae: 6.0158 - val_loss: 49.2963 - val_mae: 5.3547\n",
      "Epoch 1850/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 55.5513 - mae: 5.9727 - val_loss: 29.6120 - val_mae: 4.2167\n",
      "Epoch 1851/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 59.0451 - mae: 6.1854 - val_loss: 78.4597 - val_mae: 7.4222\n",
      "Epoch 1852/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 56.4518 - mae: 5.9336 - val_loss: 32.0298 - val_mae: 4.4072\n",
      "Epoch 1853/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 55.0895 - mae: 5.8287 - val_loss: 151.8895 - val_mae: 9.7427\n",
      "Epoch 1854/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 56.9259 - mae: 6.0492 - val_loss: 83.7821 - val_mae: 7.1865\n",
      "Epoch 1855/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 58.3606 - mae: 6.1544 - val_loss: 68.1418 - val_mae: 6.1546\n",
      "Epoch 1856/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 54.3097 - mae: 5.9173 - val_loss: 26.6266 - val_mae: 3.8784\n",
      "Epoch 1857/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 56.4160 - mae: 5.7957 - val_loss: 59.1379 - val_mae: 6.0531\n",
      "Epoch 1858/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 58.9294 - mae: 6.0772 - val_loss: 39.7656 - val_mae: 4.8976\n",
      "Epoch 1859/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 53.4599 - mae: 5.7727 - val_loss: 32.4998 - val_mae: 4.5034\n",
      "Epoch 1860/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 59.2563 - mae: 5.9459 - val_loss: 51.1871 - val_mae: 5.6666\n",
      "Epoch 1861/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 56.4822 - mae: 6.0010 - val_loss: 56.4885 - val_mae: 5.9302\n",
      "Epoch 1862/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 57.4182 - mae: 6.1709 - val_loss: 106.1943 - val_mae: 8.4008\n",
      "Epoch 1863/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 57.1051 - mae: 5.9074 - val_loss: 61.4247 - val_mae: 6.2577\n",
      "Epoch 1864/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 53.3481 - mae: 5.5597 - val_loss: 78.7419 - val_mae: 7.5181\n",
      "Epoch 1865/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 58.3950 - mae: 6.0534 - val_loss: 44.1079 - val_mae: 5.1280\n",
      "Epoch 1866/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 56.4501 - mae: 6.0760 - val_loss: 28.4757 - val_mae: 4.1832\n",
      "Epoch 1867/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 54.0086 - mae: 5.7302 - val_loss: 81.4230 - val_mae: 7.5489\n",
      "Epoch 1868/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 61.1875 - mae: 6.1784 - val_loss: 71.6104 - val_mae: 6.6333\n",
      "Epoch 1869/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 53.9959 - mae: 5.8847 - val_loss: 35.5209 - val_mae: 4.8742\n",
      "Epoch 1870/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 58.4140 - mae: 6.0365 - val_loss: 73.0524 - val_mae: 6.8213\n",
      "Epoch 1871/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 54.7304 - mae: 6.0137 - val_loss: 64.3669 - val_mae: 6.1783\n",
      "Epoch 1872/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 56.6200 - mae: 6.0578 - val_loss: 29.7338 - val_mae: 4.2153\n",
      "Epoch 1873/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 55.8204 - mae: 6.0589 - val_loss: 28.1540 - val_mae: 3.9484\n",
      "Epoch 1874/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 58.4916 - mae: 6.0343 - val_loss: 58.6321 - val_mae: 6.3726\n",
      "Epoch 1875/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 58.9082 - mae: 6.2568 - val_loss: 33.6880 - val_mae: 4.5875\n",
      "Epoch 1876/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 54.6511 - mae: 5.9525 - val_loss: 57.5163 - val_mae: 6.1241\n",
      "Epoch 1877/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 55.4265 - mae: 5.8989 - val_loss: 114.3708 - val_mae: 8.8070\n",
      "Epoch 1878/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 55.7971 - mae: 6.0163 - val_loss: 64.3878 - val_mae: 6.4848\n",
      "Epoch 1879/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 59.6864 - mae: 6.2083 - val_loss: 29.2406 - val_mae: 4.2198\n",
      "Epoch 1880/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 55.1160 - mae: 5.9278 - val_loss: 105.9189 - val_mae: 8.6322\n",
      "Epoch 1881/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 55.8550 - mae: 6.0238 - val_loss: 40.0507 - val_mae: 4.6000\n",
      "Epoch 1882/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 57.1301 - mae: 5.9002 - val_loss: 112.8617 - val_mae: 8.2273\n",
      "Epoch 1883/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 52.8729 - mae: 5.6503 - val_loss: 33.6824 - val_mae: 4.3520\n",
      "Epoch 1884/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 57.0435 - mae: 5.9523 - val_loss: 38.0091 - val_mae: 4.7943\n",
      "Epoch 1885/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 55.4340 - mae: 5.9771 - val_loss: 36.9949 - val_mae: 4.8989\n",
      "Epoch 1886/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 54.5892 - mae: 5.9110 - val_loss: 72.8449 - val_mae: 6.9499\n",
      "Epoch 1887/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 57.8031 - mae: 6.0141 - val_loss: 43.3366 - val_mae: 5.2087\n",
      "Epoch 1888/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 58.3470 - mae: 6.1265 - val_loss: 47.1978 - val_mae: 5.3029\n",
      "Epoch 1889/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 49.5719 - mae: 5.4598 - val_loss: 59.9256 - val_mae: 6.3169\n",
      "Epoch 1890/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 56.0624 - mae: 5.9655 - val_loss: 44.3990 - val_mae: 5.0805\n",
      "Epoch 1891/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 58.3807 - mae: 6.0036 - val_loss: 72.2152 - val_mae: 7.1263\n",
      "Epoch 1892/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 53.8238 - mae: 5.8940 - val_loss: 27.5961 - val_mae: 4.0102\n",
      "Epoch 1893/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 56.5268 - mae: 6.0556 - val_loss: 159.4935 - val_mae: 10.0914\n",
      "Epoch 1894/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 56.2245 - mae: 5.9516 - val_loss: 80.6287 - val_mae: 7.8633\n",
      "Epoch 1895/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 55.0544 - mae: 5.8760 - val_loss: 54.4044 - val_mae: 5.6223\n",
      "Epoch 1896/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 56.8763 - mae: 5.9508 - val_loss: 87.4915 - val_mae: 7.3191\n",
      "Epoch 1897/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 54.4210 - mae: 5.7938 - val_loss: 158.6492 - val_mae: 11.1772\n",
      "Epoch 1898/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 57.3601 - mae: 5.9462 - val_loss: 116.7796 - val_mae: 9.1922\n",
      "Epoch 1899/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 59.0150 - mae: 6.2019 - val_loss: 36.6008 - val_mae: 4.7332\n",
      "Epoch 1900/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 50.8847 - mae: 5.7276 - val_loss: 26.0078 - val_mae: 3.8456\n",
      "Epoch 1901/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 56.9447 - mae: 5.9395 - val_loss: 55.8311 - val_mae: 5.9759\n",
      "Epoch 1902/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 55.6339 - mae: 5.8519 - val_loss: 45.6835 - val_mae: 5.2969\n",
      "Epoch 1903/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 56.4228 - mae: 5.9244 - val_loss: 54.9780 - val_mae: 5.9767\n",
      "Epoch 1904/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 54.3363 - mae: 5.7427 - val_loss: 59.1190 - val_mae: 6.2529\n",
      "Epoch 1905/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 56.9863 - mae: 6.0134 - val_loss: 43.3217 - val_mae: 5.0979\n",
      "Epoch 1906/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 55.7298 - mae: 6.0189 - val_loss: 34.8889 - val_mae: 4.5220\n",
      "Epoch 1907/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 53.3374 - mae: 5.8713 - val_loss: 98.9610 - val_mae: 7.9903\n",
      "Epoch 1908/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 53.9413 - mae: 5.8612 - val_loss: 53.1166 - val_mae: 6.1740\n",
      "Epoch 1909/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 54.4938 - mae: 5.6847 - val_loss: 77.5001 - val_mae: 7.2124\n",
      "Epoch 1910/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 60.0160 - mae: 6.1905 - val_loss: 33.5539 - val_mae: 4.4256\n",
      "Epoch 1911/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 51.6647 - mae: 5.5474 - val_loss: 41.2797 - val_mae: 4.9643\n",
      "Epoch 1912/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 59.1779 - mae: 6.2319 - val_loss: 92.0620 - val_mae: 7.7173\n",
      "Epoch 1913/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 52.1286 - mae: 5.5480 - val_loss: 57.9443 - val_mae: 6.3691\n",
      "Epoch 1914/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 55.2853 - mae: 5.8794 - val_loss: 25.2021 - val_mae: 3.8091\n",
      "Epoch 1915/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 54.6562 - mae: 5.8231 - val_loss: 39.9487 - val_mae: 4.8830\n",
      "Epoch 1916/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 51.7184 - mae: 5.7163 - val_loss: 63.9121 - val_mae: 6.3423\n",
      "Epoch 1917/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 55.7669 - mae: 6.0579 - val_loss: 101.7519 - val_mae: 8.2119\n",
      "Epoch 1918/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 52.7708 - mae: 5.7354 - val_loss: 141.7575 - val_mae: 10.5032\n",
      "Epoch 1919/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 54.2176 - mae: 5.7669 - val_loss: 34.4778 - val_mae: 4.4276\n",
      "Epoch 1920/2000\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 55.1418 - mae: 5.9122 - val_loss: 143.6628 - val_mae: 10.4367\n",
      "Epoch 1921/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 55.3150 - mae: 5.9897 - val_loss: 30.7343 - val_mae: 4.1946\n",
      "Epoch 1922/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 57.3379 - mae: 6.0738 - val_loss: 47.0753 - val_mae: 5.4639\n",
      "Epoch 1923/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 54.7050 - mae: 5.9036 - val_loss: 38.4727 - val_mae: 4.9656\n",
      "Epoch 1924/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 51.5006 - mae: 5.5635 - val_loss: 89.6721 - val_mae: 7.6886\n",
      "Epoch 1925/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 58.5729 - mae: 6.0105 - val_loss: 65.4209 - val_mae: 6.4544\n",
      "Epoch 1926/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 54.5023 - mae: 5.9089 - val_loss: 36.0304 - val_mae: 4.7792\n",
      "Epoch 1927/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 54.5463 - mae: 5.8966 - val_loss: 79.6285 - val_mae: 7.2770\n",
      "Epoch 1928/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 54.4478 - mae: 5.7771 - val_loss: 49.0978 - val_mae: 5.7046\n",
      "Epoch 1929/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 52.8366 - mae: 5.8865 - val_loss: 102.7133 - val_mae: 8.6865\n",
      "Epoch 1930/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 53.2408 - mae: 5.6879 - val_loss: 55.5430 - val_mae: 5.7804\n",
      "Epoch 1931/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 56.7970 - mae: 5.9978 - val_loss: 34.5365 - val_mae: 4.4832\n",
      "Epoch 1932/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 54.4416 - mae: 5.7587 - val_loss: 47.8248 - val_mae: 5.6298\n",
      "Epoch 1933/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 56.0041 - mae: 6.0519 - val_loss: 67.3742 - val_mae: 6.7667\n",
      "Epoch 1934/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 56.3545 - mae: 5.9889 - val_loss: 37.1418 - val_mae: 4.8448\n",
      "Epoch 1935/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 54.0124 - mae: 5.9553 - val_loss: 65.9512 - val_mae: 6.5936\n",
      "Epoch 1936/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 53.3225 - mae: 5.8396 - val_loss: 31.9097 - val_mae: 4.3972\n",
      "Epoch 1937/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 55.0669 - mae: 5.8407 - val_loss: 39.2963 - val_mae: 4.8039\n",
      "Epoch 1938/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 54.7710 - mae: 5.8990 - val_loss: 35.0924 - val_mae: 4.5669\n",
      "Epoch 1939/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 54.0844 - mae: 6.0071 - val_loss: 42.4686 - val_mae: 5.2249\n",
      "Epoch 1940/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 55.1805 - mae: 6.0579 - val_loss: 98.9545 - val_mae: 8.1398\n",
      "Epoch 1941/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 53.6658 - mae: 5.7475 - val_loss: 45.8382 - val_mae: 5.1659\n",
      "Epoch 1942/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 53.5946 - mae: 5.8618 - val_loss: 24.1503 - val_mae: 3.8079\n",
      "Epoch 1943/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 54.9818 - mae: 5.7789 - val_loss: 31.4812 - val_mae: 4.3135\n",
      "Epoch 1944/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 55.8274 - mae: 6.0156 - val_loss: 39.7037 - val_mae: 4.8859\n",
      "Epoch 1945/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 50.2494 - mae: 5.7378 - val_loss: 118.0651 - val_mae: 9.0566\n",
      "Epoch 1946/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 54.9034 - mae: 5.8084 - val_loss: 99.8554 - val_mae: 8.0269\n",
      "Epoch 1947/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 50.8870 - mae: 5.4510 - val_loss: 68.3484 - val_mae: 6.6866\n",
      "Epoch 1948/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 57.0280 - mae: 6.1128 - val_loss: 48.5012 - val_mae: 5.6043\n",
      "Epoch 1949/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 50.1604 - mae: 5.6755 - val_loss: 53.7213 - val_mae: 6.1272\n",
      "Epoch 1950/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 55.9263 - mae: 6.0479 - val_loss: 35.0349 - val_mae: 4.6944\n",
      "Epoch 1951/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 53.7030 - mae: 5.7568 - val_loss: 64.9359 - val_mae: 6.3240\n",
      "Epoch 1952/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 50.2933 - mae: 5.6533 - val_loss: 99.0051 - val_mae: 8.4518\n",
      "Epoch 1953/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 54.7134 - mae: 5.9081 - val_loss: 71.2846 - val_mae: 7.0155\n",
      "Epoch 1954/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 54.5632 - mae: 5.9569 - val_loss: 82.5916 - val_mae: 6.7632\n",
      "Epoch 1955/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 57.5694 - mae: 6.1018 - val_loss: 86.5875 - val_mae: 7.3365\n",
      "Epoch 1956/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 53.4120 - mae: 5.8510 - val_loss: 93.6681 - val_mae: 8.2763\n",
      "Epoch 1957/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 53.0398 - mae: 5.8337 - val_loss: 63.9834 - val_mae: 6.0729\n",
      "Epoch 1958/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 51.8057 - mae: 5.7517 - val_loss: 69.4600 - val_mae: 6.1947\n",
      "Epoch 1959/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 57.0143 - mae: 6.0384 - val_loss: 44.5815 - val_mae: 5.0461\n",
      "Epoch 1960/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 49.0605 - mae: 5.4900 - val_loss: 147.8888 - val_mae: 10.3402\n",
      "Epoch 1961/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 55.0652 - mae: 5.9652 - val_loss: 66.9247 - val_mae: 6.9923\n",
      "Epoch 1962/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 53.4911 - mae: 5.8903 - val_loss: 82.7470 - val_mae: 7.7709\n",
      "Epoch 1963/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 54.3791 - mae: 6.0214 - val_loss: 25.9891 - val_mae: 4.0050\n",
      "Epoch 1964/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 53.5308 - mae: 5.7077 - val_loss: 40.4537 - val_mae: 4.8606\n",
      "Epoch 1965/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 51.0077 - mae: 5.7232 - val_loss: 23.7887 - val_mae: 3.6695\n",
      "Epoch 1966/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 49.4155 - mae: 5.4511 - val_loss: 129.4047 - val_mae: 10.1483\n",
      "Epoch 1967/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 55.4583 - mae: 5.8713 - val_loss: 49.8535 - val_mae: 5.5229\n",
      "Epoch 1968/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 52.6486 - mae: 5.8491 - val_loss: 170.4389 - val_mae: 11.1018\n",
      "Epoch 1969/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 52.7476 - mae: 5.8552 - val_loss: 35.2607 - val_mae: 4.7793\n",
      "Epoch 1970/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 54.2159 - mae: 5.7692 - val_loss: 87.3376 - val_mae: 7.5419\n",
      "Epoch 1971/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 52.9524 - mae: 5.8282 - val_loss: 60.4034 - val_mae: 6.1665\n",
      "Epoch 1972/2000\n",
      "65/65 [==============================] - 1s 7ms/step - loss: 53.7743 - mae: 5.9220 - val_loss: 84.1520 - val_mae: 7.6859\n",
      "Epoch 1973/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 56.8998 - mae: 6.0810 - val_loss: 44.5960 - val_mae: 5.3521\n",
      "Epoch 1974/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 51.1930 - mae: 5.7576 - val_loss: 66.9247 - val_mae: 6.5749\n",
      "Epoch 1975/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 52.4726 - mae: 5.8312 - val_loss: 21.5409 - val_mae: 3.5970\n",
      "Epoch 1976/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 53.9454 - mae: 5.8530 - val_loss: 29.5852 - val_mae: 4.2571\n",
      "Epoch 1977/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 56.1299 - mae: 5.9188 - val_loss: 64.4900 - val_mae: 6.6433\n",
      "Epoch 1978/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 51.3493 - mae: 5.6406 - val_loss: 75.5251 - val_mae: 7.1010\n",
      "Epoch 1979/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 54.9061 - mae: 6.0138 - val_loss: 32.9437 - val_mae: 4.5264\n",
      "Epoch 1980/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 54.8334 - mae: 5.8984 - val_loss: 59.0437 - val_mae: 6.1259\n",
      "Epoch 1981/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 52.6027 - mae: 5.8455 - val_loss: 101.5434 - val_mae: 8.7283\n",
      "Epoch 1982/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 53.6336 - mae: 5.9140 - val_loss: 140.1454 - val_mae: 10.1430\n",
      "Epoch 1983/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 53.4114 - mae: 5.6516 - val_loss: 39.3989 - val_mae: 5.0898\n",
      "Epoch 1984/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 49.1832 - mae: 5.4613 - val_loss: 45.0657 - val_mae: 5.4186\n",
      "Epoch 1985/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 56.8454 - mae: 6.0927 - val_loss: 51.9758 - val_mae: 5.8622\n",
      "Epoch 1986/2000\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 55.8910 - mae: 6.1429 - val_loss: 72.4500 - val_mae: 6.7486\n",
      "Epoch 1987/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 50.7991 - mae: 5.6640 - val_loss: 61.4749 - val_mae: 5.8700\n",
      "Epoch 1988/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 54.4893 - mae: 5.9232 - val_loss: 43.5198 - val_mae: 5.3222\n",
      "Epoch 1989/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 53.8195 - mae: 5.8946 - val_loss: 28.8959 - val_mae: 4.2759\n",
      "Epoch 1990/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 53.7657 - mae: 5.8242 - val_loss: 39.9761 - val_mae: 5.1048\n",
      "Epoch 1991/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 48.9927 - mae: 5.4145 - val_loss: 98.5515 - val_mae: 8.2611\n",
      "Epoch 1992/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 57.2446 - mae: 5.9862 - val_loss: 124.6688 - val_mae: 9.4318\n",
      "Epoch 1993/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 49.7159 - mae: 5.4159 - val_loss: 132.9397 - val_mae: 9.2412\n",
      "Epoch 1994/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 53.5485 - mae: 5.8819 - val_loss: 88.2627 - val_mae: 7.8286\n",
      "Epoch 1995/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 54.9421 - mae: 5.9402 - val_loss: 52.0879 - val_mae: 5.8533\n",
      "Epoch 1996/2000\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 51.0523 - mae: 5.8211 - val_loss: 94.1109 - val_mae: 7.9905\n",
      "Epoch 1997/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 53.0947 - mae: 5.8038 - val_loss: 39.6722 - val_mae: 5.0619\n",
      "Epoch 1998/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 49.4009 - mae: 5.5736 - val_loss: 31.6027 - val_mae: 4.3137\n",
      "Epoch 1999/2000\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 55.2807 - mae: 5.9592 - val_loss: 19.1571 - val_mae: 3.3015\n",
      "Epoch 2000/2000\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 53.2375 - mae: 5.8037 - val_loss: 120.8351 - val_mae: 8.8312\n",
      "101/101 [==============================] - 0s 2ms/step\n",
      "51/51 [==============================] - 0s 2ms/step\n",
      "51/51 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Start MLflow run\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # Log parameters\n",
    "    mlflow.set_tag(\"programmer\", \"Berchie\")\n",
    "    mlflow.log_param(\"Data-path\", \"D:\\Groundwater level (GWL) changes\\Groundwater level (GWL) changes data\\Pamen.csv\")\n",
    "    mlflow.log_param('epochs', 2000)\n",
    "    mlflow.log_param('batch_size', 50)\n",
    "    #Feed forward neural network model architecture\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(x_train.shape[1],)))\n",
    "    model.add(Dense(1000, activation='relu'))\n",
    "    model.add(Dense(500, activation='relu'))\n",
    "    model.add(Dense(250, activation='linear'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    # Log the model architecture using mlflow.tensorflow\n",
    "    mlflow.tensorflow.log_model(model, 'model')\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "\n",
    "    earlyStop = EarlyStopping(monitor='val_loss',\n",
    "                             mode='min',\n",
    "                             patience=500)\n",
    "\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        epochs=2000,\n",
    "                        callbacks=[earlyStop],\n",
    "                        batch_size=50,\n",
    "                        validation_data=(x_val, y_val),\n",
    "                        verbose=1)\n",
    "    # Log metrics\n",
    "    mlflow.log_metric('final_training_loss', history.history['loss'][-1])\n",
    "    mlflow.log_metric('final_validation_loss', history.history['val_loss'][-1])\n",
    "    \n",
    "    # Log MAE metrics\n",
    "    train_preds = model.predict(x_train)\n",
    "    val_preds = model.predict(x_val)\n",
    "    test_preds = model.predict(x_test)\n",
    "    \n",
    "    mlflow.log_metric('train_mae', mean_absolute_error(y_train, train_preds))\n",
    "    mlflow.log_metric('val_mae', mean_absolute_error(y_val, val_preds))\n",
    "    mlflow.log_metric('test_mae', mean_absolute_error(y_test, test_preds))\n",
    "    \n",
    "    # Plot and save training/validation loss\n",
    "    plt.plot(history.history['loss'], label='Training loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    loss_plot_path = 'D:\\RGT\\Code\\Practice\\Deep Learning for GWL Changes\\Artifacts\\loss_plot.png'\n",
    "    plt.savefig(loss_plot_path)\n",
    "    mlflow.log_artifact(loss_plot_path)\n",
    "    plt.close()\n",
    "    \n",
    "    # Log scatter plots\n",
    "    fig, axes = plt.subplots(1, 2)\n",
    "\n",
    "    # Training Results\n",
    "    axes[0].scatter(x=y_train, y=train_preds)\n",
    "    axes[0].set_xlabel(\"Actual\", fontsize=10)\n",
    "    axes[0].set_ylabel(\"Predicted\", fontsize=10)\n",
    "    axes[0].set_title(\"Training\")\n",
    "\n",
    "    x = np.linspace(*axes[0].get_xlim())\n",
    "    axes[0].plot(x, x, color='red')\n",
    "\n",
    "    # Validation Results\n",
    "    axes[1].scatter(x=y_test, y=test_preds)\n",
    "    axes[1].set_xlabel(\"Actual\", fontsize=10)\n",
    "    axes[1].set_ylabel(\"Predicted\", fontsize=10)\n",
    "    axes[1].set_title(\"Validation\")\n",
    "\n",
    "    x = np.linspace(*axes[1].get_xlim())\n",
    "    axes[1].plot(x, x, color='red')\n",
    "\n",
    "    # Tight layout\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Save scatter plot\n",
    "    scatter_plot_path = 'D:\\RGT\\Code\\Practice\\Deep Learning for GWL Changes\\Artifacts\\scatter_plot.png'\n",
    "    plt.savefig(scatter_plot_path)\n",
    "    mlflow.log_artifact(scatter_plot_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2769eec3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlopsenv",
   "language": "python",
   "name": "mlopsenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
